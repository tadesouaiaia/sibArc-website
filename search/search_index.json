{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SibArc is a simple tool that allows inferences about complex genetic architecture to be made from sibling-trait data alone. Package Downloads Operating System Link Notes Linux 64-bit v1.0.1 Updated 4-24-2024 Mac 64-bit v1.0.1 Updated 4-24-2024 Windows 64-bit v1.0.1 Updated 4-24-2024 Overview SibArc is written in Python. To run SibArc using the supplied sample data please see our Quick Start Tutorial. . Following the Quick Start, please read our manuscript, to learn more about the theory behind sibArc. Citation: Our Manuscript is published Elife Please cite our paper : Tade Souaiaia, Hei Man Wu, Clive Hoggart, Paul O\u2019Reilly. 2023 Sibling Similarity Can Reveal Key Insights Into Genetic Architecture. eLife12:RP87522 Contact For questions about the methodology, this website, or our manuscript please contact Dr Tade Souaiaia Dr Clive Hoggart , or Dr Paul O'Reilly . For source code and coding issues please visit our github page . Acknowledgements We would like to thank Shai Carmi for helpful feedback.","title":"Home"},{"location":"#package-downloads","text":"Operating System Link Notes Linux 64-bit v1.0.1 Updated 4-24-2024 Mac 64-bit v1.0.1 Updated 4-24-2024 Windows 64-bit v1.0.1 Updated 4-24-2024","title":"Package Downloads"},{"location":"#overview","text":"SibArc is written in Python. To run SibArc using the supplied sample data please see our Quick Start Tutorial. . Following the Quick Start, please read our manuscript, to learn more about the theory behind sibArc. Citation: Our Manuscript is published Elife Please cite our paper : Tade Souaiaia, Hei Man Wu, Clive Hoggart, Paul O\u2019Reilly. 2023 Sibling Similarity Can Reveal Key Insights Into Genetic Architecture. eLife12:RP87522","title":"Overview"},{"location":"#contact","text":"For questions about the methodology, this website, or our manuscript please contact Dr Tade Souaiaia Dr Clive Hoggart , or Dr Paul O'Reilly . For source code and coding issues please visit our github page .","title":"Contact"},{"location":"#acknowledgements","text":"We would like to thank Shai Carmi for helpful feedback.","title":"Acknowledgements"},{"location":"about_future/","text":"Future Work Coming Soon","title":"Future Work"},{"location":"about_future/#future-work","text":"Coming Soon","title":"Future Work"},{"location":"quik_demo/","text":"Running SibArc: Running SibArc on a trait with de-novo tail architecture From the test directory type: ./sibArc.py ../data/trait1-test.csv --out denovoExample This will produce the following output files: denovoExample.result.out, denovoExample.fig.png, denovoExample.fig.pdf Running SibArc on a trait with Mendelian tail architecture From the test directory type: ./sibArc.py ../data/trait2-test.csv --out mendelianExample This will produce the following output files: mendelianExample.result.out, mendelianExample.fig.png, mendelianExample.fig.pdf","title":"Running SibArc"},{"location":"quik_demo/#running-sibarc","text":"Running SibArc on a trait with de-novo tail architecture From the test directory type: ./sibArc.py ../data/trait1-test.csv --out denovoExample This will produce the following output files: denovoExample.result.out, denovoExample.fig.png, denovoExample.fig.pdf Running SibArc on a trait with Mendelian tail architecture From the test directory type: ./sibArc.py ../data/trait2-test.csv --out mendelianExample This will produce the following output files: mendelianExample.result.out, mendelianExample.fig.png, mendelianExample.fig.pdf","title":"Running SibArc:"},{"location":"quik_install/","text":"Preparation After downloading and unzipping sibArc into a suitable directory on your machine you will observe that a folder with the following contents: sibArc <--- program executable data/ <--- input data LICENSE README.me tests/ <--- test directory For Mac/Linux, using the terminal, type the following command from within the directory: chmod +x sibArc.py to make sibArc executable Input Data SibArc requires two column sibling phenotype data. The columns can be separated by a comma or whitespace, a header is optional: Phenotype1,Phenotype2 -2.23511,-2.33331 -1.23041,-1.03325 -1.55322,-0.03213 0.32353,0.991132 0.53233,2.124533 1.23345,0.936323 2.35326,1.323531 Sample Sibling Data Sample Sibling Data can be found in the data folder data/trait1-test.csv data/trait2-test.csv","title":"Installation and Data"},{"location":"quik_install/#preparation","text":"After downloading and unzipping sibArc into a suitable directory on your machine you will observe that a folder with the following contents: sibArc <--- program executable data/ <--- input data LICENSE README.me tests/ <--- test directory For Mac/Linux, using the terminal, type the following command from within the directory: chmod +x sibArc.py to make sibArc executable","title":"Preparation"},{"location":"quik_install/#input-data","text":"SibArc requires two column sibling phenotype data. The columns can be separated by a comma or whitespace, a header is optional: Phenotype1,Phenotype2 -2.23511,-2.33331 -1.23041,-1.03325 -1.55322,-0.03213 0.32353,0.991132 0.53233,2.124533 1.23345,0.936323 2.35326,1.323531 Sample Sibling Data Sample Sibling Data can be found in the data folder data/trait1-test.csv data/trait2-test.csv","title":"Input Data"},{"location":"quik_result/","text":"Interpreting SibArc Results A trait with denovo tail architecture in both tails (denovoExample.fig.png) Notice: 1. Evidence of De Novo architecture in both trait tails. 2. Lower heritability in both trait tails. A trait with Mendelian tail architecture in both tails (mendelianExample.fig.png) Notice: 1. Polygenic architecture in the lower tail, Mendelian heritability in the upper tail. 2. Increased heritability in the upper tail.","title":"Interpreting Results"},{"location":"quik_result/#interpreting-sibarc-results","text":"A trait with denovo tail architecture in both tails (denovoExample.fig.png) Notice: 1. Evidence of De Novo architecture in both trait tails. 2. Lower heritability in both trait tails. A trait with Mendelian tail architecture in both tails (mendelianExample.fig.png) Notice: 1. Polygenic architecture in the lower tail, Mendelian heritability in the upper tail. 2. Increased heritability in the upper tail.","title":"Interpreting SibArc Results"},{"location":"workshop_practical_clive.docx/","text":"BridgePRS Learning Objectives In the previous lecture we covered in detail the modelling used by BridgePRS. Here we will use the BridgePRS software to apply the method. The aim of this practical is to provide you with a basic understanding and some experience of running BridgePRS software. After completing this practical, you should: Be able to perform cross-population analyses using BridgePRS understand what input files are required by BridgePRS setting up configuration files used to pass arguments to BridgePRS Interpret output from BridgePRS Use BridgePRS output to calculate PRS in unseen samples using SNP weights BridgePRS input data In the BridgePRS directory there is a data folder which we will use in this practical. View the data directory $ ls -l data total 5368 drwxr-xr-x 73 hoggac01 staff 2336 26 Jul 16:00 1000G_sample -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 afr.config -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 eas.config -rw-r--r-- 1 hoggac01 staff 410 12 Aug 14:35 eur.config drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_AFR drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_EAS drwxr-xr-x 5 hoggac01 staff 160 7 Aug 20:30 pop_EUR -rw-r--r-- 1 hoggac01 staff 200376 7 Aug 21:30 qc_snplist.txt The pop_AFR, pop_EAS, pop_EUR folders contain simulated genotype, phenotype and GWAS summary statistics representative of Europeans, East Asians and Africans for input to BridgePRS. Each pop_* folder is split into summary statistics, and individual level genotype and phenotype folders, e.g. $ ls -l data/pop_AFR/ total 0 drwxr-xr-x 68 hoggac01 staff 2176 14 Jul 17:22 genotypes drwxr-xr-x 4 hoggac01 staff 128 14 Jul 17:22 phenotypes drwxr-xr-x 68 hoggac01 staff 2176 12 Aug 11:02 sumstats Look at each directory e.g. ls pop_AFR/genotypes . There are two sets of summary statistics in each sumstats folder from the analysis of the same simulated continuos phenotype, the \"half\" files were generated using half the sample size. For computation speed the summary statistics only have a small subset of SNPs, 19k-20k genomewide, the following commands count the number of lines in each set of summary statistics zcat data/pop_EAS/sumstats/EAS.chr* | wc -l zcat data/pop_EUR/sumstats/EUR.chr* | wc -l zcat data/pop_AFR/sumstats/AFR.chr* | wc -l or on a Mac gzcat data/pop_EAS/sumstats/EAS.chr* | wc -l gzcat data/pop_EUR/sumstats/EUR.chr* | wc -l gzcat data/pop_AFR/sumstats/AFR.chr* | wc -l zcat / gzcat are used as the files are gzipped. | \"pipes\" the output to wc -l which counts the number of lines. Results in these files are only shown for SNPs with MAF>0 and are a random subset of HapMap SNPs. Questions? Which population has the most polymorphic SNPs? Which population has the least polymorphic SNPs? Why do you think this bias exists? Which population would you expect to have the most polymorphic SNPs if SNPs were ascertained from 1000G? Take a look a look at the files, e.g. zcat data/pop_AFR/sumstats/AFR.chr19.glm.linear.gz | head zcat data/pop_AFR/sumstats/AFR_half.chr19.glm.linear.gz | head again use gzcat on a Mac. In the OBS_CT column you'll see can that the \"_half\" summary statistics files have half the sample size, 10,000 compared to 20,000 for the EAS and AFR populations and 40,000 compared to 80,000 for the EUR population. The same SNPs are contained in each set of summary statistics. The phenotypes folders has two files: \"test\" and \"validation\" with IDs, the outcome phenotype and covariates. \"Test\" data is used to optimise the PRS and \"validation\" data is is just to assess model performance, it is not used to estimate the PRS. The genotypes folders are in plink binary format and are split by chromosome. These folders contain the genetic data for both test and validation individuals in the phenotypes folder. Test data will only be used for individuals with both genotype and phenotype information. Similarly model performance metrics will only use samples with both genotype and phenotype information, however, predictions are generated for all validation samples with genotype data. Passing arguments to run BridgePRS Example run of BridgePRS: ./bridgePRS pipeline go -o out/ --config_files data/eas.config data/eur.config --fst 0.11 --phenotype y --cores 4 --restart Arguments can be passed to BridgePRS on both the commandline and in config files. config files, used above, are a neat way to store population specific arguments, for a standard two population analysis two config are required. By default the first config file is for the target population and the second is for the base population. The -o argument specifies the output folder. The --fst argument is used to specify a prior distribution used in the BridgePRS analysis and should be the Fst between the base and target populations used in the analysis. Our first analysis uses European base data and East Asian target data, the Fst between these populations is 0.11. The --phenotype argument specifies the column label of the phenotype in the test and validation files, e.g. EAS_valid.dat . The --cores argument specifies the number of cores used in the analysis. A full list of arguments that can be used on the command line can be found here . The *.config files .config files tell BridgePRS where to find the required input files and the column headers of the summary statistics files for a population data set, take a look, e.g. cat data/eas.config POP=EAS LDPOP=EAS LD_PATH=1000G_sample SUMSTATS_PREFIX=pop_EAS/sumstats/EAS.chr SUMSTATS_SIZE=20000 #SUMSTATS_PREFIX=pop_EAS/sumstats/EAS_half.chr #SUMSTATS_SIZE=10000 SUMSTATS_SUFFIX=.glm.linear.gz GENOTYPE_PREFIX=pop_EAS/genotypes/chr PHENOTYPE_FILE=pop_EAS/phenotypes/EAS_test.dat VALIDATION_FILE=pop_EAS/phenotypes/EAS_valid.dat SNP_FILE=qc_snplist.txt SSF-P=P SSF-SNPID=ID SSF-BETA=BETA SSF-REF=REF SSF-ALT=A1 This config file conatins all possible arguments that can be used in config files. config files use the same argument names as the commandline arguments but in uppercase, and use \"=\" instead of a space between the argument name and the argument being passed. The POP argument simply labels the population used in this .config file for output. Estimating Linkage Dissequilibrium (LD) BridgePRS requires individual level genetic data in plink binary format to estimate linkage dissequilibrium (LD) in the populations which produced the GWAS summary statistics. The genotype test and validation data could be used, e.g. data here pop_EUR/genotypes/ . If these data are small, less than 500 samples, or are not representative of the GWAS population we provide 1000 Genomes (1000G) data to estimate LD. Suitable 1000G data for this analysis is in the 1000G_sample folder for the small subset of SNPs used in these examples. The .config files point to the folder with reference LD data by the LD_PATH argument in the config file. LD reference data is available for the five 1000G super population (abbreviations required to use in brackets): East Asian (EAS), South Asian (SAS), European (Eur), African (AFR) and American (AMR). For real data analyses 1000G reference data for larger subsets of SNPs can be downloaded here Qustion? Can you work out what the other command line arguments are doing? Can you work out what the other config file arguments are doing? BridgePRS output The main output is in the folder out/prs-combined_EAS-EUR/ . First view the output summary plot evince out/prs-combined_AFR-EUR/bridge.afr-eur.prs-combined.result.pdf on a Mac use open instead of evince . The barplot at the top shows the varaince explained (R2) by the four PRS models BridgePRS estimates. The weighted model is BridgePRS estimated \"best\" PRS. The models estimated by BridgePRS The three separate target population PRS estimated by BridgePRS are: * Stage2 model -- estimated using target population data with prior effect-size distribution from the base (European) population * Stage 1 model -- estimated using only the target (Non-European) data * Stage1+2 model -- estimated using both stage 1 and stage 2 models Each of these three models are given weights corresponding to how well they fit the test data. These weights are then used to combine the PRS to give the single weighted combined PRS. The weighted combined PRS should typically be used. The models, stage1, stage2 and stage1+2, should not be used unless users have a strong prior belief that a particular model is better. The hypotheses of the three models are: * Stage 2 model reflects the belief that the target population GWAS is only informative in conjugtion with the base population GWAS. * Stage 1 model reflects the belief that the target population GWAS is informative and the base population GWAS gives no addition information. * Stage 1+2 model reflects the belief both the base and target population GWAS contribute independent information. Look at the following output file cat out/prs-combined_AFR-EUR/EAS_weighted_combined_var_explained.txt Question? Which plot in the summary plot was constructed from this output file? How do the Manhattan plots of the base and target populations compare? EAS_weighted_combined_preds.dat has PRS predictions for samples in the validation data using all four models: stage1, stage2, stage1+2 and weighted. EAS_weighted_combined_snp_weights.dat has the SNP weights for the combined to allow this model to be applied to other samples. Using BridgePRS without target summary statistics Often GWAS summary statistics are only available in one population. BridgePRS can use these summary statistics and optimise them to estimate a PRS for another target population given individual level from the target population. Here is an example using the data/eur_eas.config config file ./bridgePRS prs-single run -o out_single/ --config_files data/eur_eas.config --phenotype y --cores 10 Look at data/eur_eas.config . Questions? What GWAS summary data is used? What test data is used for model optimisation? What validation data is used? Results of interest are written to the folder out_single/prs-single_EAS/quantify/ . Model performance is shown in the file EAS_quantify_var_explained.txt and plotted in .... See how these results compare with the previous analysis which included EAS GWAS summary statistics. cat out_single/prs-single_EAS/quantify/EAS_quantify_var_explained.txt cat out/prs-combined_EAS-EUR/EAS_weighted_combined_var_explained.txt This single summary statistic analysis is equilvant to the stage 2 analysis previously but with all the weight on the EUR prior. Question? How does prediction using only EUR summary statistics compare with those which include information from the EAS summary statistics? Further analysis with BridgePRS African analysis Run BridgePRS again to estimate PRS in Africans using afr.config . Note, you should also change the command line fst argument to match the Fst between Africans and Europeans, use 0.15. Qustions? Which population, EAS or AFR, has the best prediction? What are the reasons for the differences in prediction between the populations? Analyses with other GWAS summary statistics For each population the config files contain commented out links to GWAS summary statistics of the same phenotype using half the same size: 40k for EUR and 10k for both EAS and AFR. Edit eas.config to use the EAS 10k GWAS summary statistics. To run the analysis write results to a new output directory e.g. out_half_target . Run the similar analysis for African samples by editing afr.config . Compare with previous results using the 10k EAS and EAS GWAS. Compare EAS and AFR results. Check you've run the analyses using the correct GWAS summary statistics, e.g. less less out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log less less out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log or grep Sumstats out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log grep Sumstats out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log If you have made a mistake, correct and run again using the --restart flag which deletes the previously genereated results. Qustions? How has using the less well powered EAS and AFR GWAS affected the predictive accuracy of the BridgePRS models? How do AFR and EAS results compare? Analyses with smaller EUR GWAS summary statistics Edit the config files again to run analyses using the 40k EUR GWAS (i.e. EUR_half ) and the 20k EAS and AFR GWAS and write to results to a new directory e.g. out_half_eur . Qustions? How has using the less well powered EUR GWAS affected the predictive accuracy of the BridgePRS models? How do AFR and EAS results compare? Using BidgePRS SNP weights The SNP weights in EAS_weighted_combined_snp_weights.dat can be used to make predictions in other samples for which we have overlapping genotype data. We demonstrate this using plink and data in data/pop_EAS/genotypes/ . The genotype data is split by chromosome, therefore predictions are estimated for each chromosome separately and then combined. The following bash commands estimate the per chromosome predictions using plink, we first make a directory to write these predictions to mkdir out/preds for chr in {1..22} do plink --score out/prs-combined_EAS-EUR/EAS_weighted_combined_snp_weights.dat 1 2 4 list-variants \\ --bfile data/pop_EAS/genotypes/chr$chr \\ --out out/preds/EAS_chr$chr done We then read these predictions into R to combine R library(data.table) tmp <- fread(paste0('out1/preds/EAS_chr1.profile')) pred <- data.frame( tmp$IID, tmp$SCORESUM ) colnames(pred) <- c('IID','Score') for( chr in 2:22 ){ tmp <- fread(paste0('out1/preds/EAS_chr',chr,'.profile')) pred[,2] <- pred[,2] + tmp$SCORESUM } # Check predictions are the same as those produced directly by BridgePRS valid <- fread('out1/prs-combined_EAS-EUR/EAS_weighted_combined_preds.dat') # Match IDs ptr <- match( valid$IID, pred$IID ) plot( pred$Score[ptr], valid$Weighted ) Predictions are the same +/- rounding error and a constant.","title":"Day 2 (AM)"},{"location":"workshop_practical_clive.docx/#bridgeprs","text":"","title":"BridgePRS"},{"location":"workshop_practical_clive.docx/#learning-objectives","text":"In the previous lecture we covered in detail the modelling used by BridgePRS. Here we will use the BridgePRS software to apply the method. The aim of this practical is to provide you with a basic understanding and some experience of running BridgePRS software. After completing this practical, you should: Be able to perform cross-population analyses using BridgePRS understand what input files are required by BridgePRS setting up configuration files used to pass arguments to BridgePRS Interpret output from BridgePRS Use BridgePRS output to calculate PRS in unseen samples using SNP weights","title":"Learning Objectives"},{"location":"workshop_practical_clive.docx/#bridgeprs-input-data","text":"In the BridgePRS directory there is a data folder which we will use in this practical. View the data directory $ ls -l data total 5368 drwxr-xr-x 73 hoggac01 staff 2336 26 Jul 16:00 1000G_sample -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 afr.config -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 eas.config -rw-r--r-- 1 hoggac01 staff 410 12 Aug 14:35 eur.config drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_AFR drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_EAS drwxr-xr-x 5 hoggac01 staff 160 7 Aug 20:30 pop_EUR -rw-r--r-- 1 hoggac01 staff 200376 7 Aug 21:30 qc_snplist.txt The pop_AFR, pop_EAS, pop_EUR folders contain simulated genotype, phenotype and GWAS summary statistics representative of Europeans, East Asians and Africans for input to BridgePRS. Each pop_* folder is split into summary statistics, and individual level genotype and phenotype folders, e.g. $ ls -l data/pop_AFR/ total 0 drwxr-xr-x 68 hoggac01 staff 2176 14 Jul 17:22 genotypes drwxr-xr-x 4 hoggac01 staff 128 14 Jul 17:22 phenotypes drwxr-xr-x 68 hoggac01 staff 2176 12 Aug 11:02 sumstats Look at each directory e.g. ls pop_AFR/genotypes . There are two sets of summary statistics in each sumstats folder from the analysis of the same simulated continuos phenotype, the \"half\" files were generated using half the sample size. For computation speed the summary statistics only have a small subset of SNPs, 19k-20k genomewide, the following commands count the number of lines in each set of summary statistics zcat data/pop_EAS/sumstats/EAS.chr* | wc -l zcat data/pop_EUR/sumstats/EUR.chr* | wc -l zcat data/pop_AFR/sumstats/AFR.chr* | wc -l or on a Mac gzcat data/pop_EAS/sumstats/EAS.chr* | wc -l gzcat data/pop_EUR/sumstats/EUR.chr* | wc -l gzcat data/pop_AFR/sumstats/AFR.chr* | wc -l zcat / gzcat are used as the files are gzipped. | \"pipes\" the output to wc -l which counts the number of lines. Results in these files are only shown for SNPs with MAF>0 and are a random subset of HapMap SNPs.","title":"BridgePRS input data"},{"location":"workshop_practical_clive.docx/#questions","text":"Which population has the most polymorphic SNPs? Which population has the least polymorphic SNPs? Why do you think this bias exists? Which population would you expect to have the most polymorphic SNPs if SNPs were ascertained from 1000G? Take a look a look at the files, e.g. zcat data/pop_AFR/sumstats/AFR.chr19.glm.linear.gz | head zcat data/pop_AFR/sumstats/AFR_half.chr19.glm.linear.gz | head again use gzcat on a Mac. In the OBS_CT column you'll see can that the \"_half\" summary statistics files have half the sample size, 10,000 compared to 20,000 for the EAS and AFR populations and 40,000 compared to 80,000 for the EUR population. The same SNPs are contained in each set of summary statistics. The phenotypes folders has two files: \"test\" and \"validation\" with IDs, the outcome phenotype and covariates. \"Test\" data is used to optimise the PRS and \"validation\" data is is just to assess model performance, it is not used to estimate the PRS. The genotypes folders are in plink binary format and are split by chromosome. These folders contain the genetic data for both test and validation individuals in the phenotypes folder. Test data will only be used for individuals with both genotype and phenotype information. Similarly model performance metrics will only use samples with both genotype and phenotype information, however, predictions are generated for all validation samples with genotype data.","title":"Questions?"},{"location":"workshop_practical_clive.docx/#passing-arguments-to-run-bridgeprs","text":"Example run of BridgePRS: ./bridgePRS pipeline go -o out/ --config_files data/eas.config data/eur.config --fst 0.11 --phenotype y --cores 4 --restart Arguments can be passed to BridgePRS on both the commandline and in config files. config files, used above, are a neat way to store population specific arguments, for a standard two population analysis two config are required. By default the first config file is for the target population and the second is for the base population. The -o argument specifies the output folder. The --fst argument is used to specify a prior distribution used in the BridgePRS analysis and should be the Fst between the base and target populations used in the analysis. Our first analysis uses European base data and East Asian target data, the Fst between these populations is 0.11. The --phenotype argument specifies the column label of the phenotype in the test and validation files, e.g. EAS_valid.dat . The --cores argument specifies the number of cores used in the analysis. A full list of arguments that can be used on the command line can be found here .","title":"Passing arguments to run BridgePRS"},{"location":"workshop_practical_clive.docx/#the-config-files","text":".config files tell BridgePRS where to find the required input files and the column headers of the summary statistics files for a population data set, take a look, e.g. cat data/eas.config POP=EAS LDPOP=EAS LD_PATH=1000G_sample SUMSTATS_PREFIX=pop_EAS/sumstats/EAS.chr SUMSTATS_SIZE=20000 #SUMSTATS_PREFIX=pop_EAS/sumstats/EAS_half.chr #SUMSTATS_SIZE=10000 SUMSTATS_SUFFIX=.glm.linear.gz GENOTYPE_PREFIX=pop_EAS/genotypes/chr PHENOTYPE_FILE=pop_EAS/phenotypes/EAS_test.dat VALIDATION_FILE=pop_EAS/phenotypes/EAS_valid.dat SNP_FILE=qc_snplist.txt SSF-P=P SSF-SNPID=ID SSF-BETA=BETA SSF-REF=REF SSF-ALT=A1 This config file conatins all possible arguments that can be used in config files. config files use the same argument names as the commandline arguments but in uppercase, and use \"=\" instead of a space between the argument name and the argument being passed. The POP argument simply labels the population used in this .config file for output.","title":"The *.config files"},{"location":"workshop_practical_clive.docx/#estimating-linkage-dissequilibrium-ld","text":"BridgePRS requires individual level genetic data in plink binary format to estimate linkage dissequilibrium (LD) in the populations which produced the GWAS summary statistics. The genotype test and validation data could be used, e.g. data here pop_EUR/genotypes/ . If these data are small, less than 500 samples, or are not representative of the GWAS population we provide 1000 Genomes (1000G) data to estimate LD. Suitable 1000G data for this analysis is in the 1000G_sample folder for the small subset of SNPs used in these examples. The .config files point to the folder with reference LD data by the LD_PATH argument in the config file. LD reference data is available for the five 1000G super population (abbreviations required to use in brackets): East Asian (EAS), South Asian (SAS), European (Eur), African (AFR) and American (AMR). For real data analyses 1000G reference data for larger subsets of SNPs can be downloaded here","title":"Estimating Linkage Dissequilibrium (LD)"},{"location":"workshop_practical_clive.docx/#qustion","text":"Can you work out what the other command line arguments are doing? Can you work out what the other config file arguments are doing?","title":"Qustion?"},{"location":"workshop_practical_clive.docx/#bridgeprs-output","text":"The main output is in the folder out/prs-combined_EAS-EUR/ . First view the output summary plot evince out/prs-combined_AFR-EUR/bridge.afr-eur.prs-combined.result.pdf on a Mac use open instead of evince . The barplot at the top shows the varaince explained (R2) by the four PRS models BridgePRS estimates. The weighted model is BridgePRS estimated \"best\" PRS.","title":"BridgePRS output"},{"location":"workshop_practical_clive.docx/#the-models-estimated-by-bridgeprs","text":"The three separate target population PRS estimated by BridgePRS are: * Stage2 model -- estimated using target population data with prior effect-size distribution from the base (European) population * Stage 1 model -- estimated using only the target (Non-European) data * Stage1+2 model -- estimated using both stage 1 and stage 2 models Each of these three models are given weights corresponding to how well they fit the test data. These weights are then used to combine the PRS to give the single weighted combined PRS. The weighted combined PRS should typically be used. The models, stage1, stage2 and stage1+2, should not be used unless users have a strong prior belief that a particular model is better. The hypotheses of the three models are: * Stage 2 model reflects the belief that the target population GWAS is only informative in conjugtion with the base population GWAS. * Stage 1 model reflects the belief that the target population GWAS is informative and the base population GWAS gives no addition information. * Stage 1+2 model reflects the belief both the base and target population GWAS contribute independent information. Look at the following output file cat out/prs-combined_AFR-EUR/EAS_weighted_combined_var_explained.txt","title":"The models estimated by BridgePRS"},{"location":"workshop_practical_clive.docx/#question","text":"Which plot in the summary plot was constructed from this output file? How do the Manhattan plots of the base and target populations compare? EAS_weighted_combined_preds.dat has PRS predictions for samples in the validation data using all four models: stage1, stage2, stage1+2 and weighted. EAS_weighted_combined_snp_weights.dat has the SNP weights for the combined to allow this model to be applied to other samples.","title":"Question?"},{"location":"workshop_practical_clive.docx/#using-bridgeprs-without-target-summary-statistics","text":"Often GWAS summary statistics are only available in one population. BridgePRS can use these summary statistics and optimise them to estimate a PRS for another target population given individual level from the target population. Here is an example using the data/eur_eas.config config file ./bridgePRS prs-single run -o out_single/ --config_files data/eur_eas.config --phenotype y --cores 10 Look at data/eur_eas.config .","title":"Using BridgePRS without target summary statistics"},{"location":"workshop_practical_clive.docx/#questions_1","text":"What GWAS summary data is used? What test data is used for model optimisation? What validation data is used? Results of interest are written to the folder out_single/prs-single_EAS/quantify/ . Model performance is shown in the file EAS_quantify_var_explained.txt and plotted in .... See how these results compare with the previous analysis which included EAS GWAS summary statistics. cat out_single/prs-single_EAS/quantify/EAS_quantify_var_explained.txt cat out/prs-combined_EAS-EUR/EAS_weighted_combined_var_explained.txt This single summary statistic analysis is equilvant to the stage 2 analysis previously but with all the weight on the EUR prior.","title":"Questions?"},{"location":"workshop_practical_clive.docx/#question_1","text":"How does prediction using only EUR summary statistics compare with those which include information from the EAS summary statistics?","title":"Question?"},{"location":"workshop_practical_clive.docx/#further-analysis-with-bridgeprs","text":"","title":"Further analysis with BridgePRS"},{"location":"workshop_practical_clive.docx/#african-analysis","text":"Run BridgePRS again to estimate PRS in Africans using afr.config . Note, you should also change the command line fst argument to match the Fst between Africans and Europeans, use 0.15.","title":"African analysis"},{"location":"workshop_practical_clive.docx/#qustions","text":"Which population, EAS or AFR, has the best prediction? What are the reasons for the differences in prediction between the populations?","title":"Qustions?"},{"location":"workshop_practical_clive.docx/#analyses-with-other-gwas-summary-statistics","text":"For each population the config files contain commented out links to GWAS summary statistics of the same phenotype using half the same size: 40k for EUR and 10k for both EAS and AFR. Edit eas.config to use the EAS 10k GWAS summary statistics. To run the analysis write results to a new output directory e.g. out_half_target . Run the similar analysis for African samples by editing afr.config . Compare with previous results using the 10k EAS and EAS GWAS. Compare EAS and AFR results. Check you've run the analyses using the correct GWAS summary statistics, e.g. less less out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log less less out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log or grep Sumstats out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log grep Sumstats out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log If you have made a mistake, correct and run again using the --restart flag which deletes the previously genereated results.","title":"Analyses with other GWAS summary statistics"},{"location":"workshop_practical_clive.docx/#qustions_1","text":"How has using the less well powered EAS and AFR GWAS affected the predictive accuracy of the BridgePRS models? How do AFR and EAS results compare?","title":"Qustions?"},{"location":"workshop_practical_clive.docx/#analyses-with-smaller-eur-gwas-summary-statistics","text":"Edit the config files again to run analyses using the 40k EUR GWAS (i.e. EUR_half ) and the 20k EAS and AFR GWAS and write to results to a new directory e.g. out_half_eur .","title":"Analyses with smaller EUR GWAS summary statistics"},{"location":"workshop_practical_clive.docx/#qustions_2","text":"How has using the less well powered EUR GWAS affected the predictive accuracy of the BridgePRS models? How do AFR and EAS results compare?","title":"Qustions?"},{"location":"workshop_practical_clive.docx/#using-bidgeprs-snp-weights","text":"The SNP weights in EAS_weighted_combined_snp_weights.dat can be used to make predictions in other samples for which we have overlapping genotype data. We demonstrate this using plink and data in data/pop_EAS/genotypes/ . The genotype data is split by chromosome, therefore predictions are estimated for each chromosome separately and then combined. The following bash commands estimate the per chromosome predictions using plink, we first make a directory to write these predictions to mkdir out/preds for chr in {1..22} do plink --score out/prs-combined_EAS-EUR/EAS_weighted_combined_snp_weights.dat 1 2 4 list-variants \\ --bfile data/pop_EAS/genotypes/chr$chr \\ --out out/preds/EAS_chr$chr done We then read these predictions into R to combine R library(data.table) tmp <- fread(paste0('out1/preds/EAS_chr1.profile')) pred <- data.frame( tmp$IID, tmp$SCORESUM ) colnames(pred) <- c('IID','Score') for( chr in 2:22 ){ tmp <- fread(paste0('out1/preds/EAS_chr',chr,'.profile')) pred[,2] <- pred[,2] + tmp$SCORESUM } # Check predictions are the same as those produced directly by BridgePRS valid <- fread('out1/prs-combined_EAS-EUR/EAS_weighted_combined_preds.dat') # Match IDs ptr <- match( valid$IID, pred$IID ) plot( pred$Score[ptr], valid$Weighted ) Predictions are the same +/- rounding error and a constant.","title":"Using BidgePRS SNP weights"},{"location":"tmp/workshop_practical_paul.docx/","text":"Introduction to Polygenic Risk Scores Table of Contents Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Data Structure You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this command - cd ~/Downloads wget https://wcs_data_transfer.cog.sanger.ac.uk/Day2_Base_Data.zip You may also download it via dropbox if the above fails with this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice_linux/PRSice Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary. Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres \u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status. Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis. Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top Introduction to Polygenic Risk Scores Table of Contents Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Data Structure You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2),the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice/PRSice_linux -h Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary. Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres \u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status. Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis. Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Day 1 (AM)"},{"location":"tmp/workshop_practical_paul.docx/#introduction-to-polygenic-risk-scores","text":"","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp/workshop_practical_paul.docx/#table-of-contents","text":"Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents","title":"Table of Contents"},{"location":"tmp/workshop_practical_paul.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp/workshop_practical_paul.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp/workshop_practical_paul.docx/#data-structure","text":"You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this command - cd ~/Downloads wget https://wcs_data_transfer.cog.sanger.ac.uk/Day2_Base_Data.zip You may also download it via dropbox if the above fails with this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents","title":"Data Structure"},{"location":"tmp/workshop_practical_paul.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp/workshop_practical_paul.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents","title":"Understanding GWAS Summary Statistics"},{"location":"tmp/workshop_practical_paul.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents","title":"Matching the Base and Target Data sets"},{"location":"tmp/workshop_practical_paul.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp/workshop_practical_paul.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents","title":"Performing Clumping"},{"location":"tmp/workshop_practical_paul.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds.","title":"P-Value Thresholding"},{"location":"tmp/workshop_practical_paul.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice_linux/PRSice Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp/workshop_practical_paul.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp/workshop_practical_paul.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents","title":"High Resolution Scoring"},{"location":"tmp/workshop_practical_paul.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents","title":"Stratifying Samples by PRS"},{"location":"tmp/workshop_practical_paul.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary.","title":"Case Control Studies"},{"location":"tmp/workshop_practical_paul.docx/#rscript-prsice_linuxprsicer-prsice-prsice_linuxprsice_linux-base-base_datacadaddtxt-target-target_datatar-snp-markername-a1-effect_allele-a2-noneffect_allele-chr-chr-bp-bp_hg19-stat-beta-beta-pvalue-p_dgc-pheno-target_datacadpheno-binary-target-t-out-resultscadhighres","text":"\u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status.","title":"Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres\n"},{"location":"tmp/workshop_practical_paul.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis.","title":"Cross-Trait Analysis"},{"location":"tmp/workshop_practical_paul.docx/#rscript-prsice_linuxprsicer-prsice-prsice_linuxprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datacadpheno-binary-target-t-out-resultscrosshighres","text":"Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres\n"},{"location":"tmp/workshop_practical_paul.docx/#introduction-to-polygenic-risk-scores_1","text":"","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp/workshop_practical_paul.docx/#table-of-contents_1","text":"Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents","title":"Table of Contents"},{"location":"tmp/workshop_practical_paul.docx/#key-learning-outcomes_1","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp/workshop_practical_paul.docx/#resources-you-will-be-using_1","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp/workshop_practical_paul.docx/#data-structure_1","text":"You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents","title":"Data Structure"},{"location":"tmp/workshop_practical_paul.docx/#introduction_1","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp/workshop_practical_paul.docx/#understanding-gwas-summary-statistics_1","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents","title":"Understanding GWAS Summary Statistics"},{"location":"tmp/workshop_practical_paul.docx/#matching-the-base-and-target-data-sets_1","text":"The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents","title":"Matching the Base and Target Data sets"},{"location":"tmp/workshop_practical_paul.docx/#linkage-disequilibrium-in-prs-analyses_1","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp/workshop_practical_paul.docx/#performing-clumping_1","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents","title":"Performing Clumping"},{"location":"tmp/workshop_practical_paul.docx/#p-value-thresholding_1","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds.","title":"P-Value Thresholding"},{"location":"tmp/workshop_practical_paul.docx/#height-prs-using-gw-significant-snps-only_1","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2),the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice/PRSice_linux -h Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp/workshop_practical_paul.docx/#height-prs-across-multiple-p-value-thresholds_1","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp/workshop_practical_paul.docx/#high-resolution-scoring_1","text":"If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents","title":"High Resolution Scoring"},{"location":"tmp/workshop_practical_paul.docx/#stratifying-samples-by-prs_1","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents","title":"Stratifying Samples by PRS"},{"location":"tmp/workshop_practical_paul.docx/#case-control-studies_1","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary.","title":"Case Control Studies"},{"location":"tmp/workshop_practical_paul.docx/#rscript-prsiceprsicer-prsice-prsiceprsice_linux-base-base_datacadaddtxt-target-target_datatar-snp-markername-a1-effect_allele-a2-noneffect_allele-chr-chr-bp-bp_hg19-stat-beta-beta-pvalue-p_dgc-pheno-target_datacadpheno-binary-target-t-out-resultscadhighres","text":"\u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status.","title":"Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres\n"},{"location":"tmp/workshop_practical_paul.docx/#cross-trait-analysis_1","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis.","title":"Cross-Trait Analysis"},{"location":"tmp/workshop_practical_paul.docx/#rscript-prsiceprsicer-prsice-prsiceprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datacadpheno-binary-target-t-out-resultscrosshighres","text":"Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres\n"},{"location":"tmp/workshop_practical_tade/","text":"Population Genetics And Ancestry Analysis Table of Contents Key Learning Outcomes Practical Data A Portability Problem Population Genetics Basics Dimensional Reduction: PCA Key Learning Outcomes After completing this practical, you should be able to: Run mixed ancestry PRS and understand the PRS Portability Problem Understand principle component analysis and dimensional reduction Understand basic population genetics and know how to analyze ancestry groups. Understand the challenges and limitations of applying PRS in populations with diverse genetic backgrounds. Practical Specific Data The multi-ancestry data/software required for this practical can be downloaded here. Please download, unzip the data, and move it into a suitable directory on your laptop. After doing this you should see the following directories: exercise1: Data/Code to run multi-ancestry PRS exercise2: Data/Code for principal component analysis exercise3: Data/Code for population genetics analysis Ex 1: Portability Problem The first exercise of this practical takes place in the folder exercise1 . Once inside the folder you should see code and data directories. Looking in the data directory by typing the following command will reveal: ls data/* \ud83c\uddea\ud83c\uddfa: EURO_GWAS.assoc (European Ancestry GWAS Sumstats) \ud83c\uddec\ud83c\udde7: data/ukTarget (Genotype Phenotype data From a population from the UK.) \ud83c\uddef\ud83c\uddf5: data/japanTarget (Genotype Phenotype data from a population from Japan.) To start, run PRSice using the European GWAS and target data from the UK: ./code/PRSice --base data/EURO_GWAS.assoc --target data/ukTarget/ukTarget --binary-target F --out ukRun Verify that this command produce a file called \"ukRun.best\" that contains individual prs-scores in fourth column. This file can compared to the file data/ukTarget/ukTarget.pheno which contains phenotype-values in the third column. \ud83d\udea8 OPTIONAL-CHALLENGE \ud83d\udea8 Using R, Python, or another program, consider calculating the correlation between the PRS and phenotype data in the two files? First read the pseudocode and see if you can follow the strategy. Then give it a try or read the following solutions and make sure that you understand them. Notice the differences in similarities in the programming languages. Hints #1) Step1: Read Both Files in. prs_data = read('ukRun.best') pheno_data = read(\"data/ukTarget/ukTarget.pheno\") #2) Step2: Extract the correct Column from each file . prs_vals = extract_from(prs_data, column 4) pheno_vals = extract_from(pheno_data, column 3) #3) Step3: Calculate the correlation. R2 = calculate_R2_from_data(prs_vals, pheno_vals) Solution (R) R # read-in prs-file prs <- read.table(\"ukRun.best\", header = TRUE, sep = \"\", stringsAsFactors = FALSE) prs.data <- prs1[,4] # read-in pheno-file pheno <- read.table(\"data/ukTarget/ukTarget.pheno\", header = TRUE, sep = \"\", stringsAsFactors = FALSE) pheno.data <- pheno[,3] # Create DataFrame combined_data <- data.frame( x = prs.data, y = pheno.data) # Fit a linear model to the data model <- lm(y ~ x, data = combined_data) # Calculate the R-squared value r_squared <- summary(model)$r.squared # return R2 print(r_squared) Solution (Python) python3 # read-in prs-file: with open('ukRun.best') as F: prs_vals = [float(line.split()[-1]) for i,line in enumerate(F.readlines()) if i > 0] # read-in pheno-file: with open('data/ukTarget/ukTarget.pheno') as F: pheno_vals = [float(line.split()[-1]) for i,line in enumerate(F.readlines()) if i > 0] # calculate correlation prs_mean, pheno_mean = sum(prs_vals)/len(prs_vals), sum(pheno_vals)/len(pheno_vals) rTop = sum([(x-prs_mean)*(y-pheno_mean) for x,y in zip(prs_vals, pheno_vals)]) rBottom = (sum([(x-prs_mean)*(x-prs_mean) for x in prs_vals])**0.5) * (sum([(x-pheno_mean)*(x-pheno_mean) for x in pheno_vals])**0.5) # Return R2 R2 = (rTop/rBottom)*(rTop/rBottom) print(R2) After you feel confident about the code, please run the Rscript in the code directory to calculate the correlation and create a scatterplot using the UK PRS-result: Rscript --vanilla code/plot_prs_results.R data/ukTarget/ukTarget.pheno ukRun.best This will create a scatterplot file called: ukRunScatterplot.pdf . Verify that you can view it, and then type the commands below to reuse the European GWAS data and PRSice with the genotype-phenotype data from a Japan. After viewing the resulting scatterplot please answer the questions below. ./code/PRSice --base data/EURO_GWAS.assoc --target data/japanTarget/japanTarget --binary-target F --out japanRun Rscript --vanilla code/plot_prs_results.R data/japanTarget/japanTarget.pheno japanRun.best \u2753QUESTIONS: In the UK-result, what percent of variance in phenotype is explained by prs? Approximately 10%. In the Japan-result, what percent of variance in phenotype is explained by prs? Approximately 0%. Besides a difference in variance explained, do you notice any other differences? Less variance in PRS, a shift to the left. What is the name of the problem that refers to this drop in performance? The PRS Portability problem. What are some causes of the problem? 1. Differences in LD. 2. Differences in allele frequency. 3. Differences in environment. 4. Differences in population-structure. Back to Top 1000 Genomes Data Now that you have observed the PRS-portability problem in practice we are going to consider some analysis that can be used to provide a solution. Recall from the lecture that population structure and population assignment is often accomplished using principal components analysis (PCA) and that the primary population differences that drive the portability problem are difference in allele frequency and linkage disequilibrium. In the next exercise we will learn how to analyze and compare data from different populations and quantify linkage disequilibrium. In the final exercise we what PCA is and learn how it can be used to separate population data by recent ancestry. Both of these exercises use the 1000Genomes dataset which contains individuals from 26 different source populations from all five continents. Back to Top Ex 2: Population Genetics This exercise of this practical takes place in the folder exercise2 . Once inside the folder you should see code and data directories. Looking in the data directory by typing the following command will reveal: ls data/* \ud83c\udf0e: chr1-22.bed/bim/fam (Global Genotype Data) \ud83c\udff7\ufe0f: data/pop_info.pheno (Population specific annotation data) \ud83d\udcab: data/all_phase3.king.psam (Axillary Phase Data) Sample Sizes The first thing we would like to find out about this data is the number of individuals within each global superpopulation. Type the following command to query the number of European ancestry individuals in the downloaded dataset: grep -F \"EUR\" data/all_phase3.king.psam | wc -l Next, repeat the same command for East Asian, African, South Asian and Amerindian superpopulations, by inserting the relevant ancestry codes (EAS, AFR, SAS, AMR). \ud83d\uddd2\ufe0f Make note of how many individuals from each ancestry group are available. Number of Genetic Variants We do not need to use the full genome-wide data for this tutorial, only a small fraction of the 80 million total available variants. This provides a reliable approximation for the genomic analyses in this tutorial and importantly, reduces the computation time required to complete the tutorial. The following command derives the number of genetic variants on chromosomes 1 to chromosome 22 by counting the number of lines in the relevant (.bim) file, which contains a single variant per line. wc data/chr1-22.bim -l To quantify the number of single nucleotide polymorphisms (SNPs) we can ask plink to write a list of SNPs: ./code/plink --bfile data/chr1-22 --snps-only --write-snplist See the output file plink.snplist, which contains a list of all the SNPs in the dataset. Quantification of variable SNPs The rate at which a genetic variant occurs in a population is also known as its allelic frequency. Allele frequencies are shaped by evolutionary forces over a long period of time and hence can vary. This has implications for PRS research as the allelic frequency distribution of a disease or trait may vary between populations. It is possible to generate allele frequency statistics for each SNP in a given population, using the population information in the file pop_info.pheno. ./code/plink --bfile data/chr1-22 --snps-only --freq --within data/pop_info.pheno Population-stratified allele frequency results can be found in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: grep -F \"AFR\" plink.frq.strat | wc -l Compare the totals against number of SNPs which have minor allele frequencies greater than 0 (and hence are useful for statistical analysis). Do this for all 5 populations (EAS, EUR, SAS, EUR and AFR), using the code given below: grep -F \"AFR\" plink.frq.strat > freq_report.afr grep -F \"AMR\" plink.frq.strat > freq_report.amr grep -F \"EUR\" plink.frq.strat > freq_report.eur grep -F \"EAS\" plink.frq.strat > freq_report.eas grep -F \"SAS\" plink.frq.strat > freq_report.sas grep -F \"AFR\" plink.frq.strat | awk '$6 >0' freq_report.afr | wc -l grep -F \"EUR\" plink.frq.strat | awk '$6 >0' freq_report.eur | wc -l grep -F \"EAS\" plink.frq.strat | awk '$6 >0' freq_report.eas | wc -l grep -F \"AMR\" plink.frq.strat | awk '$6 >0' freq_report.amr | wc -l grep -F \"SAS\" plink.frq.strat | awk '$6 >0' freq_report.sas | wc -l Having compared the number of SNPs that show variation in each population, answer the following questions: \u2753QUESTIONS: Which populations have the largest number (density) of SNPs that can be considered polymorphic? AFR and AMR. What do you think is the significance of the observed population order? Human evolution and migration. Investigation Missingness Genotype missingness, caused by genotyping failure can potentially lead to biased allele frequency estimation. Therefore missingness needs to be excluded as a possible source of bias when calculating allele frequency differences. ./code/plink --bfile data/chr1-22 --missing --within data/pop_info.pheno The output file plink.lmiss provides a variant-based missing data report). Use the following code to query the number of genotyping failures based on the missingness information in the NMISS column: awk '$4 > 0' plink.lmiss | wc -l Cross Population Allele Frequency Comparisons Here we compare profiles of allele frequency across the five ancestral populations. To do this we will use the previously-generated output on minor allele frequencies per ancestry group (the file \"plink.frq.strat\"), using R: R-Code: Compare Allele Frequencies library(dplyr) library(ggplot2) freq <-read.table(\"plink.frq.strat\", header =T) plotDat <- freq %>% mutate(AlleleFrequency = cut(MAF, seq(0, 1, 0.25))) %>% group_by(AlleleFrequency, CLST) %>% summarise(FractionOfSNPs = n()/nrow(freq) * 100) ggplot(na.omit(plotDat),aes(AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST)) + geom_line() + scale_y_continuous(limits = c(0, 12)) + ggtitle(\"Distribution of allele frequency across genome\") \u2753QUESTIONS: How are the allele frequencies in AFR distinguishable from the other global reference groups? Greater diversity. Linkage disequilibrium versus genomic distance, across populations We will now perform pairwise LD comparisons between genome-wide snps in order to show cross-populations relationships between genomic distance and LD strength. We derive information on pairwise R2 between all SNPs: ./code/plink --bfile data/chr1-22 --keep-cluster-names AFR --within data/pop_info.pheno --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 2500 --threads 30 --out chr1-22.AFR Repeat this step for all five 1000Genomes populations. Output files containing LD info for all pairwise SNPs, have a \u2018.ld\u2019 su\ufb03x Next, create a summary file containing the base-pair distance between each pair and the corresponding r2 value. The following example shows this for AFR and EUR populations only, as just these populations will be used in the plot. cat chr1-22.AFR.ld | sed 1,1d | awk -F \" \" 'function abs(v) {return v < 0 ? -v : v}BEGIN{OFS=\"\\t\"}{print abs($5-$2),$7}' | sort -k1,1n > chr1-22.AFR.ld.summary cat chr1-22.EUR.ld | sed 1,1d | awk -F \" \" 'function abs(v) {return v < 0 ? -v : v}BEGIN{OFS=\"\\t\"}{print abs($5-$2),$7}' | sort -k1,1n > chr1-22.EUR.ld.summary LD decay versus chromosomal distance To visualise LD behaviour as a function of chromosomal distance we can carry out the following commands from within an R terminal: R-Code: Visualize LD Behavior # need to add additional functionality to be able to # carry out the necessary data transformation (dplyr) # and manipulation of character strings (stringr ) install.packages(\"dplyr\") install.packages(\"stringr\") install.packages(\"ggplot2\") library(dplyr) library(stringr) library(ggplot2) # Next we will (1) load the previously generated information on pairwise LD, # Categorize distances into intervals of fixed length (100KB), # Compute mean and median r2 within blocks # Obrain mid-points for each distance interval dfr<-read.delim(\"chr1-22.AFR.ld.summary\",sep=\"\",header=F,check.names=F, stringsAsFactors=F) colnames(dfr)<-c(\"dist\",\"rsq\") dfr$distc<-cut(dfr$dist,breaks=seq(from=min(dfr$dist)-1,to=max(dfr$dist)+1,by=100000)) dfr1<-dfr %>% group_by(distc) %>% summarise(mean=mean(rsq),median=median(rsq)) dfr1 <- dfr1 %>% mutate(start=as.integer(str_extract(str_replace_all(distc,\"[\\\\(\\\\)\\\\[\\\\]]\",\"\"),\"^[0-9-e+.]+\")), end=as.integer(str_extract(str_replace_all(distc,\"[\\\\(\\\\)\\\\[\\\\]]\",\"\"),\"[0-9-e+.]+$\")), mid=start+((end-start)/2)) # The preceding code block should be repeated for the file chr1-22._EUR.ld.summary. # When doing so, the output object dfr1 on lines 4 and 5 should be renamed dfr2 to prevent the object df1 being over-written. # Finally, we can plot LD decay for AFR and EUR reference populations in a single graph: ggplot()+ geom_point(data=dfr1,aes(x=start,y=mean),size=0.4,colour=\"grey20\")+ geom_line(data=dfr1,aes(x=start,y=mean),size=0.3,alpha=0.5,colour=\"grey40\")+ labs(x=\"Distance (Megabases)\",y=expression(LD~(r^{2})))+ scale_x_continuous(breaks=c(0,2*10^6,4*10^6,6*10^6,8*10^6),labels=c(\"0\",\"2\",\"4\",\"6\",\"8\"))+ theme_bw() \u2753QUESTIONS: What differences do you observe in terms of LD decay between AFR and EUR genomes? Greater decay in AFR How is this likely to impact the transferability of PRS performance between the two populations? Negatively. Distribution of LD-block length The next set of scripts will allow us to visualise the distribution of LD block length across different 1000Genomes populations. ./code/plink --bfile chr1-22 --keep-cluster-names AFR --blocks no-pheno-req no-small-max-span --blocks-max-kb 250 --within data/pop_info.pheno --threads 30 --out AFR The \u201c\u2013block\" flag estimates haplotype blocks using the same block definition implemented by the software Haploview. The default setting for the flag --blocks-max-kb only considers pairs of variants that are within 200 kilobases of each other. The output file from the above command is a .blocks file. Use the same code to generate output for EUR, EAS, SAS and AMR populations (as it is not possible to generate population-specific information using the --within flag). Then, in R: R-Code: Load each of the 5 datasets and set column names to lower case. dfr.afr <- read.delim(\"AFR.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.afr) <- tolower(colnames(dfr.afr)) dfr.eur <- read.delim(\"EUR.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.eur) <- tolower(colnames(dfr.eur)) dfr.amr <- read.delim(\"AMR.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.amr) <- tolower(colnames(dfr.amr)) dfr.sas <- read.delim(\"SAS.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.sas) <- tolower(colnames(dfr.sas)) dfr.eas <- read.delim(\"EAS.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.eas) <- tolower(colnames(dfr.eas)) Then plot the data: plot (density(dfr.afr$kb), main=\"LD block length distribution\", ylab=\"Density\",xlab=\"LD block length (Kb)\" ) lines (density(dfr.eur$kb), col=\"blue\") lines (density(dfr.eas$kb), col=\"red\") lines (density(dfr.amr$kb), col=\"purple\") lines (density(dfr.sas$kb), col=\"green\") legend(\"topright\",c(\"AFR\",\"EAS\",\"EUR\",\"SAS\",\"AMR\"), fill=c(\"black\",\"red\",\"blue\",\"green\",\"purple\")) \u2753QUESTIONS: What are the main features of this plot? How do you interpret them? Open ended Back to Top Ex 3: PCA Principle Component Analysis is a useful technique that allows researchers to visualize high dimensional data in lower space by rotating the axes in such a way that the lower dimensions (or components) maximize the total variance explained. In statistical genetics this involves \"rotating\" million-dimensional data - something that is very hard to visualize! For this reason, we begin with a simpler exercise. For the following three two dimensional shapes, spend some time identifying the principle components or sketching the line across for which variance is maximized. Check your answers below: \u2753QUESTIONS: What line represents the principle component for the first shape? The line 4/3(x) + y What line represents the principle component for the second shape? The line x+y. What line represents the principle component for the third shape? The X and Y axis already maximize the variance. Below you can view the shapes in principal component space. Now that we understand how PCA works in two dimensions we will consider a higher dimensional example. In the three dimensional space below, see if you can visualize a plane that maximizes the variance across two dimensions: Did you get it right? If so, realize that this is equivalent to what we do in genetics - we find rotate the data through millions of dimensions of space to find the plane that maximizes the variance in two dimensions: To run PCA with real data please enter the exercise2 directory, and type the following command to run PCA on the 1000 Genome data: plink --bfile data/chr1-22 --indep-pairwise 250 25 0.1 --maf 0.1 --threads 30 --out chr1-22.ldpruned_all_1kgv2 plink --bfile data/chr1-22 --extract chr1-22.ldpruned_all_1kgv2.prune.in --pca --threads 30 This will generate the principal components that maximize the variance in the data. To plot the result run the following commands from with an R-terminal: R-Code: Generate a PCA Plot require('RColorBrewer') options(scipen=100, digits=3) eigenvec <- read.table('plink.eigenvec', header = F, skip=0, sep = ' ') rownames(eigenvec) <- eigenvec[,2] eigenvec <- eigenvec[,3:ncol(eigenvec)] colnames(eigenvec) <- paste('Principal Component ', c(1:20), sep = '') PED <- read.table(\"data/all_phase3.king.psam\", header = TRUE, skip = 0, sep = '\\t') PED <- PED[which(PED$IID %in% rownames(eigenvec)), ] PED <- PED[match(rownames(eigenvec), PED$IID),] PED$Population <- factor(PED$Population, levels=c(\"ACB\",\"ASW\",\"ESN\",\"GWD\",\"LWK\",\"MSL\",\"YRI\",\"CLM\",\"MXL\",\"PEL\",\"PUR\",\"CDX\",\"CHB\",\"CHS\",\"JPT\",\"KHV\",\"CEU\",\"FIN\",\"GBR\",\"IBS\",\"TSI\",\"BEB\",\"GIH\",\"ITU\",\"PJL\",\"STU\")) col <- colorRampPalette(c(\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"forestgreen\",\"forestgreen\",\"forestgreen\",\"forestgreen\",\"grey\",\"grey\",\"grey\",\"grey\",\"grey\", \"royalblue\",\"royalblue\",\"royalblue\",\"royalblue\",\"royalblue\",\"black\",\"black\",\"black\",\"black\",\"black\"))(length(unique(PED$Population)))[factor(PED$Population)] project.pca <- eigenvec par(mar = c(5,5,5,5), cex = 2.0,cex.main = 7, cex.axis = 2.75, cex.lab = 2.75, mfrow = c(1,2)) plot(project.pca[,1], project.pca[,2], type = 'n', main = 'A', adj = 0.5, xlab = 'First component', ylab = 'Second component', font = 2, font.lab = 2) points(project.pca[,1], project.pca[,2], col = col, pch = 20, cex = 2.25) legend('bottomright', bty = 'n', cex = 3.0, title = '', c('AFR', 'AMR', 'EAS', 'EUR', 'SAS'), fill = c('yellow', 'forestgreen', 'grey', 'royalblue', 'black')) plot(project.pca[,1], project.pca[,3], type=\"n\", main=\"B\", adj=0.5, xlab=\"First component\", ylab=\"Third component\", font=2, font.lab=2) points(project.pca[,1], project.pca[,3], col=col, pch=20, cex=2.25) \u2753QUESTIONS: What is distinct about the PC projects of the AMR group relative to other populations? Greater Distance, Overlap. Why does this occur? What does it tell us about ancestry of this group? Suggest recent admixture?","title":"Day 1 (PM)"},{"location":"tmp/workshop_practical_tade/#population-genetics-and-ancestry-analysis","text":"","title":"Population Genetics And Ancestry Analysis"},{"location":"tmp/workshop_practical_tade/#table-of-contents","text":"Key Learning Outcomes Practical Data A Portability Problem Population Genetics Basics Dimensional Reduction: PCA","title":"Table of Contents"},{"location":"tmp/workshop_practical_tade/#key-learning-outcomes","text":"After completing this practical, you should be able to: Run mixed ancestry PRS and understand the PRS Portability Problem Understand principle component analysis and dimensional reduction Understand basic population genetics and know how to analyze ancestry groups. Understand the challenges and limitations of applying PRS in populations with diverse genetic backgrounds.","title":"Key Learning Outcomes"},{"location":"tmp/workshop_practical_tade/#ex-1-portability-problem","text":"The first exercise of this practical takes place in the folder exercise1 . Once inside the folder you should see code and data directories. Looking in the data directory by typing the following command will reveal: ls data/* \ud83c\uddea\ud83c\uddfa: EURO_GWAS.assoc (European Ancestry GWAS Sumstats) \ud83c\uddec\ud83c\udde7: data/ukTarget (Genotype Phenotype data From a population from the UK.) \ud83c\uddef\ud83c\uddf5: data/japanTarget (Genotype Phenotype data from a population from Japan.) To start, run PRSice using the European GWAS and target data from the UK: ./code/PRSice --base data/EURO_GWAS.assoc --target data/ukTarget/ukTarget --binary-target F --out ukRun Verify that this command produce a file called \"ukRun.best\" that contains individual prs-scores in fourth column. This file can compared to the file data/ukTarget/ukTarget.pheno which contains phenotype-values in the third column. \ud83d\udea8 OPTIONAL-CHALLENGE \ud83d\udea8 Using R, Python, or another program, consider calculating the correlation between the PRS and phenotype data in the two files? First read the pseudocode and see if you can follow the strategy. Then give it a try or read the following solutions and make sure that you understand them. Notice the differences in similarities in the programming languages. Hints #1) Step1: Read Both Files in. prs_data = read('ukRun.best') pheno_data = read(\"data/ukTarget/ukTarget.pheno\") #2) Step2: Extract the correct Column from each file . prs_vals = extract_from(prs_data, column 4) pheno_vals = extract_from(pheno_data, column 3) #3) Step3: Calculate the correlation. R2 = calculate_R2_from_data(prs_vals, pheno_vals) Solution (R) R # read-in prs-file prs <- read.table(\"ukRun.best\", header = TRUE, sep = \"\", stringsAsFactors = FALSE) prs.data <- prs1[,4] # read-in pheno-file pheno <- read.table(\"data/ukTarget/ukTarget.pheno\", header = TRUE, sep = \"\", stringsAsFactors = FALSE) pheno.data <- pheno[,3] # Create DataFrame combined_data <- data.frame( x = prs.data, y = pheno.data) # Fit a linear model to the data model <- lm(y ~ x, data = combined_data) # Calculate the R-squared value r_squared <- summary(model)$r.squared # return R2 print(r_squared) Solution (Python) python3 # read-in prs-file: with open('ukRun.best') as F: prs_vals = [float(line.split()[-1]) for i,line in enumerate(F.readlines()) if i > 0] # read-in pheno-file: with open('data/ukTarget/ukTarget.pheno') as F: pheno_vals = [float(line.split()[-1]) for i,line in enumerate(F.readlines()) if i > 0] # calculate correlation prs_mean, pheno_mean = sum(prs_vals)/len(prs_vals), sum(pheno_vals)/len(pheno_vals) rTop = sum([(x-prs_mean)*(y-pheno_mean) for x,y in zip(prs_vals, pheno_vals)]) rBottom = (sum([(x-prs_mean)*(x-prs_mean) for x in prs_vals])**0.5) * (sum([(x-pheno_mean)*(x-pheno_mean) for x in pheno_vals])**0.5) # Return R2 R2 = (rTop/rBottom)*(rTop/rBottom) print(R2) After you feel confident about the code, please run the Rscript in the code directory to calculate the correlation and create a scatterplot using the UK PRS-result: Rscript --vanilla code/plot_prs_results.R data/ukTarget/ukTarget.pheno ukRun.best This will create a scatterplot file called: ukRunScatterplot.pdf . Verify that you can view it, and then type the commands below to reuse the European GWAS data and PRSice with the genotype-phenotype data from a Japan. After viewing the resulting scatterplot please answer the questions below. ./code/PRSice --base data/EURO_GWAS.assoc --target data/japanTarget/japanTarget --binary-target F --out japanRun Rscript --vanilla code/plot_prs_results.R data/japanTarget/japanTarget.pheno japanRun.best \u2753QUESTIONS: In the UK-result, what percent of variance in phenotype is explained by prs? Approximately 10%. In the Japan-result, what percent of variance in phenotype is explained by prs? Approximately 0%. Besides a difference in variance explained, do you notice any other differences? Less variance in PRS, a shift to the left. What is the name of the problem that refers to this drop in performance? The PRS Portability problem. What are some causes of the problem? 1. Differences in LD. 2. Differences in allele frequency. 3. Differences in environment. 4. Differences in population-structure. Back to Top","title":"Ex 1: Portability Problem"},{"location":"tmp/workshop_practical_tade/#ex-2-population-genetics","text":"This exercise of this practical takes place in the folder exercise2 . Once inside the folder you should see code and data directories. Looking in the data directory by typing the following command will reveal: ls data/* \ud83c\udf0e: chr1-22.bed/bim/fam (Global Genotype Data) \ud83c\udff7\ufe0f: data/pop_info.pheno (Population specific annotation data) \ud83d\udcab: data/all_phase3.king.psam (Axillary Phase Data)","title":"Ex 2: Population Genetics"},{"location":"tmp/workshop_practical_tade/#ex-3-pca","text":"Principle Component Analysis is a useful technique that allows researchers to visualize high dimensional data in lower space by rotating the axes in such a way that the lower dimensions (or components) maximize the total variance explained. In statistical genetics this involves \"rotating\" million-dimensional data - something that is very hard to visualize! For this reason, we begin with a simpler exercise. For the following three two dimensional shapes, spend some time identifying the principle components or sketching the line across for which variance is maximized. Check your answers below: \u2753QUESTIONS: What line represents the principle component for the first shape? The line 4/3(x) + y What line represents the principle component for the second shape? The line x+y. What line represents the principle component for the third shape? The X and Y axis already maximize the variance. Below you can view the shapes in principal component space. Now that we understand how PCA works in two dimensions we will consider a higher dimensional example. In the three dimensional space below, see if you can visualize a plane that maximizes the variance across two dimensions: Did you get it right? If so, realize that this is equivalent to what we do in genetics - we find rotate the data through millions of dimensions of space to find the plane that maximizes the variance in two dimensions: To run PCA with real data please enter the exercise2 directory, and type the following command to run PCA on the 1000 Genome data: plink --bfile data/chr1-22 --indep-pairwise 250 25 0.1 --maf 0.1 --threads 30 --out chr1-22.ldpruned_all_1kgv2 plink --bfile data/chr1-22 --extract chr1-22.ldpruned_all_1kgv2.prune.in --pca --threads 30 This will generate the principal components that maximize the variance in the data. To plot the result run the following commands from with an R-terminal: R-Code: Generate a PCA Plot require('RColorBrewer') options(scipen=100, digits=3) eigenvec <- read.table('plink.eigenvec', header = F, skip=0, sep = ' ') rownames(eigenvec) <- eigenvec[,2] eigenvec <- eigenvec[,3:ncol(eigenvec)] colnames(eigenvec) <- paste('Principal Component ', c(1:20), sep = '') PED <- read.table(\"data/all_phase3.king.psam\", header = TRUE, skip = 0, sep = '\\t') PED <- PED[which(PED$IID %in% rownames(eigenvec)), ] PED <- PED[match(rownames(eigenvec), PED$IID),] PED$Population <- factor(PED$Population, levels=c(\"ACB\",\"ASW\",\"ESN\",\"GWD\",\"LWK\",\"MSL\",\"YRI\",\"CLM\",\"MXL\",\"PEL\",\"PUR\",\"CDX\",\"CHB\",\"CHS\",\"JPT\",\"KHV\",\"CEU\",\"FIN\",\"GBR\",\"IBS\",\"TSI\",\"BEB\",\"GIH\",\"ITU\",\"PJL\",\"STU\")) col <- colorRampPalette(c(\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"forestgreen\",\"forestgreen\",\"forestgreen\",\"forestgreen\",\"grey\",\"grey\",\"grey\",\"grey\",\"grey\", \"royalblue\",\"royalblue\",\"royalblue\",\"royalblue\",\"royalblue\",\"black\",\"black\",\"black\",\"black\",\"black\"))(length(unique(PED$Population)))[factor(PED$Population)] project.pca <- eigenvec par(mar = c(5,5,5,5), cex = 2.0,cex.main = 7, cex.axis = 2.75, cex.lab = 2.75, mfrow = c(1,2)) plot(project.pca[,1], project.pca[,2], type = 'n', main = 'A', adj = 0.5, xlab = 'First component', ylab = 'Second component', font = 2, font.lab = 2) points(project.pca[,1], project.pca[,2], col = col, pch = 20, cex = 2.25) legend('bottomright', bty = 'n', cex = 3.0, title = '', c('AFR', 'AMR', 'EAS', 'EUR', 'SAS'), fill = c('yellow', 'forestgreen', 'grey', 'royalblue', 'black')) plot(project.pca[,1], project.pca[,3], type=\"n\", main=\"B\", adj=0.5, xlab=\"First component\", ylab=\"Third component\", font=2, font.lab=2) points(project.pca[,1], project.pca[,3], col=col, pch=20, cex=2.25) \u2753QUESTIONS: What is distinct about the PC projects of the AMR group relative to other populations? Greater Distance, Overlap. Why does this occur? What does it tell us about ancestry of this group? Suggest recent admixture?","title":"Ex 3: PCA"},{"location":"tmp/practical_docs_hidden/Day1a.docx/","text":"Polygenic Risk Score Analyses Workshop 2024 Day 1a: GWAS & relevant Statistics Introduction to Bash Most software in Bioinformatics and Statistical Genetics need to be run in a Unix environment (e.g. Linux or Mac OS) and most high-performance computer clusters run Unix systems. Therefore, although there are alternatives available on Windows (command line, Linux subsystems or Virtual Machines), it will be highly beneficial to become familiar with performing research in a Unix-only environment. Moving around the File System To begin our practical, please open up a \\\"terminal\\\" on your computer (on a Mac this is stored in Applications/Utilities/). We can change our directory using the following command: cd \\<Path>\\ where *\\ * is the path to the target directory. Some common usage of cd includes cd ~/ # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd XXX # will bring you to the XXX directory, so long as it is in the current directory As an example, we can move to the data directory by typing: cd data/ Looking at the Current Directory Next we can move into the ~/data/Day1a_Data/Day1a_Data folder (from the data/ folder type: cd Day1a_Data/Day1a_Data). We can list out the folder content by typing: ls For ls, there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size Counting Number of Lines in File We can also count the number of lines in a file with the following command (where *\\ * is the file of interest): wc -l <file> Often we would like to store the output of a command, which we can do by redirecting the output of the command to a file. For example, we can redirect the count of the GIANT_Height.txt to giant_count using the following command: wc -l GIANT_Height.txt > giant_count.txt Search File Content Another common task is to search for specific words or characters in a file (e.g. does this file contain our gene of interest?). This can be performed using the \"grep\" command as follows: grep <string> file For example, to check if the Single Nucleotide Polymorphism (SNP) rs10786427 is present in GIANT_Height.txt , we can do: grep rs10786427 GIANT_Height.txt In addition, grep allows us to check if patterns contained in one file can be found in another file. For example, if we want to extract a subset of samples from the phenotype file (e.g. extract the list of samples in Data/Day_1a/TAR.height ), we can do: grep -f Select.sample TAR.height An extremely useful feature of the terminal is chaining multiple commands into one command, which we call piping . For example, we can use piping to count the number of samples in Select.sample that were found in TAR.height in a single command, as follows: bash grep -f Select.sample TAR.height | wc -l Filtering and Reshu\ufb04ing Files A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new results file that only contains SNP rsIDs (column 1), allele frequencies (column 4) and P -values (column 7) as follows: awk '{ print $1,$4,$7}' GIANT_Height.txt > GIANT_Height_3cols.txt We can also use a \\\"conditional statement\\\" in awk to extract all significant [SNPs] from the results file, using the following command: awk '{if($7 < 5e-8) { print } }' GIANT_Height.txt > Significant_SNPs.txt Or the short form: awk '$7 < 5e-8{ print}' GIANT_Height.txt > Significant_SNPs.txt \"if( \\(7<5e-8)\" and \"\\) 7 < 5e-8\" tell awk to extract any rows with column 7 (the column containing P -value) with a value of smaller than 5e-8 and {print} means that we would like to print the entire row when this criterion is met. Introduction to R R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop. Basics If you are not using R Studio then you can type R in your terminal to run R in the terminal. ## Adding script to working dir cd ~/data/Day1a_Data/Day1a_Data wget https://raw.githubusercontent.com/WCSCourses/prs_2023/main/scripts/nagelkerke.R Working Directory When we start R , we will be working in a specific folder called the working directory . We can check the current/working directory we are in by typing: getwd() And we can change our working directory to the Practical folder by setwd(\"~/data/Day1a_Data/Day1a_Data\") Libraries Most functionality of R is organised in \\\"packages\\\" or \\\"libraries\\\". To access these functions, we will have to install and \\\"load\\\" these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Alternatively, we can import functions (e.g. that we have written) from an R script file on our computer. For example, you can load the Nagelkerke R2 function by typing source(\"nagelkerke.R\") And you are now able to use the Nagelkerke R2 function (we will use this function at the end of this worksheet). Variables in R You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\") Functions You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2) Plotting While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point() Regression Models In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial)) We will need the NagelkerkeR2 function to calculate the pseudo R2 for logistic model source(\"nagelkerke.R\") reg <- glm(y~x, family=binomial) Calculate the Nagelkerke R2 using the NagelkerkeR2 function NagelkerkeR2(reg)","title":"Polygenic Risk Score Analyses Workshop 2024"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#polygenic-risk-score-analyses-workshop-2024","text":"","title":"Polygenic Risk Score Analyses Workshop 2024"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#day-1a-gwas-relevant-statistics","text":"","title":"Day 1a: GWAS &amp; relevant Statistics"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#introduction-to-bash","text":"Most software in Bioinformatics and Statistical Genetics need to be run in a Unix environment (e.g. Linux or Mac OS) and most high-performance computer clusters run Unix systems. Therefore, although there are alternatives available on Windows (command line, Linux subsystems or Virtual Machines), it will be highly beneficial to become familiar with performing research in a Unix-only environment.","title":"Introduction to Bash"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#moving-around-the-file-system","text":"To begin our practical, please open up a \\\"terminal\\\" on your computer (on a Mac this is stored in Applications/Utilities/). We can change our directory using the following command: cd \\<Path>\\ where *\\ * is the path to the target directory. Some common usage of cd includes cd ~/ # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd XXX # will bring you to the XXX directory, so long as it is in the current directory As an example, we can move to the data directory by typing: cd data/","title":"Moving around the File System"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#looking-at-the-current-directory","text":"Next we can move into the ~/data/Day1a_Data/Day1a_Data folder (from the data/ folder type: cd Day1a_Data/Day1a_Data). We can list out the folder content by typing: ls For ls, there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size","title":"Looking at the Current Directory"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#counting-number-of-lines-in-file","text":"We can also count the number of lines in a file with the following command (where *\\ * is the file of interest): wc -l <file> Often we would like to store the output of a command, which we can do by redirecting the output of the command to a file. For example, we can redirect the count of the GIANT_Height.txt to giant_count using the following command: wc -l GIANT_Height.txt > giant_count.txt","title":"Counting Number of Lines in File"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#search-file-content","text":"Another common task is to search for specific words or characters in a file (e.g. does this file contain our gene of interest?). This can be performed using the \"grep\" command as follows: grep <string> file For example, to check if the Single Nucleotide Polymorphism (SNP) rs10786427 is present in GIANT_Height.txt , we can do: grep rs10786427 GIANT_Height.txt In addition, grep allows us to check if patterns contained in one file can be found in another file. For example, if we want to extract a subset of samples from the phenotype file (e.g. extract the list of samples in Data/Day_1a/TAR.height ), we can do: grep -f Select.sample TAR.height An extremely useful feature of the terminal is chaining multiple commands into one command, which we call piping . For example, we can use piping to count the number of samples in Select.sample that were found in TAR.height in a single command, as follows: bash grep -f Select.sample TAR.height | wc -l","title":"Search File Content"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#filtering-and-reshuffling-files","text":"A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new results file that only contains SNP rsIDs (column 1), allele frequencies (column 4) and P -values (column 7) as follows: awk '{ print $1,$4,$7}' GIANT_Height.txt > GIANT_Height_3cols.txt We can also use a \\\"conditional statement\\\" in awk to extract all significant [SNPs] from the results file, using the following command: awk '{if($7 < 5e-8) { print } }' GIANT_Height.txt > Significant_SNPs.txt Or the short form: awk '$7 < 5e-8{ print}' GIANT_Height.txt > Significant_SNPs.txt \"if( \\(7<5e-8)\" and \"\\) 7 < 5e-8\" tell awk to extract any rows with column 7 (the column containing P -value) with a value of smaller than 5e-8 and {print} means that we would like to print the entire row when this criterion is met.","title":"Filtering and Reshu\ufb04ing Files"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#introduction-to-r","text":"R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop.","title":"Introduction to R"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#basics","text":"If you are not using R Studio then you can type R in your terminal to run R in the terminal. ## Adding script to working dir cd ~/data/Day1a_Data/Day1a_Data wget https://raw.githubusercontent.com/WCSCourses/prs_2023/main/scripts/nagelkerke.R","title":"Basics"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#working-directory","text":"When we start R , we will be working in a specific folder called the working directory . We can check the current/working directory we are in by typing: getwd() And we can change our working directory to the Practical folder by setwd(\"~/data/Day1a_Data/Day1a_Data\")","title":"Working Directory"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#libraries","text":"Most functionality of R is organised in \\\"packages\\\" or \\\"libraries\\\". To access these functions, we will have to install and \\\"load\\\" these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Alternatively, we can import functions (e.g. that we have written) from an R script file on our computer. For example, you can load the Nagelkerke R2 function by typing source(\"nagelkerke.R\") And you are now able to use the Nagelkerke R2 function (we will use this function at the end of this worksheet).","title":"Libraries"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#variables-in-r","text":"You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\")","title":"Variables in R"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#functions","text":"You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2)","title":"Functions"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#plotting","text":"While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point()","title":"Plotting"},{"location":"tmp/practical_docs_hidden/Day1a.docx/#regression-models","text":"In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial)) We will need the NagelkerkeR2 function to calculate the pseudo R2 for logistic model source(\"nagelkerke.R\") reg <- glm(y~x, family=binomial) Calculate the Nagelkerke R2 using the NagelkerkeR2 function NagelkerkeR2(reg)","title":"Regression Models"},{"location":"tmp/practical_docs_hidden/Day2.docx/","text":"Introduction to Polygenic Risk Scores Table of Contents Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Data Structure You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this command - cd ~/Downloads wget https://wcs_data_transfer.cog.sanger.ac.uk/Day2_Base_Data.zip You may also download it via dropbox if the above fails with this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice_linux/PRSice Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary. Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres \u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status. Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis. Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp/practical_docs_hidden/Day2.docx/#introduction-to-polygenic-risk-scores","text":"","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp/practical_docs_hidden/Day2.docx/#table-of-contents","text":"Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents","title":"Table of Contents"},{"location":"tmp/practical_docs_hidden/Day2.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp/practical_docs_hidden/Day2.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp/practical_docs_hidden/Day2.docx/#data-structure","text":"You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this command - cd ~/Downloads wget https://wcs_data_transfer.cog.sanger.ac.uk/Day2_Base_Data.zip You may also download it via dropbox if the above fails with this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents","title":"Data Structure"},{"location":"tmp/practical_docs_hidden/Day2.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp/practical_docs_hidden/Day2.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents","title":"Understanding GWAS Summary Statistics"},{"location":"tmp/practical_docs_hidden/Day2.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents","title":"Matching the Base and Target Data sets"},{"location":"tmp/practical_docs_hidden/Day2.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp/practical_docs_hidden/Day2.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents","title":"Performing Clumping"},{"location":"tmp/practical_docs_hidden/Day2.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds.","title":"P-Value Thresholding"},{"location":"tmp/practical_docs_hidden/Day2.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice_linux/PRSice Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp/practical_docs_hidden/Day2.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp/practical_docs_hidden/Day2.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents","title":"High Resolution Scoring"},{"location":"tmp/practical_docs_hidden/Day2.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents","title":"Stratifying Samples by PRS"},{"location":"tmp/practical_docs_hidden/Day2.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary.","title":"Case Control Studies"},{"location":"tmp/practical_docs_hidden/Day2.docx/#rscript-prsice_linuxprsicer-prsice-prsice_linuxprsice_linux-base-base_datacadaddtxt-target-target_datatar-snp-markername-a1-effect_allele-a2-noneffect_allele-chr-chr-bp-bp_hg19-stat-beta-beta-pvalue-p_dgc-pheno-target_datacadpheno-binary-target-t-out-resultscadhighres","text":"\u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status.","title":"Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres\n"},{"location":"tmp/practical_docs_hidden/Day2.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis.","title":"Cross-Trait Analysis"},{"location":"tmp/practical_docs_hidden/Day2.docx/#rscript-prsice_linuxprsicer-prsice-prsice_linuxprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datacadpheno-binary-target-t-out-resultscrosshighres","text":"Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres\n"},{"location":"tmp/practical_docs_hidden/Day2b.docx/","text":"Advanced Polygenic Risk Score Analyses Day 2 - Afternoon Practical: Pathway PRS Analyses Table of Contents Introduction to gene set (pathway) PRS analysis Inputs required for gene-set PRS analysis Molecular Signatures Database MSigDB Other inputs that can be used for gene-set PRS using PRSet Exercise: Calculate gene-set PRS analysis Considerations when analysing and interpreting gene set PRSs Clumping for each gene set independently P-value thresholding in gene set PRS analyses Self-contained vs competitive testing Key Learning Outcomes After completing this practical, you should be able to: 1. Understand the motivation and rationale for calculating gene set PRS. 2. Identify the additional inputs required for gene set PRS analysis. 3. Calculate gene set based PRSs using PRSet. 5. Understand and interpret the outcomes of gene set PRSs and how they differ from genome-wide PRS. Data Structure You will find all practical materials in the data/Day_2b directory. Relevant materials that you should find at the start of the practical are: \ud83d\udcc2: Base_Data - GIANT_Height.txt, \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.covariate \ud83d\udcc1: Reference - Homo_sapiens.GRCh38.109.gtf.gz - Sets.gmt Introduction to gene set (pathway) PRS analysis Most PRS methods summarize genetic risk to a single number, based on the aggregation of an individual\u2019s genome-wide risk alleles. This approach does not consider the different contributions of the various biological processes that can influence complex diseases and traits. During this session, you will learn how to run a gene set (or pathway) based PRS analyses. The key difference between genome-wide PRS and gene set or pathway-based PRSs analyses is that, instead of aggregating the estimated effects of risk alleles across the entire genome, gene set PRSs aggregate risk alleles across as many gene sets as the user defines (Figure 1). Figure 1: The pathway polygenic risk score approach. Coloured boxes represent genes, lines link genes that are within the same genomic pathway. See full description here . \ud83d\udccc In this practical, we will go through some of the additional input requirements and considerations for the analysis of gene set PRS analysis, and will then calculate some gene set based PRS using PRSet . By aggregating PRS across multiple gene sets (or pathways), these PRS analyses will allow us to determine the genetic contribution made by each biological process in complex traits and diseases. For more information about the rationale and the software that we are going to use, please see the PRSet publication PRSet: Pathway-based polygenic risk score analyses and software . \u2753 Why is it useful to have polygenic scores measured across gene-sets (or pathways) for individuals? Isn\u2019t it su\ufb03cient to just obtain a ranking of gene-sets according to GWAS-signal enrichment (using gene set enrichment tools such as MAGMA or partitioned LDSC)? Inputs required for gene-set PRS analysis Summary statistics from GWAS, as well as individual level genotype and phenotype data are required to perform gene set PRS analyses. In this session, the following Base and Target data is used. Base data is publicly available. All Target data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Data Set Description Download Link Base from the GIANT Consortium GWAS of height on 253,288 individuals Link Simulated Target Data Individual-level phenotype and genotype files Data folder Additionally, to perform gene set PRS analyses, information about the gene sets for which we want to calculate the PRSs are required. In this tutorial, we will use as input gene-sets from the Molecular Signatures Database . However, PRSet also takes as input BED and SNP files . Data Set Description Download Link Ensembl Human Genome GTF file A file containing the coordinates for genes in the human genome. Used by PRSet to map the SNPs onto genic regions Link to Homo_sapiens.GRCh38.109.gtf.gz MSigDB Gene Sets File containing the gene-set information. Free registration required. Download link after registration Molecular Signatures Database MSigDB + General Transfer Format file MSigDB o\ufb00ers an excellent source of gene sets, including the hallmark genes, gene sets of di\ufb00erent biological processes, gene sets of di\ufb00erent oncogenic signatures etc. All gene sets from MSigDB follows the Gene Matrix Transposed file format (GMT), which consists of one line per gene set, each containing at least 3 column of data: Set A Description Gene 1 Gene 2 ... Set A Description Gene 1 Gene 2 ... \ud83d\udcac While you can read the GMT file using Excel, we recommend exploring these files using bash. You should be aware that Excel has a tendency to convert gene names into dates (e.g. SEPT9 to Sep-9) ** Have a look at the Reference/Sets.gmt file. ** \u2753 How many gene sets are there in the Reference/Sets.gmt file? \u2753 How many genes does the largest gene set contain? As GMT format does not contain the chromosomal location for each individual gene, an additional file (General Transfer Format file) is required to provide the chromosomal location such that SNPs can be mapped to genes. The General Transfer Format (GTF) file contains the chromosomal coordinates for each gene. It is a tab separated file and all fields except the last must contain a value. You can read the full format specification here . Two columns in the GTF file that might be of particular interest are: - Column 3: feature , which indicates what feature that line of GTF represents. This allows us to select or ignore features that are of interest. Column 9: attribute , which contains a semicolon-separated list of tag-value pairs (separated by a space), providing additional information about each feature. A key can be repeated multiple times. > \ud83d\udccc Tip , to parse column 9 and split the additional information in separate columns, you can use the following R code: library(data.table) library(magrittr) # Function to extract attributes from column 9 in GTF files: extract_attribute = function(input, attribute) { strsplit(input, split = \";\") %>% unlist %>% .[grepl(attribute, .)] %>% gsub(\"\\\"\", \"\", .) %>% strsplit(., split = \" \") %>% unlist %>% tail(n = 1) %>% return } gtf38 = fread(\"./Reference/Homo_sapiens.GRCh38.109.gtf.gz\") gtf38_parsed = gtf38 %>% # Select genes only, based on column 3 (feature) .[V3 == \"gene\"] %>% # Select genes located in autosomes .[`#!genebuild-last-updated 2022-11` %in% 1:22] %>% # Create colummns with Gene information .[, c(\"chr\", \"Gene_start\", \"Gene_end\", \"ensemblID\", \"Gene_Name\", \"Gene_biotype\") := data.table( `#!genebuild-last-updated 2022-11`, V4, V5, sapply(V9, extract_attribute, \"gene_id\"), sapply(V9, extract_attribute, \"gene_name\"), sapply(V9, extract_attribute, \"gene_biotype\"))] %>% # Filter the columns of interest .[, c(\"chr\", \"Gene_start\", \"Gene_end\", \"ensemblID\", \"Gene_Name\", \"Gene_biotype\")] ** Have a look at the Reference/Homo_sapiens.GRCh38.109.gtf.gz file. ** \u2753 Based on the column with information about the features, how many instances of feature = \"gene\" can you find ? \u2753 Based on the column with inforamtion about the attributes, how many protein-coding genes are there in the Reference/Homo_sapiens.GRCh38.109.gtf.gz file? Other inputs that can be used for gene set PRS using PRSet Browser Extensible Data BED Browser Extensible Data (BED) file (di\ufb00erent to the binary ped file from PLINK), is a file format to define genetic regions. It contains 3 required fields per line (chromosome, start coordinate and end coordinate) together with 9 additional optional field. A special property of BED is that it is a 0-based format, i.e. chromosome starts at 0, as opposed to the usual 1-based format such as the PLINK format. For example, a SNP on chr1:10000 will be represented as: 1 9999 10000 \u2753 How should we represent the coordinate of rs2980300 (chr1:785989) in BED format? List of SNPs Finally, PRSet also allow SNP sets, where the user have flexibility to decide what SNPs are included. The list of SNPs can have two different formats: - SNP list format, a file containing a single column of SNP ID. Name of the set will be the file name or can be provided using --snp-set File:Name - MSigDB format: Each row represent a single SNP set with the first column containing the name of the SNP set. Back to Top Exercise: Calculate gene set PRS analysis We are now ready to perform gene-set association analyses using PRSet. To perform the PRSet analysis and obtain the set based PRS and competitive P-value, simply provide the GTF file and the GMT file to PRSice and specify the number of permutation for competitive P-value calculation using the --set-perm option. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ ----> ATTENTION, the binary file may be different depending on the operative system (linux, mac, windows) --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --A1 Allele1 \\ --A2 Allele2 \\ --snp MarkerName \\ --pvalue p \\ --stat b \\ --beta \\ --binary-target F \\ --pheno Target_Data/TAR.height \\ --cov Target_Data/TAR.covariate \\ --out Height.set \\ --gtf Reference/Homo_sapiens.GRCh38.109.gtf.gz \\ --wind-5 5kb \\ --wind-3 1kb \\ --msigdb Reference/Sets.gmt \\ --multi-plot 10 \\ --set-perm 1000 > \ud83d\udccc If the --wind-5 and --wind-3 flag is not specified, PRSet will use the exact coordinates of each gene as the boundary. By specifying eg. --wind-5 5kb and --wind-3 1kb then the boundary of each gene will be extended 5 kb towards the 5\u2019 end and 1 kb towards the 3\u2019 end so that regulatory elements of the gene can be included. Results and Plots specific of gene set PRS analyses ** Check the .summary results file, with and without running the PRSet specific options ** \u2753 How does this file change? What extra information is incorporated when including the PRSet specific commands? Apart from the output files, running the PRSet options will provide extra information about the new gene set PRSs calculated. For example, a new figure with the results for each gene set PRS. Figure 2 : An example of the multi-set plot. Sets are sorted based on their self-contained R2. Base is the genome wide PRS. Considerations when analysing and interpreting gene-set PRSs Clumping for each gene set independently In standard clumping and P-value thresholding methods, clumping is performed to account for linkage disequilibrium between SNPs. If genome-wide clumping is performed at the gene set level, we may remove signal as shown in this toy example . To maximize signal within each gene set, clumping is performed for each gene set separately. ** Check the .summary results file. When answering questions, do not count the Base, as this result corresponds to the genome-wide PRS ** \u2753 Check the '.summary' file. How many SNPs are included in the top 10 gene sets? \u2753 Can you plot the relationship between the gene set R2 and the number of SNPs in each gene set? What general trend can be seen? P-value thresholding in gene set PRS analyses PRSet default option is to no not perform p-value thresholding. It will simply calculate the set based PRS at P-value threshold of 1. \u2753 Why do you think that the default option of PRSet is P-value threshold of 1? \u2753 In what cases would you like to apply P-value thresholding? Self-contained vs competitive testing An important aspect when calculating gene set based PRSs is the type of test used for association. Since we are only considering one region of the genome, self-contained and/or competitive tests can be performed. The null-hypothesis of self-contained and competitive test statistics is di\ufb00erent: \u2013 Self-Contained - None of the genes within the gene-set are associated with the phenotype \u2013 Competitive - Genes within the gene-set are no more associated with the phenotype than genes outside the gene-set Therefore, a bigger gene-set will have a higher likelihood of having a significant P -value from self-contained test, which is not desirable. ** Check the .summary results file again ** \u2753 What are the 3 gene-sets with the smallest competitive P-values? \u2753 Why do you think that we check the competitive P-value, instead of the self contained P-value? ** Imagine that you are running an analysis to find the gene sets most associated with height ** \u2753 Considering the competitive P-value results, what gene set do you think is the most interesting and why? Back to Top","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#advanced-polygenic-risk-score-analyses","text":"","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#day-2-afternoon-practical-pathway-prs-analyses","text":"","title":"Day 2 - Afternoon Practical: Pathway PRS Analyses"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#table-of-contents","text":"Introduction to gene set (pathway) PRS analysis Inputs required for gene-set PRS analysis Molecular Signatures Database MSigDB Other inputs that can be used for gene-set PRS using PRSet Exercise: Calculate gene-set PRS analysis Considerations when analysing and interpreting gene set PRSs Clumping for each gene set independently P-value thresholding in gene set PRS analyses Self-contained vs competitive testing","title":"Table of Contents"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: 1. Understand the motivation and rationale for calculating gene set PRS. 2. Identify the additional inputs required for gene set PRS analysis. 3. Calculate gene set based PRSs using PRSet. 5. Understand and interpret the outcomes of gene set PRSs and how they differ from genome-wide PRS.","title":"Key Learning Outcomes"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#data-structure","text":"You will find all practical materials in the data/Day_2b directory. Relevant materials that you should find at the start of the practical are: \ud83d\udcc2: Base_Data - GIANT_Height.txt, \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.covariate \ud83d\udcc1: Reference - Homo_sapiens.GRCh38.109.gtf.gz - Sets.gmt","title":"Data Structure"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#introduction-to-gene-set-pathway-prs-analysis","text":"Most PRS methods summarize genetic risk to a single number, based on the aggregation of an individual\u2019s genome-wide risk alleles. This approach does not consider the different contributions of the various biological processes that can influence complex diseases and traits. During this session, you will learn how to run a gene set (or pathway) based PRS analyses. The key difference between genome-wide PRS and gene set or pathway-based PRSs analyses is that, instead of aggregating the estimated effects of risk alleles across the entire genome, gene set PRSs aggregate risk alleles across as many gene sets as the user defines (Figure 1). Figure 1: The pathway polygenic risk score approach. Coloured boxes represent genes, lines link genes that are within the same genomic pathway. See full description here . \ud83d\udccc In this practical, we will go through some of the additional input requirements and considerations for the analysis of gene set PRS analysis, and will then calculate some gene set based PRS using PRSet . By aggregating PRS across multiple gene sets (or pathways), these PRS analyses will allow us to determine the genetic contribution made by each biological process in complex traits and diseases. For more information about the rationale and the software that we are going to use, please see the PRSet publication PRSet: Pathway-based polygenic risk score analyses and software . \u2753 Why is it useful to have polygenic scores measured across gene-sets (or pathways) for individuals? Isn\u2019t it su\ufb03cient to just obtain a ranking of gene-sets according to GWAS-signal enrichment (using gene set enrichment tools such as MAGMA or partitioned LDSC)?","title":"Introduction to gene set (pathway) PRS analysis"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#inputs-required-for-gene-set-prs-analysis","text":"Summary statistics from GWAS, as well as individual level genotype and phenotype data are required to perform gene set PRS analyses. In this session, the following Base and Target data is used. Base data is publicly available. All Target data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Data Set Description Download Link Base from the GIANT Consortium GWAS of height on 253,288 individuals Link Simulated Target Data Individual-level phenotype and genotype files Data folder Additionally, to perform gene set PRS analyses, information about the gene sets for which we want to calculate the PRSs are required. In this tutorial, we will use as input gene-sets from the Molecular Signatures Database . However, PRSet also takes as input BED and SNP files . Data Set Description Download Link Ensembl Human Genome GTF file A file containing the coordinates for genes in the human genome. Used by PRSet to map the SNPs onto genic regions Link to Homo_sapiens.GRCh38.109.gtf.gz MSigDB Gene Sets File containing the gene-set information. Free registration required. Download link after registration","title":"Inputs required for gene-set PRS analysis"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#molecular-signatures-database-msigdb-general-transfer-format-file","text":"MSigDB o\ufb00ers an excellent source of gene sets, including the hallmark genes, gene sets of di\ufb00erent biological processes, gene sets of di\ufb00erent oncogenic signatures etc. All gene sets from MSigDB follows the Gene Matrix Transposed file format (GMT), which consists of one line per gene set, each containing at least 3 column of data: Set A Description Gene 1 Gene 2 ... Set A Description Gene 1 Gene 2 ... \ud83d\udcac While you can read the GMT file using Excel, we recommend exploring these files using bash. You should be aware that Excel has a tendency to convert gene names into dates (e.g. SEPT9 to Sep-9) ** Have a look at the Reference/Sets.gmt file. ** \u2753 How many gene sets are there in the Reference/Sets.gmt file? \u2753 How many genes does the largest gene set contain? As GMT format does not contain the chromosomal location for each individual gene, an additional file (General Transfer Format file) is required to provide the chromosomal location such that SNPs can be mapped to genes. The General Transfer Format (GTF) file contains the chromosomal coordinates for each gene. It is a tab separated file and all fields except the last must contain a value. You can read the full format specification here . Two columns in the GTF file that might be of particular interest are: - Column 3: feature , which indicates what feature that line of GTF represents. This allows us to select or ignore features that are of interest. Column 9: attribute , which contains a semicolon-separated list of tag-value pairs (separated by a space), providing additional information about each feature. A key can be repeated multiple times.","title":"Molecular Signatures Database MSigDB + General Transfer Format file"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#tip-to-parse-column-9-and-split-the-additional-information-in-separate-columns-you-can-use-the-following-r-code","text":"library(data.table) library(magrittr) # Function to extract attributes from column 9 in GTF files: extract_attribute = function(input, attribute) { strsplit(input, split = \";\") %>% unlist %>% .[grepl(attribute, .)] %>% gsub(\"\\\"\", \"\", .) %>% strsplit(., split = \" \") %>% unlist %>% tail(n = 1) %>% return } gtf38 = fread(\"./Reference/Homo_sapiens.GRCh38.109.gtf.gz\") gtf38_parsed = gtf38 %>% # Select genes only, based on column 3 (feature) .[V3 == \"gene\"] %>% # Select genes located in autosomes .[`#!genebuild-last-updated 2022-11` %in% 1:22] %>% # Create colummns with Gene information .[, c(\"chr\", \"Gene_start\", \"Gene_end\", \"ensemblID\", \"Gene_Name\", \"Gene_biotype\") := data.table( `#!genebuild-last-updated 2022-11`, V4, V5, sapply(V9, extract_attribute, \"gene_id\"), sapply(V9, extract_attribute, \"gene_name\"), sapply(V9, extract_attribute, \"gene_biotype\"))] %>% # Filter the columns of interest .[, c(\"chr\", \"Gene_start\", \"Gene_end\", \"ensemblID\", \"Gene_Name\", \"Gene_biotype\")] ** Have a look at the Reference/Homo_sapiens.GRCh38.109.gtf.gz file. ** \u2753 Based on the column with information about the features, how many instances of feature = \"gene\" can you find ? \u2753 Based on the column with inforamtion about the attributes, how many protein-coding genes are there in the Reference/Homo_sapiens.GRCh38.109.gtf.gz file?","title":"&gt; \ud83d\udccc Tip, to parse column 9 and split the additional information in separate columns, you can use the following R code:"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#other-inputs-that-can-be-used-for-gene-set-prs-using-prset","text":"","title":"Other inputs that can be used for gene set PRS using PRSet"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#browser-extensible-data-bed","text":"Browser Extensible Data (BED) file (di\ufb00erent to the binary ped file from PLINK), is a file format to define genetic regions. It contains 3 required fields per line (chromosome, start coordinate and end coordinate) together with 9 additional optional field. A special property of BED is that it is a 0-based format, i.e. chromosome starts at 0, as opposed to the usual 1-based format such as the PLINK format. For example, a SNP on chr1:10000 will be represented as: 1 9999 10000 \u2753 How should we represent the coordinate of rs2980300 (chr1:785989) in BED format?","title":"Browser Extensible Data BED"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#list-of-snps","text":"Finally, PRSet also allow SNP sets, where the user have flexibility to decide what SNPs are included. The list of SNPs can have two different formats: - SNP list format, a file containing a single column of SNP ID. Name of the set will be the file name or can be provided using --snp-set File:Name - MSigDB format: Each row represent a single SNP set with the first column containing the name of the SNP set. Back to Top","title":"List of SNPs"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#exercise-calculate-gene-set-prs-analysis","text":"We are now ready to perform gene-set association analyses using PRSet. To perform the PRSet analysis and obtain the set based PRS and competitive P-value, simply provide the GTF file and the GMT file to PRSice and specify the number of permutation for competitive P-value calculation using the --set-perm option. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ ----> ATTENTION, the binary file may be different depending on the operative system (linux, mac, windows) --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --A1 Allele1 \\ --A2 Allele2 \\ --snp MarkerName \\ --pvalue p \\ --stat b \\ --beta \\ --binary-target F \\ --pheno Target_Data/TAR.height \\ --cov Target_Data/TAR.covariate \\ --out Height.set \\ --gtf Reference/Homo_sapiens.GRCh38.109.gtf.gz \\ --wind-5 5kb \\ --wind-3 1kb \\ --msigdb Reference/Sets.gmt \\ --multi-plot 10 \\ --set-perm 1000","title":"Exercise: Calculate gene set PRS analysis"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#if-the-wind-5-and-wind-3-flag-is-not-specified-prset-will-use-the-exact-coordinates-of-each-gene-as-the-boundary-by-specifying-eg-wind-5-5kb-and-wind-3-1kb-then-the-boundary-of-each-gene-will-be-extended-5-kb-towards-the-5-end-and-1-kb-towards-the-3-end-so-that-regulatory-elements-of-the-gene-can-be-included","text":"","title":"&gt; \ud83d\udccc If the --wind-5 and --wind-3 flag is not specified, PRSet will use the exact coordinates of each gene as the boundary. By specifying eg. --wind-5 5kb and --wind-3 1kb then the boundary of each gene will be extended 5 kb towards the 5\u2019 end and 1 kb towards the 3\u2019 end so that regulatory elements of the gene can be included."},{"location":"tmp/practical_docs_hidden/Day2b.docx/#results-and-plots-specific-of-gene-set-prs-analyses","text":"** Check the .summary results file, with and without running the PRSet specific options ** \u2753 How does this file change? What extra information is incorporated when including the PRSet specific commands? Apart from the output files, running the PRSet options will provide extra information about the new gene set PRSs calculated. For example, a new figure with the results for each gene set PRS. Figure 2 : An example of the multi-set plot. Sets are sorted based on their self-contained R2. Base is the genome wide PRS.","title":"Results and Plots specific of gene set PRS analyses"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#considerations-when-analysing-and-interpreting-gene-set-prss","text":"","title":"Considerations when analysing and interpreting gene-set PRSs"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#clumping-for-each-gene-set-independently","text":"In standard clumping and P-value thresholding methods, clumping is performed to account for linkage disequilibrium between SNPs. If genome-wide clumping is performed at the gene set level, we may remove signal as shown in this toy example . To maximize signal within each gene set, clumping is performed for each gene set separately. ** Check the .summary results file. When answering questions, do not count the Base, as this result corresponds to the genome-wide PRS ** \u2753 Check the '.summary' file. How many SNPs are included in the top 10 gene sets? \u2753 Can you plot the relationship between the gene set R2 and the number of SNPs in each gene set? What general trend can be seen?","title":"Clumping for each gene set independently"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#p-value-thresholding-in-gene-set-prs-analyses","text":"PRSet default option is to no not perform p-value thresholding. It will simply calculate the set based PRS at P-value threshold of 1. \u2753 Why do you think that the default option of PRSet is P-value threshold of 1? \u2753 In what cases would you like to apply P-value thresholding?","title":"P-value thresholding in gene set PRS analyses"},{"location":"tmp/practical_docs_hidden/Day2b.docx/#self-contained-vs-competitive-testing","text":"An important aspect when calculating gene set based PRSs is the type of test used for association. Since we are only considering one region of the genome, self-contained and/or competitive tests can be performed. The null-hypothesis of self-contained and competitive test statistics is di\ufb00erent: \u2013 Self-Contained - None of the genes within the gene-set are associated with the phenotype \u2013 Competitive - Genes within the gene-set are no more associated with the phenotype than genes outside the gene-set Therefore, a bigger gene-set will have a higher likelihood of having a significant P -value from self-contained test, which is not desirable. ** Check the .summary results file again ** \u2753 What are the 3 gene-sets with the smallest competitive P-values? \u2753 Why do you think that we check the competitive P-value, instead of the self contained P-value? ** Imagine that you are running an analysis to find the gene sets most associated with height ** \u2753 Considering the competitive P-value results, what gene set do you think is the most interesting and why? Back to Top","title":"Self-contained vs competitive testing"},{"location":"tmp/practical_docs_hidden/Day3a.docx/","text":"Advanced Polygenic Risk Score Analyses Day 3 - Polygenic Risk Score Analyses Workshop 2024 Table of Contents Key Learning Outcomes Base and Target datasets Downloading Datasets Method for Calculating PRS Exercise 1 Estimating R 2 Exercise 2 Visualising and comparing R 2 Day 3a practical Key Learning Outcomes After completing this practical, you should be able to: 1. Compute and analyse ancestry-matched and unmatched PRS using PRSice-2. 2. Understand and interpret the results from PRSise-2 derived scores. 3. Understand and identify the impact of ancestry on the predictive utility of PRS. 4. Understand and identify the impact of sample size on the predictive utility of PRS. 5. Understand the challenges and limitations of applying PRS in populations with diverse genetic backgrounds. Base and Target datasets In this practical, we will compute a PRS for systolic blood pressure (SBP) and assess it performance across European and African ancestry datasets to clearly illustrate the portability problem. We will assess the predictive utility of 3 scores : ANCESTRY-MATCHED 1. EUR base - EUR target: Utilise European summary statistics as the training data and individual-level genotyped data from Europeans as the target dataset. 2. AFR base - AFR target: Utilise African summary statistics as the training data and individual-level genotyped data from Africans as the target dataset. ANCESTRY-UNMATCHED EUR base - AFR target: Utilise European summary statistics as the training data and individual-level genotyped data from Africans as the target dataset. Please note that the sample sizes of the individual-level target data are as follows: Europeans (n = ~500) and Africans (n = ~650). Note: This is simulated data with no real-life biological meaning or implication. Dataset Source Description Base dataset (EUR, AFR) simulated GWAS summary stats of SBP Target dataset (EUR, AFR) simulated EUR (n = ~500), AFR (n = ~650) Downloading Datasets All required software for this practical is found in the /home/manager/data/Data_Day4/software directory. \ud83d\udee0\ufe0f: Software - PRSice.R - PRSice_linux - plink_linux All required data for this practical is found in the /home/manager/data/Data_Day4/data directory. The relevant data that you should see there at the start of the practical are as follows: \ud83d\udcc2: Base_Data (summary statistics) - AFR-SBP-simulated.sumstats.prscsx - EUR-SBP-simulated.sumstats.prscsx \ud83d\udcc2: Target_Data - AFR_1kg.hm3.only.csx (.bed, .bim, .fam) - EUR_1kg.hm3.only.csx (.bed, .bim, .fam) - sbp.afr.1kg.sim_pheno - sbp.eur.1kg.sim_pheno \ud83d\udcc1: Reference files - 1kg.afr.dbSNP153.hg38.bed - 1kg.afr.dbSNP153.hg38.bim - 1kg.afr.dbSNP153.hg38.fam - 1kg.eur.dbSNP153.hg38.bed - 1kg.eur.dbSNP153.hg38.bim - 1kg.eur.dbSNP153.hg38.fam Method for calculating PRS For this practical we will use PRSice-2. PRSice-2 is one of the dedicated PRS calculation and analysis programs that makes use of a sequence of PLINK functions. The tools utilises the standard clumping and thresholding (C+T) approach. Exercise 1 Estimating R 2 Code Open the terminal and move to the data directory for this practical: cd /home/manager/data/Data_Day4/data Create the output directory - \"out\": mkdir out Look at the data files within the directory: ls -l Now, calculate PRS using PRSice 2 Scenario 1: Predicting from EUR training to EUR target data: Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.eur.eur Key code parameters The parameters listed in this table remain consistent across various scenarios, but the specific values may change based on the dataset and analysis scenario. For illustrative purposes, this table uses the first scenario, EUR base and EUR target population: Click to view the parameters table Parameter Value Description prsice PRSice_xxx Informs PRSice.R that the location of the PRSice binary, xxx is the operating system (mac or linux) base EUR-SBP-simulated.sumstats.prscsx Specifies the GWAS summary statistics file for input A1 A1 Column name for the effect allele in the GWAS summary statistics p value P Column name for the p-values of SNPs in the GWAS summary statistics no clump - Instructs PRSice to skip the clumping process, which is used to remove SNPs in linkage disequilibrium beta - Indicates that the effect sizes are given in beta coefficients (linear regression coefficients) snp SNP Column name for SNP identifiers in the GWAS summary statistics score sum Specifies that the score calculation should sum the product of SNP effect sizes and their genotype counts target EUR_1kg.hm3.only.csx Specifies the genotype data file for the target sample binary-target F Indicates that the phenotype of interest is not binary (e.g., quantitative trait), F for no pheno sbp_eur_1kg.sim_pheno Specifies the file containing phenotype data pheno-col pheno100 Column name in the phenotype file that contains the phenotype data to be used for PRS calculation cov* EUR.covariate Specifies the file containing covariate data for the analysis base-maf* MAF:0.01 Filter out SNPs with MAF < 0.01 in the GWAS summary statistics, using information in the MAF column base-info* INFO:0.8 Filter out SNPs with INFO < 0.8 in the GWAS summary statistics, using information in the INFO column stat* OR Column name for the odds ratio (effect size) in the GWAS summary statistics or* - Inform PRSice that the effect size is an Odd Ratio thread 8 Specifies the number of computing threads to use for the analysis out SBP_trial.eur.eur Specifies the name for the output files generated by PRSice *Note: These parameters are not used within this exercise but will likely be included when conducting your own analyses. QUESTIONS Move to the out directory you created earlier: cd out Look at the files produced following your first analyis within the directory: ls -l How many files have been generated from this code and what does each file show you? This code generates six files. Each files serves a different purpose in the analysis and interpretation of derived PRS. These are outlined below: 1. **.summary**: Provides a high-level summary of the best-performing PRS analysis result, allowing for a quick assessment of the PRS model's performance. 2. **.prsice**: Provides the PRS analysis results across all p-value thresholds. This file will be the input for the bar plot that assesses the R2 at each p-value threshold. 3. **.log**: Useful for debugging and detailed tracking of the computational steps undertaken during the PRS calculation. 4. **.best**: Provides details of which individuals (IID) are included in the PRS regression analysis that assesses the association between the genotype and phenotype, and provides their individual PRS score 5. **.png (Bar plot)**: Assist in visually assessing the performance of PRS calculated at each p-value threshold, with the most predictive bar being the highest R 2 and thus the tallest bar). The y axis shows the phenotypic variance explained (R 2 ), the x-axis the various p-value thresholds, and the text above each bar is the p-value showing the significance of the association between the PRS and phenotype. The colours of the bars (from red to blue) indicate the strength of the association with red indicating lower p-values (greater significance). 6. **.png (High resolution plot)**: Assist in visually assessing the performance of PRS calculated at each p-value threshold. However, this high-resolution plot uses a negative logarithmic scale on the Y-axis to show the performance of different combinations of SNPS in predicting the trait as measured by their p-values. Lower p-values indicate better performance and appear higher on the Y-axis. Examine the plot indicating the R 2 at each p-value threshold: xdg-open SBP.eur.eur_BARPLOT_2024-06-12.png Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 0.00205005. What does \"best-fit\" mean? \"Best-fit\" refers to the p-value threshold at which the PRS accounts for the highest proportion of variance in the phenotype (R 2 ) compared to other thresholds tested. Why does this matter? Choosing the optimal p-value threshold is crucial because it affects the sensitivity and specificity of the PRS. The optimal threshold balances including informative SNPs and excluding noise from less relevant variants. A threshold that is too lenient (high p-value from GWAS association test) might include too many SNPs, adding noise and possibly diluting the predictive power of the score. Conversely, a threshold that is too stringent (low p-value) might exclude potentially informative SNPs, reducing the ability of the PRS to capture the genetic architecture of the trait. Which file provides a summary of the \"best-fit\" PRS? SBP.eur.eur.summary View this summary output file: cat /home/manager/data/Data_Day4/data/out/SBP.eur.eur.summary How much phenotypic variation does the \"best-fit\" PRS explain? What does this mean in very simple terms? R 2 = 0.0829 (8.2%). This R 2 value means that out of the total variability observed in the trait across the population (under study), 8.2% of the variation can be attributed to the genetic variants included in this PRS. What is the significance of the association (p-value) between the \"best-fit\" PRS and trait? The p-value is 1.72126e-11. A p-value below 0.05 indicates statistically significant evidence that the PRS at this threshold explains phenotypic variance and captures genuine genetic associations with the phenotype (i.e. not by chance). How many SNPs are included in the \"best-fit\" PRS? Number of SNPs = 389. Scenario 2: Predicting from AFR training to AFR target data: Return to the data directory: cd /home/manager/data/Data_Day4/data Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno50 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.afr.afr View the output file: cat /home/manager/data/Data_Day4/data/out/SBP.afr.afr.summary QUESTIONS Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 5e-08. How many SNPs are included in the \"best-fit\" PRS explain? Number of SNPs = 96. How much phenotypic variation does the \"best-fit\" PRS explain? R 2 = 0.0082124 (0.8%). Scenario 3: Predicting from EUR training to AFR target data Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno50 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.eur.afr View the output file: cat /home/manager/data/Data_Day4/data/out/SBP.eur.afr.summary QUESTIONS Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 0.00815005. How many SNPs are included in the \"best-fit\" PRS explain? Number of SNPs = 1192. How much phenotypic variation does the \"best-fit\" PRS explain? R 2 = 0.0160098 (1.6%). Exercise 2 Visualising and comparing R 2 In this exercise, we will analyse and compare the phenotypic variance explained (R 2 ) by PRS across different combinations of base and target ancestries. We will use R for visualisation. Open a new terminal and open R Open a new tab in the terminal ( plus icon in the top left corner ) In this new terminal window, make sure you are in the 'out' directory: cd /home/manager/data/Data_Day4/data/out/ Now open R: R Once in R, combine the summary files and visualise the performance of each PRS: # Load necessary libraries library ( ggplot2 ) library ( RColorBrewer ) # Create a function to read the files and add ancestry information read_and_label <- function ( file, ancestry ) { data <- read.table ( file, header = TRUE, sep = \"\\t\" ) data $Ancestry <- ancestry return ( data ) } # Read each file with the corresponding ancestry information EUR_EUR <- read_and_label ( \"SBP.eur.eur.summary\" , \"EUR_EUR\" ) AFR_AFR <- read_and_label ( \"SBP.afr.afr.summary\" , \"AFR_AFR\" ) EUR_AFR <- read_and_label ( \"SBP.eur.afr.summary\" , \"EUR_AFR\" ) # Combine all data into one dataframe all_data <- rbind ( EUR_EUR, AFR_AFR, EUR_AFR ) # Create a bar graph with different colors for each ancestry png ( '/home/manager/data/Data_Day4/data/out/PRS_ancestry_analysis.png' , unit = 'px' , res =300 , width =3500 , height =4500) ancestry <- ggplot ( all_data, aes ( x = Ancestry, y = PRS.R2, fill = Ancestry )) + geom_bar ( stat = \"identity\" , position = \"dodge\" ) + labs ( title = \"R2 Values by Ancestry\" , x = \"Ancestry\" , y = \"R2 Value\" ) + theme_minimal () + scale_fill_brewer ( palette = \"Set3\" ) + theme ( plot.title = element_text ( hjust = 0 .5, size = 16 , face = \"bold\" ) , axis.title.x = element_text ( size = 14 , face = \"bold\" ) , axis.title.y = element_text ( size = 14 , face = \"bold\" ) , axis.text.x = element_text ( size = 12 , angle = 45 , hjust = 1) , axis.text.y = element_text ( size = 12) , legend.position = \"none\" ) print ( ancestry ) dev.off () Examine the bar plot indicating the R 2 for each base:target ancestry pair: xdg-open PRS_ancestry_analysis.png QUESTIONS Which base:target pair has the highest phenotypic variance explained? EUR:EUR. Which base:target pair has the lowest phenotypic variance explained? AFR:AFR. Explain the results? Are they as expected? THINK - PAIR - SHARE \u203c\ufe0f Note that all target phenotype data in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Top","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#advanced-polygenic-risk-score-analyses","text":"","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#day-3-polygenic-risk-score-analyses-workshop-2024","text":"","title":"Day 3 - Polygenic Risk Score Analyses Workshop 2024"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#table-of-contents","text":"Key Learning Outcomes Base and Target datasets Downloading Datasets Method for Calculating PRS Exercise 1 Estimating R 2 Exercise 2 Visualising and comparing R 2","title":"Table of Contents"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#day-3a-practical","text":"","title":"Day 3a practical"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: 1. Compute and analyse ancestry-matched and unmatched PRS using PRSice-2. 2. Understand and interpret the results from PRSise-2 derived scores. 3. Understand and identify the impact of ancestry on the predictive utility of PRS. 4. Understand and identify the impact of sample size on the predictive utility of PRS. 5. Understand the challenges and limitations of applying PRS in populations with diverse genetic backgrounds.","title":"Key Learning Outcomes"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#base-and-target-datasets","text":"In this practical, we will compute a PRS for systolic blood pressure (SBP) and assess it performance across European and African ancestry datasets to clearly illustrate the portability problem. We will assess the predictive utility of 3 scores : ANCESTRY-MATCHED 1. EUR base - EUR target: Utilise European summary statistics as the training data and individual-level genotyped data from Europeans as the target dataset. 2. AFR base - AFR target: Utilise African summary statistics as the training data and individual-level genotyped data from Africans as the target dataset. ANCESTRY-UNMATCHED EUR base - AFR target: Utilise European summary statistics as the training data and individual-level genotyped data from Africans as the target dataset. Please note that the sample sizes of the individual-level target data are as follows: Europeans (n = ~500) and Africans (n = ~650). Note: This is simulated data with no real-life biological meaning or implication. Dataset Source Description Base dataset (EUR, AFR) simulated GWAS summary stats of SBP Target dataset (EUR, AFR) simulated EUR (n = ~500), AFR (n = ~650)","title":"Base and Target datasets"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#downloading-datasets","text":"All required software for this practical is found in the /home/manager/data/Data_Day4/software directory. \ud83d\udee0\ufe0f: Software - PRSice.R - PRSice_linux - plink_linux All required data for this practical is found in the /home/manager/data/Data_Day4/data directory. The relevant data that you should see there at the start of the practical are as follows: \ud83d\udcc2: Base_Data (summary statistics) - AFR-SBP-simulated.sumstats.prscsx - EUR-SBP-simulated.sumstats.prscsx \ud83d\udcc2: Target_Data - AFR_1kg.hm3.only.csx (.bed, .bim, .fam) - EUR_1kg.hm3.only.csx (.bed, .bim, .fam) - sbp.afr.1kg.sim_pheno - sbp.eur.1kg.sim_pheno \ud83d\udcc1: Reference files - 1kg.afr.dbSNP153.hg38.bed - 1kg.afr.dbSNP153.hg38.bim - 1kg.afr.dbSNP153.hg38.fam - 1kg.eur.dbSNP153.hg38.bed - 1kg.eur.dbSNP153.hg38.bim - 1kg.eur.dbSNP153.hg38.fam","title":"Downloading Datasets"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#method-for-calculating-prs","text":"For this practical we will use PRSice-2. PRSice-2 is one of the dedicated PRS calculation and analysis programs that makes use of a sequence of PLINK functions. The tools utilises the standard clumping and thresholding (C+T) approach.","title":"Method for calculating PRS"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#exercise-1-estimating-r2","text":"","title":"Exercise 1 Estimating R2"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#code","text":"Open the terminal and move to the data directory for this practical: cd /home/manager/data/Data_Day4/data Create the output directory - \"out\": mkdir out Look at the data files within the directory: ls -l Now, calculate PRS using PRSice 2","title":"Code"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#scenario-1-predicting-from-eur-training-to-eur-target-data","text":"Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.eur.eur","title":"Scenario 1: Predicting from EUR training to EUR target data:"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#key-code-parameters","text":"The parameters listed in this table remain consistent across various scenarios, but the specific values may change based on the dataset and analysis scenario. For illustrative purposes, this table uses the first scenario, EUR base and EUR target population: Click to view the parameters table Parameter Value Description prsice PRSice_xxx Informs PRSice.R that the location of the PRSice binary, xxx is the operating system (mac or linux) base EUR-SBP-simulated.sumstats.prscsx Specifies the GWAS summary statistics file for input A1 A1 Column name for the effect allele in the GWAS summary statistics p value P Column name for the p-values of SNPs in the GWAS summary statistics no clump - Instructs PRSice to skip the clumping process, which is used to remove SNPs in linkage disequilibrium beta - Indicates that the effect sizes are given in beta coefficients (linear regression coefficients) snp SNP Column name for SNP identifiers in the GWAS summary statistics score sum Specifies that the score calculation should sum the product of SNP effect sizes and their genotype counts target EUR_1kg.hm3.only.csx Specifies the genotype data file for the target sample binary-target F Indicates that the phenotype of interest is not binary (e.g., quantitative trait), F for no pheno sbp_eur_1kg.sim_pheno Specifies the file containing phenotype data pheno-col pheno100 Column name in the phenotype file that contains the phenotype data to be used for PRS calculation cov* EUR.covariate Specifies the file containing covariate data for the analysis base-maf* MAF:0.01 Filter out SNPs with MAF < 0.01 in the GWAS summary statistics, using information in the MAF column base-info* INFO:0.8 Filter out SNPs with INFO < 0.8 in the GWAS summary statistics, using information in the INFO column stat* OR Column name for the odds ratio (effect size) in the GWAS summary statistics or* - Inform PRSice that the effect size is an Odd Ratio thread 8 Specifies the number of computing threads to use for the analysis out SBP_trial.eur.eur Specifies the name for the output files generated by PRSice *Note: These parameters are not used within this exercise but will likely be included when conducting your own analyses. QUESTIONS Move to the out directory you created earlier: cd out Look at the files produced following your first analyis within the directory: ls -l How many files have been generated from this code and what does each file show you? This code generates six files. Each files serves a different purpose in the analysis and interpretation of derived PRS. These are outlined below: 1. **.summary**: Provides a high-level summary of the best-performing PRS analysis result, allowing for a quick assessment of the PRS model's performance. 2. **.prsice**: Provides the PRS analysis results across all p-value thresholds. This file will be the input for the bar plot that assesses the R2 at each p-value threshold. 3. **.log**: Useful for debugging and detailed tracking of the computational steps undertaken during the PRS calculation. 4. **.best**: Provides details of which individuals (IID) are included in the PRS regression analysis that assesses the association between the genotype and phenotype, and provides their individual PRS score 5. **.png (Bar plot)**: Assist in visually assessing the performance of PRS calculated at each p-value threshold, with the most predictive bar being the highest R 2 and thus the tallest bar). The y axis shows the phenotypic variance explained (R 2 ), the x-axis the various p-value thresholds, and the text above each bar is the p-value showing the significance of the association between the PRS and phenotype. The colours of the bars (from red to blue) indicate the strength of the association with red indicating lower p-values (greater significance). 6. **.png (High resolution plot)**: Assist in visually assessing the performance of PRS calculated at each p-value threshold. However, this high-resolution plot uses a negative logarithmic scale on the Y-axis to show the performance of different combinations of SNPS in predicting the trait as measured by their p-values. Lower p-values indicate better performance and appear higher on the Y-axis. Examine the plot indicating the R 2 at each p-value threshold: xdg-open SBP.eur.eur_BARPLOT_2024-06-12.png Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 0.00205005. What does \"best-fit\" mean? \"Best-fit\" refers to the p-value threshold at which the PRS accounts for the highest proportion of variance in the phenotype (R 2 ) compared to other thresholds tested. Why does this matter? Choosing the optimal p-value threshold is crucial because it affects the sensitivity and specificity of the PRS. The optimal threshold balances including informative SNPs and excluding noise from less relevant variants. A threshold that is too lenient (high p-value from GWAS association test) might include too many SNPs, adding noise and possibly diluting the predictive power of the score. Conversely, a threshold that is too stringent (low p-value) might exclude potentially informative SNPs, reducing the ability of the PRS to capture the genetic architecture of the trait. Which file provides a summary of the \"best-fit\" PRS? SBP.eur.eur.summary View this summary output file: cat /home/manager/data/Data_Day4/data/out/SBP.eur.eur.summary How much phenotypic variation does the \"best-fit\" PRS explain? What does this mean in very simple terms? R 2 = 0.0829 (8.2%). This R 2 value means that out of the total variability observed in the trait across the population (under study), 8.2% of the variation can be attributed to the genetic variants included in this PRS. What is the significance of the association (p-value) between the \"best-fit\" PRS and trait? The p-value is 1.72126e-11. A p-value below 0.05 indicates statistically significant evidence that the PRS at this threshold explains phenotypic variance and captures genuine genetic associations with the phenotype (i.e. not by chance). How many SNPs are included in the \"best-fit\" PRS? Number of SNPs = 389.","title":"Key code parameters"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#scenario-2-predicting-from-afr-training-to-afr-target-data","text":"Return to the data directory: cd /home/manager/data/Data_Day4/data Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno50 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.afr.afr View the output file: cat /home/manager/data/Data_Day4/data/out/SBP.afr.afr.summary QUESTIONS Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 5e-08. How many SNPs are included in the \"best-fit\" PRS explain? Number of SNPs = 96. How much phenotypic variation does the \"best-fit\" PRS explain? R 2 = 0.0082124 (0.8%).","title":"Scenario 2: Predicting from AFR training to AFR target data:"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#scenario-3-predicting-from-eur-training-to-afr-target-data","text":"Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno50 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.eur.afr View the output file: cat /home/manager/data/Data_Day4/data/out/SBP.eur.afr.summary QUESTIONS Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 0.00815005. How many SNPs are included in the \"best-fit\" PRS explain? Number of SNPs = 1192. How much phenotypic variation does the \"best-fit\" PRS explain? R 2 = 0.0160098 (1.6%).","title":"Scenario 3: Predicting from EUR training to AFR target data"},{"location":"tmp/practical_docs_hidden/Day3a.docx/#exercise-2-visualising-and-comparing-r2","text":"In this exercise, we will analyse and compare the phenotypic variance explained (R 2 ) by PRS across different combinations of base and target ancestries. We will use R for visualisation. Open a new terminal and open R Open a new tab in the terminal ( plus icon in the top left corner ) In this new terminal window, make sure you are in the 'out' directory: cd /home/manager/data/Data_Day4/data/out/ Now open R: R Once in R, combine the summary files and visualise the performance of each PRS: # Load necessary libraries library ( ggplot2 ) library ( RColorBrewer ) # Create a function to read the files and add ancestry information read_and_label <- function ( file, ancestry ) { data <- read.table ( file, header = TRUE, sep = \"\\t\" ) data $Ancestry <- ancestry return ( data ) } # Read each file with the corresponding ancestry information EUR_EUR <- read_and_label ( \"SBP.eur.eur.summary\" , \"EUR_EUR\" ) AFR_AFR <- read_and_label ( \"SBP.afr.afr.summary\" , \"AFR_AFR\" ) EUR_AFR <- read_and_label ( \"SBP.eur.afr.summary\" , \"EUR_AFR\" ) # Combine all data into one dataframe all_data <- rbind ( EUR_EUR, AFR_AFR, EUR_AFR ) # Create a bar graph with different colors for each ancestry png ( '/home/manager/data/Data_Day4/data/out/PRS_ancestry_analysis.png' , unit = 'px' , res =300 , width =3500 , height =4500) ancestry <- ggplot ( all_data, aes ( x = Ancestry, y = PRS.R2, fill = Ancestry )) + geom_bar ( stat = \"identity\" , position = \"dodge\" ) + labs ( title = \"R2 Values by Ancestry\" , x = \"Ancestry\" , y = \"R2 Value\" ) + theme_minimal () + scale_fill_brewer ( palette = \"Set3\" ) + theme ( plot.title = element_text ( hjust = 0 .5, size = 16 , face = \"bold\" ) , axis.title.x = element_text ( size = 14 , face = \"bold\" ) , axis.title.y = element_text ( size = 14 , face = \"bold\" ) , axis.text.x = element_text ( size = 12 , angle = 45 , hjust = 1) , axis.text.y = element_text ( size = 12) , legend.position = \"none\" ) print ( ancestry ) dev.off () Examine the bar plot indicating the R 2 for each base:target ancestry pair: xdg-open PRS_ancestry_analysis.png QUESTIONS Which base:target pair has the highest phenotypic variance explained? EUR:EUR. Which base:target pair has the lowest phenotypic variance explained? AFR:AFR. Explain the results? Are they as expected? THINK - PAIR - SHARE \u203c\ufe0f Note that all target phenotype data in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Top","title":"Exercise 2 Visualising and comparing R2"},{"location":"tmp/practical_docs_hidden/Day3b.docx/","text":"Day 3b practical We need to move into the directory you will be working in; cd ~/data/Data_Day4/data Introduction to Cross-Ancestry PRS computation Before starting the practical, the following commands will need to be run from within your virtual machine. These commands set up an 'environment' that allows you to work outside the virtual machine, which has memory restrictions. Set up the environment using conda: conda create -n \"PRScsx\" python =3 .7 conda activate PRScsx pip install scipy pip install h5py The aim of this practical is to provide you with a basic understanding and some experience of running PRS-CSx software. After completing this practical, you should: Be able to perform cross-population analyses. Be familiar with running cross-ancestry PRS analyses using PRS-CSx. Understand how to evaluate linear models using Akaike\u2019s Information Criterion. 1. The 1000 Genomes datasets The data we will be working with comes from the 1000 Genomes Project reference panel. The data relates to individuals from 26 different source populations around the world. For simplicity, the populations have been collapsed into 5 broader continental super-populations: East Asian, European, South Asian, Amerindian, African ((EAS, EUR, SAS, EUR and AFR)). The scripts used to download and process the 1000Genomes data for the purposes of this course will be provided in the course appendix at the end of this week. 2. Cross-population allele frequency Genetic variation is conveyed using allelic frequencies. Allele frequency is shaped by evolutionary forces and drift. Here we compare profiles of allele frequency across the five ancestral populations. Global differences in allelic frequency has important implications for the portability of PRS across populations. Using plink it is possible to generate allele frequency statistics for each SNP, across populations, using the annotations provided in the file pop_info.pheno . In /home/manager/data/Data_Day4 : cd ../ ./software/plink_linux --bfile ./data/chr1-22 --freq --within ./data/pop_info.pheno Population-stratified allele frequencies are reported in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: AFR grep -F 'AFR' plink.frq.strat | wc -l From there we can print the number of SNPs with minor allele frequencies greater than 0 (and are hence potentially available for genomic analyes). grep -F 'AFR' plink.frq.strat | awk '$6 >0' | wc -l EUR grep -F 'EUR' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in EUR. grep -F 'EUR' plink.frq.strat | awk '$6 >0' | wc -l EAS grep -F 'EAS' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in EAS. grep -F 'EAS' plink.frq.strat | awk '$6 >0' | wc -l SAS grep -F 'SAS' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in SAS. grep -F 'SAS' plink.frq.strat | awk '$6 >0' | wc -l AFR grep -F 'AFR' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in AFR. grep -F 'AFR' plink.frq.strat | awk '$6 >0' | wc -l Questions (i) Which population contains the most SNPs? (ii) What is the significance of the observed population order? 3. Distribution of allele frequencies In this exercise, we will analyse and compare the distribution of allele frequencies across different ancestries. We will use R for visualisation. Open a new terminal and open R Open a new tab in the terminal ( plus icon in the top left corner ) In this new terminal window, make sure you are in the correct directory: cd /home/manager/data/Data_Day4/out/ Now open R: R Generate the plot: # Install the necessary libraries install.packages ( \"dplyr\" ) install.packages ( \"ggplot2\" ) # Load necessary libraries library ( dplyr ) library ( ggplot2 ) # Create a function to read the files and add ancestry information freq <-read.table ( \"~/data/Data_Day4/plink.frq.strat\" , header = T ) plotDat <- freq %>% mutate ( AlleleFrequency = cut ( MAF, seq (0 , 1 , 0 .25 ))) %>% group_by ( AlleleFrequency, CLST ) %>% summarise ( FractionOfSNPs = n () /nrow ( freq ) * 100) # Create a bar graph png ( '/home/manager/data/Data_Day4/out/MAF_ancestry_analysis.png' , unit = 'px' , res =300 , width =3500 , height =4500) maf_ancestry <- ggplot ( na.omit ( plotDat ) , aes ( AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST )) + geom_line () + scale_y_continuous ( limits = c (0 , 12)) + ggtitle ( \"Distribution of allele frequency across genome\" ) print ( maf_ancestry ) dev.off () Examine the plot the MAF across each ancestry: # This does not work when you are in R, ensure you out of R before running: xdg-open MAF_ancestry_analysis.png Questions (i) Which population has the most SNPs? (ii) What is the significance of the observed population ordering? (iii) What is the reason behind these two features? Introduction to PRS-CSx 5. Background to PRS-CSX PRS-CSx is a Python based command line tool that integrates GWAS summary statistics and LD reference data from multiple populations to estimate population-specific PRS. PRS-CSx applies a Bayesian model with a continuous shrinkage prior to SNP effects genome-wide. Sparseness of the genetic architecture across populations is controlled by a parameter phi. For a given value of phi, PRS-CSx uses Markov chain Monte Carlo to sample from the posterior of SNP effects from which the mean SNP effects are calculated and used in the PRS. Step 1: Set up environment First change to the working directory with the data for this practical cd /home/manager/data/Data_Day4/data Make a directory called hm3_by_ancestry within the data folder, and move a folder back out of the data folder mkdir hm3_by_ancestry cd .. AFR for chr in {21..22}; do \\ /home/manager/data/Data_Day4/software/plink_linux \\ --bfile /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --chr $chr \\ --make-bed \\ --out /home/manager/data/Data_Day4/data/hm3_by_ancestry/AFR_1kg.hm3.chr${chr}_only.csx; done EUR for chr in {21..22}; do \\ /home/manager/data/Data_Day4/software/plink_linux \\ --bfile /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --chr $chr \\ --make-bed \\ --out /home/manager/data/Data_Day4/data/hm3_by_ancestry/EUR_1kg.hm3.chr${chr}_only.csx; done Set up the necessary environment variables for threading and verify they are set correctly. export N_THREADS=2 export MKL_NUM_THREADS=$N_THREADS export NUMEXPR_NUM_THREADS=$N_THREADS export OMP_NUM_THREADS=$N_THREADS Verify the variables are set echo $N_THREADS echo $MKL_NUM_THREADS echo $NUMEXPR_NUM_THREADS echo $OMP_NUM_THREADS Step 2: Run CSX. Derive new SNPs weights trained on European and African summary stats Generate job file containing the threaded PRScsx commands. First, to minimize computational resources and time, we should create a script to run the tasks in parallel. Make a script called create_multithread.sh nano create_multithread.sh Then copy and paste the code below into that script. After save, then close the script ctrl + x #!/bin/bash # Create the script file SCRIPT_FILE = \"multithread.sh\" # Write the header of the script file echo \"#!/bin/bash\" > $SCRIPT_FILE for chr in {21 ..22 } ; do echo \"python3 /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir=/home/manager/data/Data_Day4/reference/csx \\ --bim_prefix=/home/manager/data/Data_Day4/data/hm3_by_ancestry/AFR_1kg.hm3.chr ${ chr } _only.csx \\ --sst_file=/home/manager/data/Data_Day4/data/3b/data/sumstats_by_chr/EUR-SBP-simulated.sumstats.chr ${ chr } ,/home/manager/data/Data_Day4/data/3b/data/sumstats_by_chr/AFR-SBP-simulated.sumstats.chr ${ chr } \\ --n_gwas=25732,4855 \\ --chrom= ${ chr } \\ --n_iter=1000 \\ --n_burnin=500 \\ --thin=5 \\ --pop=EUR,AFR \\ --phi=1e-4 \\ --out_dir=/home/manager/data/Data_Day4/out/csx \\ --out_name=afr.target_chr ${ chr } .csx\" >> $SCRIPT_FILE done Run: Ctrl + O, followed by Enter ' to save ' Run: Ctrl + X, to Exit You will need to change permission for the script to be able to execute chmod +x create_multithread.sh Run the builder ./create_multithread.sh To be able to run the next command you first install 'parallel' sudo apt install parallel Run the Job File with GNU Parallel: (May take a while) parallel --verbose --jobs $N_THREADS < multithread.sh Step 3: Combine CSX-derived SNP weights across chromosomes (Currently Excludes Chromosome 3) Load R and the necessary library R Call in the package library(dplyr) Define the path to the directory containing the PRS-CSX output files path <- \"/home/manager/data/Data_Day4/out/csx\" Define the ancestry you want to combine (\"EUR\" or \"AFR\") ancestry <- \"EUR\" Initialize an empty data frame to store the combined data combined_data <- data.frame() Loop through chromosomes 21 to 22, (currently excluding chromosome 3) for (chr in setdiff(21:22, 3)) { # Construct the file name file_name <- paste0(\"afr.target_chr\", chr, \".csx_\", ancestry, \"_pst__a1_b0.5_phi1e-04_chr\", chr, \".txt\") file_path <- file.path(path, file_name) # Check if file exists before reading if (file.exists(file_path)) { # Read the data from the file data <- read.table(file_path, header = FALSE, sep = \"\\t\", col.names = c(\"CHR\", \"rsid\", \"pos\", \"ref\", \"alt\", \"beta\")) # Combine the data combined_data <- rbind(combined_data, data) } else { warning(paste(\"File not found:\", file_path)) } } Write the combined data to a new file output_file <- file.path(path, paste0(\"combined_\", ancestry, \"_pst_.txt\")) write.table(combined_data, output_file, sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE) Task: Replace 'ancestry <- \"EUR\" ' with 'ancestry <- \"AFR\" ' and repeat the subsequent steps shown above Step 4: Merge genotype-phenotype data Prepare data The data is slow to merge unless you split the input bim file into just chr21 and chr22 (Q- why are those faster?) cd /home/manager/data/Data_Day4/data/3b/data/ plink --bfile AFR_1kg.hm3.only.csx --chr 21 22 --make-bed --out AFR_1kg.hm3.only.csx_21_22 Start R with sudo rights to allow you to install sudo R # Load libraries. For any unavailable package, install it with **install.packages(\"_package_name\")** install.packages(\"BiocManager\") BiocManager::install(\"snpStats\") library(data.table) library(ggplot2) library(snpStats) # Define the path to the directory containing the PLINK files and phenotypic data plink_path <- \"/home/manager/data/Data_Day4/data/3b/data/\" # Read PLINK files and phenotype data into R bim_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.bim\") fam_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.fam\") bed_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.bed\") pheno_file <- file.path(plink_path, \"sbp_afr_1kg.sim_pheno\") # Read the genotype data using snpStats geno_data <- read.plink(bed_file, bim_file, fam_file) # Extract SNP IDs from geno_data$map$snp.name snp_ids <- geno_data$map$snp.name if (is.null(snp_ids) || !is.character(snp_ids)) { stop(\"SNP IDs are missing or not in the correct format.\") } # Convert the genotype data to a matrix and then to a data.table geno_matrix <- as(geno_data$genotypes, \"matrix\") geno_df <- data.table(geno_matrix) setnames(geno_df, snp_ids) # Add IID column from the fam file geno_df[, IID := geno_data$fam$member] # Read the phenotypic data** pheno_data <- fread(pheno_file, sep = \" \", header = TRUE) Merge phenotype and genotype data # Do merge combined_data <- merge(pheno_data, geno_df, by = \"IID\") # Keep only genotype columns geno <- combined_data[, !names(combined_data) %in% c(\"FID\", \"IID\", \"pheno100\", \"pheno20\", \"pheno33\", \"pheno10\"), with = FALSE] phen <- combined_data$pheno100 # Convert geno to numeric matrix** geno <- as.matrix(geno) mode(geno) <- \"numeric\" # Convert phen to vector phen <- as.vector(phen) Step 5: Split data into validation and test sets Specify Proportion # Here we specify that 40% of all IDs will be used to construct the validation group set.seed(154) vali_proportion <- 0.4 vali_size <- round(nrow(geno) * vali_proportion) vali_indices <- sample(1:nrow(geno), vali_size, replace = FALSE) test_indices <- setdiff(1:nrow(geno), vali_indices) Subsetting of individuals X_vali <- geno[vali_indices, , drop=FALSE] y_vali <- phen[vali_indices] X_test <- geno[test_indices, , drop=FALSE] y_test <- phen[test_indices] Step 6: Prepare the regression model input using the CSX-derived AFR and EUR weights # Read the merged CSX output files AFR_betas <- fread(file.path(\"/home/manager/data/Data_Day4/out/csx/combined_AFR_pst_eff.txt\"), sep = \"\\t\", header = TRUE) EUR_betas <- fread(file.path(\"/home/manager/data/Data_Day4/out/csx/combined_EUR_pst_eff.txt\"), sep = \"\\t\", header = TRUE) # Assuming the beta files have columns: \"CHR\", \"rsid\", \"pos\", \"ref\", \"alt\", \"beta\" overlap_prs <- merge(AFR_betas, EUR_betas, by = \"rsid\", suffixes = c(\"_afr\", \"_eur\")) # Filter overlap_prs to include only SNPs present in X_vali overlap_prs <- overlap_prs[rsid %in% colnames(X_vali)] # Ensure that X_vali and X_test only contain SNPs present in W_afr and W_eur common_snps <- intersect(colnames(X_vali), overlap_prs$rsid) X_vali <- X_vali[, common_snps, drop=FALSE] X_test <- X_test[, common_snps, drop=FALSE] # Reorder the columns of X_vali and X_test to match the order of SNPs in overlap_prs X_vali <- X_vali[, match(overlap_prs$rsid, colnames(X_vali)), drop=FALSE] X_test <- X_test[, match(overlap_prs$rsid, colnames(X_test)), drop=FALSE] # Extract the overlapping rsid and their corresponding betas W_afr <- overlap_prs$beta_afr W_eur <- overlap_prs$beta_eur # Convert W_afr and W_eur to numeric vectors W_afr <- as.numeric(W_afr) W_eur <- as.numeric(W_eur) Step 7: Prepare the variant weights matrices as vectors # Pre-check the alignment between the different objects if (ncol(X_vali) != length(W_afr) || ncol(X_vali) != length(W_eur)) { stop(\"Dimensions of X_vali and W_afr/W_eur do not match.\") } # In the validation sample: # (i) Compute XWafr_vali XWafr_vali <- X_vali %*% W_afr # (ii) Convert XWafr_vali to have zero mean and unit variance XWafr_vali_z <- scale(XWafr_vali) # (iii) Compute XWeur_vali XWeur_vali <- X_vali %*% W_eur # (iv) Convert XWeur_vali to have zero mean and unit variance XWeur_vali_z <- scale(XWeur_vali) # (v) Combine the normalized matrices XW_vali <- cbind(XWafr_vali_z, XWeur_vali_z) # Fit the model model <- lm(scale(y_vali) ~ XWafr_vali_z + XWeur_vali_z - 1) # '- 1' removes the intercept # Obtain the regression parameters a_hat <- coef(model)[1] b_hat <- coef(model)[2] print(paste(\"a_hat =\", a_hat)) print(paste(\"b_hat =\", b_hat)) Step 8: Predict phenotype on validation and test dataset Generate a linear combination of AFR and EUR PRSs for each individual # Each ancestry component is weighted by the regression coicient of that ancestry, in the preceding step y_hat_vali <- a_hat * XWafr_vali_z + b_hat * XWeur_vali_z # In the test sample: # Compute XWafr_test and XWeur_test XWafr_test <- X_test %*% W_afr XWafr_test_z <- scale(XWafr_test) XWeur_test <- X_test %*% W_eur XWeur_test_z <- scale(XWeur_test) # y_hat in the test sample y_hat <- a_hat * XWafr_test_z + b_hat * XWeur_test_z Step 9: Plot phenotype distributions of validation and test data: Check that both distributions are approximately normal library(ggplot2) # Create data frames for validation and test sets vali_data <- data.frame(trait = y_vali, dataset = \"Validation\") test_data <- data.frame(trait = y_test, dataset = \"Test\") # Combine both data frames combined_data <- rbind(vali_data, test_data) # Plot the distributions ggplot(combined_data, aes(x = trait, fill = dataset)) + geom_density(alpha = 0.5) + labs(title = \"Trait Distributions for Validation and Test Sets\", x = \"Trait Value\", y = \"Density\") + theme_minimal() Step 10: Plot true values against predicted values The next steps use standard normal phenotype data to reduce scale differences between PRS and trait values min_true <- min(min(y_vali), min(y_test)) max_true <- max(max(y_vali), max(y_test)) min_pred <- min(min(y_hat_vali), min(y_hat)) max_pred <- max(max(y_hat_vali), max(y_hat)) pdf(\"true_against_pred.pdf\", width = 10, height = 5) par(mfrow = c(1, 2)) plot(scale(y_vali), y_hat_vali, pch = 19, col = rgb(0, 0, 0, 0.5), xlab = 'True Values', ylab = 'Predicted Values', main = 'Validation Dataset') abline(0, 1, col = 'red', lty = 2) plot(scale(y_test), y_hat, pch = 19, col = rgb(0, 0, 0, 0.5), xlab = 'True Values', ylab = 'Predicted Values', main = 'Test Dataset') abline(0, 1, col = 'red', lty = 2) dev.off() Step 11: Calculate deviance-based R 2 # Calculate the deviance (SS_res) deviance <- sum((scale(y_test) - y_hat) ^ 2) print(paste(\"deviance =\", deviance)) # Calculate the mean of the scaled y_test y_test_mean <- mean(scale(y_test)) # Calculate the null deviance (SS_tot) deviance_null <- sum((scale(y_test) - y_test_mean)^ 2) print(paste(\"deviance_null =\", deviance_null)) # Calculate R2 R2 <- 1 - (deviance / deviance_null) print(paste(\"R2 =\", R2)) Results graph: pdf true against pred","title":"Day3b.docx"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#day-3b-practical","text":"We need to move into the directory you will be working in; cd ~/data/Data_Day4/data","title":"Day 3b practical"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#introduction-to-cross-ancestry-prs-computation","text":"Before starting the practical, the following commands will need to be run from within your virtual machine. These commands set up an 'environment' that allows you to work outside the virtual machine, which has memory restrictions. Set up the environment using conda: conda create -n \"PRScsx\" python =3 .7 conda activate PRScsx pip install scipy pip install h5py The aim of this practical is to provide you with a basic understanding and some experience of running PRS-CSx software. After completing this practical, you should: Be able to perform cross-population analyses. Be familiar with running cross-ancestry PRS analyses using PRS-CSx. Understand how to evaluate linear models using Akaike\u2019s Information Criterion.","title":"Introduction to Cross-Ancestry PRS computation"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#1-the-1000-genomes-datasets","text":"The data we will be working with comes from the 1000 Genomes Project reference panel. The data relates to individuals from 26 different source populations around the world. For simplicity, the populations have been collapsed into 5 broader continental super-populations: East Asian, European, South Asian, Amerindian, African ((EAS, EUR, SAS, EUR and AFR)). The scripts used to download and process the 1000Genomes data for the purposes of this course will be provided in the course appendix at the end of this week.","title":"1. The 1000 Genomes datasets"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#2-cross-population-allele-frequency","text":"Genetic variation is conveyed using allelic frequencies. Allele frequency is shaped by evolutionary forces and drift. Here we compare profiles of allele frequency across the five ancestral populations. Global differences in allelic frequency has important implications for the portability of PRS across populations. Using plink it is possible to generate allele frequency statistics for each SNP, across populations, using the annotations provided in the file pop_info.pheno . In /home/manager/data/Data_Day4 : cd ../ ./software/plink_linux --bfile ./data/chr1-22 --freq --within ./data/pop_info.pheno Population-stratified allele frequencies are reported in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: AFR grep -F 'AFR' plink.frq.strat | wc -l From there we can print the number of SNPs with minor allele frequencies greater than 0 (and are hence potentially available for genomic analyes). grep -F 'AFR' plink.frq.strat | awk '$6 >0' | wc -l EUR grep -F 'EUR' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in EUR. grep -F 'EUR' plink.frq.strat | awk '$6 >0' | wc -l EAS grep -F 'EAS' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in EAS. grep -F 'EAS' plink.frq.strat | awk '$6 >0' | wc -l SAS grep -F 'SAS' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in SAS. grep -F 'SAS' plink.frq.strat | awk '$6 >0' | wc -l AFR grep -F 'AFR' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in AFR. grep -F 'AFR' plink.frq.strat | awk '$6 >0' | wc -l","title":"2. Cross-population allele frequency"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#questions","text":"","title":"Questions"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#i-which-population-contains-the-most-snps","text":"","title":"(i) Which population contains the most SNPs?"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#ii-what-is-the-significance-of-the-observed-population-order","text":"","title":"(ii) What  is the significance of the observed population order?"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#3-distribution-of-allele-frequencies","text":"In this exercise, we will analyse and compare the distribution of allele frequencies across different ancestries. We will use R for visualisation. Open a new terminal and open R Open a new tab in the terminal ( plus icon in the top left corner ) In this new terminal window, make sure you are in the correct directory: cd /home/manager/data/Data_Day4/out/ Now open R: R Generate the plot: # Install the necessary libraries install.packages ( \"dplyr\" ) install.packages ( \"ggplot2\" ) # Load necessary libraries library ( dplyr ) library ( ggplot2 ) # Create a function to read the files and add ancestry information freq <-read.table ( \"~/data/Data_Day4/plink.frq.strat\" , header = T ) plotDat <- freq %>% mutate ( AlleleFrequency = cut ( MAF, seq (0 , 1 , 0 .25 ))) %>% group_by ( AlleleFrequency, CLST ) %>% summarise ( FractionOfSNPs = n () /nrow ( freq ) * 100) # Create a bar graph png ( '/home/manager/data/Data_Day4/out/MAF_ancestry_analysis.png' , unit = 'px' , res =300 , width =3500 , height =4500) maf_ancestry <- ggplot ( na.omit ( plotDat ) , aes ( AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST )) + geom_line () + scale_y_continuous ( limits = c (0 , 12)) + ggtitle ( \"Distribution of allele frequency across genome\" ) print ( maf_ancestry ) dev.off () Examine the plot the MAF across each ancestry: # This does not work when you are in R, ensure you out of R before running: xdg-open MAF_ancestry_analysis.png","title":"3. Distribution of allele frequencies"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#questions_1","text":"","title":"Questions"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#i-which-population-has-the-most-snps","text":"","title":"(i) Which population has the most SNPs?"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#ii-what-is-the-significance-of-the-observed-population-ordering","text":"","title":"(ii) What  is the significance of the observed population ordering?"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#iii-what-is-the-reason-behind-these-two-features","text":"","title":"(iii) What is the reason behind these two features?"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#introduction-to-prs-csx","text":"","title":"Introduction to PRS-CSx"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#5-background-to-prs-csx","text":"PRS-CSx is a Python based command line tool that integrates GWAS summary statistics and LD reference data from multiple populations to estimate population-specific PRS. PRS-CSx applies a Bayesian model with a continuous shrinkage prior to SNP effects genome-wide. Sparseness of the genetic architecture across populations is controlled by a parameter phi. For a given value of phi, PRS-CSx uses Markov chain Monte Carlo to sample from the posterior of SNP effects from which the mean SNP effects are calculated and used in the PRS.","title":"5. Background to PRS-CSX"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-1-set-up-environment","text":"First change to the working directory with the data for this practical cd /home/manager/data/Data_Day4/data Make a directory called hm3_by_ancestry within the data folder, and move a folder back out of the data folder mkdir hm3_by_ancestry cd .. AFR for chr in {21..22}; do \\ /home/manager/data/Data_Day4/software/plink_linux \\ --bfile /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --chr $chr \\ --make-bed \\ --out /home/manager/data/Data_Day4/data/hm3_by_ancestry/AFR_1kg.hm3.chr${chr}_only.csx; done EUR for chr in {21..22}; do \\ /home/manager/data/Data_Day4/software/plink_linux \\ --bfile /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --chr $chr \\ --make-bed \\ --out /home/manager/data/Data_Day4/data/hm3_by_ancestry/EUR_1kg.hm3.chr${chr}_only.csx; done Set up the necessary environment variables for threading and verify they are set correctly. export N_THREADS=2 export MKL_NUM_THREADS=$N_THREADS export NUMEXPR_NUM_THREADS=$N_THREADS export OMP_NUM_THREADS=$N_THREADS Verify the variables are set echo $N_THREADS echo $MKL_NUM_THREADS echo $NUMEXPR_NUM_THREADS echo $OMP_NUM_THREADS","title":"Step 1: Set up environment"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-2-run-csx-derive-new-snps-weights-trained-on-european-and-african-summary-stats","text":"Generate job file containing the threaded PRScsx commands. First, to minimize computational resources and time, we should create a script to run the tasks in parallel. Make a script called create_multithread.sh nano create_multithread.sh Then copy and paste the code below into that script. After save, then close the script ctrl + x #!/bin/bash # Create the script file SCRIPT_FILE = \"multithread.sh\" # Write the header of the script file echo \"#!/bin/bash\" > $SCRIPT_FILE for chr in {21 ..22 } ; do echo \"python3 /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir=/home/manager/data/Data_Day4/reference/csx \\ --bim_prefix=/home/manager/data/Data_Day4/data/hm3_by_ancestry/AFR_1kg.hm3.chr ${ chr } _only.csx \\ --sst_file=/home/manager/data/Data_Day4/data/3b/data/sumstats_by_chr/EUR-SBP-simulated.sumstats.chr ${ chr } ,/home/manager/data/Data_Day4/data/3b/data/sumstats_by_chr/AFR-SBP-simulated.sumstats.chr ${ chr } \\ --n_gwas=25732,4855 \\ --chrom= ${ chr } \\ --n_iter=1000 \\ --n_burnin=500 \\ --thin=5 \\ --pop=EUR,AFR \\ --phi=1e-4 \\ --out_dir=/home/manager/data/Data_Day4/out/csx \\ --out_name=afr.target_chr ${ chr } .csx\" >> $SCRIPT_FILE done Run: Ctrl + O, followed by Enter ' to save ' Run: Ctrl + X, to Exit You will need to change permission for the script to be able to execute chmod +x create_multithread.sh Run the builder ./create_multithread.sh To be able to run the next command you first install 'parallel' sudo apt install parallel Run the Job File with GNU Parallel: (May take a while) parallel --verbose --jobs $N_THREADS < multithread.sh","title":"Step 2: Run CSX. Derive new SNPs weights trained on European and African summary stats"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-3-combine-csx-derived-snp-weights-across-chromosomes-currently-excludes-chromosome-3","text":"Load R and the necessary library R Call in the package library(dplyr) Define the path to the directory containing the PRS-CSX output files path <- \"/home/manager/data/Data_Day4/out/csx\" Define the ancestry you want to combine (\"EUR\" or \"AFR\") ancestry <- \"EUR\" Initialize an empty data frame to store the combined data combined_data <- data.frame() Loop through chromosomes 21 to 22, (currently excluding chromosome 3) for (chr in setdiff(21:22, 3)) { # Construct the file name file_name <- paste0(\"afr.target_chr\", chr, \".csx_\", ancestry, \"_pst__a1_b0.5_phi1e-04_chr\", chr, \".txt\") file_path <- file.path(path, file_name) # Check if file exists before reading if (file.exists(file_path)) { # Read the data from the file data <- read.table(file_path, header = FALSE, sep = \"\\t\", col.names = c(\"CHR\", \"rsid\", \"pos\", \"ref\", \"alt\", \"beta\")) # Combine the data combined_data <- rbind(combined_data, data) } else { warning(paste(\"File not found:\", file_path)) } } Write the combined data to a new file output_file <- file.path(path, paste0(\"combined_\", ancestry, \"_pst_.txt\")) write.table(combined_data, output_file, sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE)","title":"Step 3: Combine CSX-derived SNP weights across chromosomes (Currently Excludes Chromosome 3)"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#task-replace-ancestry-eur-with-ancestry-afr-and-repeat-the-subsequent-steps-shown-above","text":"","title":"Task: Replace 'ancestry &lt;- \"EUR\" ' with 'ancestry &lt;- \"AFR\" ' and repeat the subsequent steps shown above"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-4-merge-genotype-phenotype-data","text":"Prepare data The data is slow to merge unless you split the input bim file into just chr21 and chr22 (Q- why are those faster?) cd /home/manager/data/Data_Day4/data/3b/data/ plink --bfile AFR_1kg.hm3.only.csx --chr 21 22 --make-bed --out AFR_1kg.hm3.only.csx_21_22 Start R with sudo rights to allow you to install sudo R # Load libraries. For any unavailable package, install it with **install.packages(\"_package_name\")** install.packages(\"BiocManager\") BiocManager::install(\"snpStats\") library(data.table) library(ggplot2) library(snpStats) # Define the path to the directory containing the PLINK files and phenotypic data plink_path <- \"/home/manager/data/Data_Day4/data/3b/data/\" # Read PLINK files and phenotype data into R bim_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.bim\") fam_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.fam\") bed_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.bed\") pheno_file <- file.path(plink_path, \"sbp_afr_1kg.sim_pheno\") # Read the genotype data using snpStats geno_data <- read.plink(bed_file, bim_file, fam_file) # Extract SNP IDs from geno_data$map$snp.name snp_ids <- geno_data$map$snp.name if (is.null(snp_ids) || !is.character(snp_ids)) { stop(\"SNP IDs are missing or not in the correct format.\") } # Convert the genotype data to a matrix and then to a data.table geno_matrix <- as(geno_data$genotypes, \"matrix\") geno_df <- data.table(geno_matrix) setnames(geno_df, snp_ids) # Add IID column from the fam file geno_df[, IID := geno_data$fam$member] # Read the phenotypic data** pheno_data <- fread(pheno_file, sep = \" \", header = TRUE) Merge phenotype and genotype data # Do merge combined_data <- merge(pheno_data, geno_df, by = \"IID\") # Keep only genotype columns geno <- combined_data[, !names(combined_data) %in% c(\"FID\", \"IID\", \"pheno100\", \"pheno20\", \"pheno33\", \"pheno10\"), with = FALSE] phen <- combined_data$pheno100 # Convert geno to numeric matrix** geno <- as.matrix(geno) mode(geno) <- \"numeric\" # Convert phen to vector phen <- as.vector(phen)","title":"Step 4: Merge genotype-phenotype data"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-5-split-data-into-validation-and-test-sets","text":"Specify Proportion # Here we specify that 40% of all IDs will be used to construct the validation group set.seed(154) vali_proportion <- 0.4 vali_size <- round(nrow(geno) * vali_proportion) vali_indices <- sample(1:nrow(geno), vali_size, replace = FALSE) test_indices <- setdiff(1:nrow(geno), vali_indices) Subsetting of individuals X_vali <- geno[vali_indices, , drop=FALSE] y_vali <- phen[vali_indices] X_test <- geno[test_indices, , drop=FALSE] y_test <- phen[test_indices]","title":"Step 5: Split data into validation and test sets"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-6-prepare-the-regression-model-input-using-the-csx-derived-afr-and-eur-weights","text":"# Read the merged CSX output files AFR_betas <- fread(file.path(\"/home/manager/data/Data_Day4/out/csx/combined_AFR_pst_eff.txt\"), sep = \"\\t\", header = TRUE) EUR_betas <- fread(file.path(\"/home/manager/data/Data_Day4/out/csx/combined_EUR_pst_eff.txt\"), sep = \"\\t\", header = TRUE) # Assuming the beta files have columns: \"CHR\", \"rsid\", \"pos\", \"ref\", \"alt\", \"beta\" overlap_prs <- merge(AFR_betas, EUR_betas, by = \"rsid\", suffixes = c(\"_afr\", \"_eur\")) # Filter overlap_prs to include only SNPs present in X_vali overlap_prs <- overlap_prs[rsid %in% colnames(X_vali)] # Ensure that X_vali and X_test only contain SNPs present in W_afr and W_eur common_snps <- intersect(colnames(X_vali), overlap_prs$rsid) X_vali <- X_vali[, common_snps, drop=FALSE] X_test <- X_test[, common_snps, drop=FALSE] # Reorder the columns of X_vali and X_test to match the order of SNPs in overlap_prs X_vali <- X_vali[, match(overlap_prs$rsid, colnames(X_vali)), drop=FALSE] X_test <- X_test[, match(overlap_prs$rsid, colnames(X_test)), drop=FALSE] # Extract the overlapping rsid and their corresponding betas W_afr <- overlap_prs$beta_afr W_eur <- overlap_prs$beta_eur # Convert W_afr and W_eur to numeric vectors W_afr <- as.numeric(W_afr) W_eur <- as.numeric(W_eur)","title":"Step 6: Prepare the regression model input using the CSX-derived AFR and EUR weights"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-7-prepare-the-variant-weights-matrices-as-vectors","text":"# Pre-check the alignment between the different objects if (ncol(X_vali) != length(W_afr) || ncol(X_vali) != length(W_eur)) { stop(\"Dimensions of X_vali and W_afr/W_eur do not match.\") } # In the validation sample: # (i) Compute XWafr_vali XWafr_vali <- X_vali %*% W_afr # (ii) Convert XWafr_vali to have zero mean and unit variance XWafr_vali_z <- scale(XWafr_vali) # (iii) Compute XWeur_vali XWeur_vali <- X_vali %*% W_eur # (iv) Convert XWeur_vali to have zero mean and unit variance XWeur_vali_z <- scale(XWeur_vali) # (v) Combine the normalized matrices XW_vali <- cbind(XWafr_vali_z, XWeur_vali_z) # Fit the model model <- lm(scale(y_vali) ~ XWafr_vali_z + XWeur_vali_z - 1) # '- 1' removes the intercept # Obtain the regression parameters a_hat <- coef(model)[1] b_hat <- coef(model)[2] print(paste(\"a_hat =\", a_hat)) print(paste(\"b_hat =\", b_hat))","title":"Step 7: Prepare the variant weights matrices as vectors"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-8-predict-phenotype-on-validation-and-test-dataset","text":"Generate a linear combination of AFR and EUR PRSs for each individual # Each ancestry component is weighted by the regression coicient of that ancestry, in the preceding step y_hat_vali <- a_hat * XWafr_vali_z + b_hat * XWeur_vali_z # In the test sample: # Compute XWafr_test and XWeur_test XWafr_test <- X_test %*% W_afr XWafr_test_z <- scale(XWafr_test) XWeur_test <- X_test %*% W_eur XWeur_test_z <- scale(XWeur_test) # y_hat in the test sample y_hat <- a_hat * XWafr_test_z + b_hat * XWeur_test_z","title":"Step 8: Predict phenotype on validation and test dataset"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-9-plot-phenotype-distributions-of-validation-and-test-data","text":"Check that both distributions are approximately normal library(ggplot2) # Create data frames for validation and test sets vali_data <- data.frame(trait = y_vali, dataset = \"Validation\") test_data <- data.frame(trait = y_test, dataset = \"Test\") # Combine both data frames combined_data <- rbind(vali_data, test_data) # Plot the distributions ggplot(combined_data, aes(x = trait, fill = dataset)) + geom_density(alpha = 0.5) + labs(title = \"Trait Distributions for Validation and Test Sets\", x = \"Trait Value\", y = \"Density\") + theme_minimal()","title":"Step 9: Plot phenotype distributions of validation and test data:"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#step-10-plot-true-values-against-predicted-values","text":"The next steps use standard normal phenotype data to reduce scale differences between PRS and trait values min_true <- min(min(y_vali), min(y_test)) max_true <- max(max(y_vali), max(y_test)) min_pred <- min(min(y_hat_vali), min(y_hat)) max_pred <- max(max(y_hat_vali), max(y_hat)) pdf(\"true_against_pred.pdf\", width = 10, height = 5) par(mfrow = c(1, 2)) plot(scale(y_vali), y_hat_vali, pch = 19, col = rgb(0, 0, 0, 0.5), xlab = 'True Values', ylab = 'Predicted Values', main = 'Validation Dataset') abline(0, 1, col = 'red', lty = 2) plot(scale(y_test), y_hat, pch = 19, col = rgb(0, 0, 0, 0.5), xlab = 'True Values', ylab = 'Predicted Values', main = 'Test Dataset') abline(0, 1, col = 'red', lty = 2) dev.off() Step 11: Calculate deviance-based R 2 # Calculate the deviance (SS_res) deviance <- sum((scale(y_test) - y_hat) ^ 2) print(paste(\"deviance =\", deviance)) # Calculate the mean of the scaled y_test y_test_mean <- mean(scale(y_test)) # Calculate the null deviance (SS_tot) deviance_null <- sum((scale(y_test) - y_test_mean)^ 2) print(paste(\"deviance_null =\", deviance_null)) # Calculate R2 R2 <- 1 - (deviance / deviance_null) print(paste(\"R2 =\", R2))","title":"Step 10: Plot true values against predicted values"},{"location":"tmp/practical_docs_hidden/Day3b.docx/#results","text":"graph: pdf true against pred","title":"Results"},{"location":"tmp/practical_docs_hidden/Day4a.docx/","text":"BridgePRS Learning Objectives In the previous lecture we covered in detail the modelling used by BridgePRS. Here we will use the BridgePRS software to apply the method. The aim of this practical is to provide you with a basic understanding and some experience of running BridgePRS software. After completing this practical, you should: Be able to perform cross-population analyses. Set up the configuration files used as input by the software. Be familiar with running cross-ancestry PRS analyses using PRS-CSx. BridgePRS input data In the BridgePRS directory there is a data folder which we will use in this practical. View the data directory $ ls -l data total 5368 drwxr-xr-x 73 hoggac01 staff 2336 26 Jul 16:00 1000G_sample -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 afr.config -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 eas.config -rw-r--r-- 1 hoggac01 staff 410 12 Aug 14:35 eur.config drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_AFR drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_EAS drwxr-xr-x 5 hoggac01 staff 160 7 Aug 20:30 pop_EUR -rw-r--r-- 1 hoggac01 staff 200376 7 Aug 21:30 qc_snplist.txt The pop_* folders contain simulated genotype, phenotype and GWAS summary statistics representative of Europeans, East Asians and Africans for input to BridgePRS. Each pop_* folder is split into summary statistics, and individual level genotype and phenotype folders, e.g. $ ls -l data/pop_AFR/ total 0 drwxr-xr-x 68 hoggac01 staff 2176 14 Jul 17:22 genotypes drwxr-xr-x 4 hoggac01 staff 128 14 Jul 17:22 phenotypes drwxr-xr-x 68 hoggac01 staff 2176 12 Aug 11:02 sumstats Look at each directory e.g. ls pop_AFR/genotypes . There are two sets of summary statistics in each sumstats folder from the analysis of the same simulated continuos phenotype, the \"half\" files were generated using half the sample size. For computation speed the summary statistics only have a small subset of SNPs, 19k-20k genomewide zcat data/pop_EAS/sumstats/EAS.chr* | wc -l zcat data/pop_EUR/sumstats/EUR.chr* | wc -l zcat data/pop_AFR/sumstats/AFR.chr* | wc -l or on a Mac gzcat data/pop_EAS/sumstats/EAS.chr* | wc -l gzcat data/pop_EUR/sumstats/EUR.chr* | wc -l gzcat data/pop_AFR/sumstats/AFR.chr* | wc -l Results in these files are only shown for SNP with MAF>0. The SNPs are a subset of the HapMap panel, there seems to be a bias to polymorphoic EUR SNPs. Take a look a look at the files, e.g. zcat data/pop_AFR/sumstats/AFR.chr19.glm.linear.gz | head zcat data/pop_AFR/sumstats/AFR_half.chr19.glm.linear.gz | head again use gzcat on a Mac. In the OBS_CT column you'll see can that the \"_half\" summary statistics files have half the sample size, 10,000 compared to 20,000 for the EAS and AFR populations and 40,000 compared to 80,000 for the EUR population. The same SNPs are contained in each set of summary statistics. The phenotypes folders has two files: \"test\" and \"validation\" with IDs, the outcome phenotype and covariates. \"Test\" data is used to optimise the PRS and \"validation\" data is not used to estimate the PRS, it is just to assess model performance. The genotypes folders are in plink1.9 format and are split by chromosome. These folders contain the genetic data for individuals in the phenotypes folder. Test data will only be used for individuals with both genotype and phenotype information. Similarly model performance metrics will only use samples with both genotype and phenotype information, however, predictions are generated for all validation samples with genotype data. Passing arguments to run BridgePRS Example run of BridgePRS: ./bridgePRS pipeline go -o out/ --config_files data/eas.config data/eur.config --fst 0.11 --phenotype y --cores 4 --restart Arguments can be passed to BridgePRS on both the commandline and in config files. config files, used above, are a neat way to store population specific arguments, therefore for a standard two population analysis two config are required. By default the first config file is for the target population and the second is for the base population. The -o argument specifies the output folder. The --fst argument is used to specify a prior distribution used in the BridgePRS analysis and should be the Fst between the base and target populations used in the analysis. Our first analysis uses European base data and East Asian target data, the Fst between these populations is 0.11. The --phenotype argument specifies the column label of the phenotype in the test and validation files, e.g. EAS_valid.dat . The --cores argument specifies the number of cores used in the analysis. A full list of arguments that can be used on the commandline can be found here.... The *.config files .config files to tell the software where to find the required input files and the column headers of the summary statistics files, take a look, e.g. cat data/eas.config LD_PATH=1000G_sample LDPOP=EAS POP=EAS SUMSTATS_PREFIX=pop_EAS/sumstats/EAS.chr #SUMSTATS_PREFIX=pop_EAS/sumstats/EAS_half.chr SUMSTATS_SUFFIX=.glm.linear.gz GENOTYPE_PREFIX=pop_EAS/genotypes/chr PHENOTYPE_FILE=pop_EAS/phenotypes/EAS_test.dat VALIDATION_FILE=pop_EAS/phenotypes/EAS_valid.dat COVARIATES=PC1,PC2 SNP_FILE=qc_snplist.txt SSF-P=P SSF-SNPID=ID SSF-SE=SE SSF-SS=OBS_CT SSF-BETA=BETA SSF-REF=REF SSF-ALT=A1 SSF-MAF=A1_FREQ This config file conatins all possible arguments that can be used in config files. config files use the same argument names as the commandline arguments but in uppercase, and use \"=\" instead of a space between the argument name and the argument being passed. The POP argument simply labels the population used in this .config file for output. Estimating Linkage Dissequilibrium (LD) BridgePRS requires individual level genetic data in plink1.9 binary format to estimate linkage dissequilibrium (LD) in the populations which produced the GWAS summary statistics. The genotype test and validation data could be used, i.e. data in these folders pop_/genotypes/. If these data are small, less than 500 samples, or are not representative of the GWAS population we provide 1000 Genomes (1000G) data to estimate LD. Suitable 1000G data for this analysis is in the 1000G_sample folder for the small subset of SNPs used in these examples. The .config points to the folder with reference LD data by the LD_PATH argument in the config file. LD reference data is available for the five 1000G super population (abbreviations required to use in brackets): East Asian (EAS), South Asian (SAS), European (Eur), African (AFR) and American (AMR). For real data analyses 1000G reference data for larger subsets of SNPs can be downloaded here Can you work out what the other arguments are doing? BridgePRS output The main output is in the folder out/prs-combined_EAS-EUR/ . First view the output summary plot evince out/prs-combined_AFR-EUR/bridge.afr-eur.prs-combined.result.pdf on a Mac simply use open instead of evince . The barplot at the top which shows the varaince explained (R2) by the three PRS BridgePRS estimates and the variance explained by a weighted average of the three model. The weighted model is BridgePRS estimated \"best\" PRS This weighted combined PRS should be used. The three separate PRS estimated by BridgePRS are: * PRS using a prior effect-size distribution from the European model -- stage2 model * PRS using only the target (Non-European) dataset, stage 1 analysis - stage 1 model * PRS using both stage 1 and stage 2 results - stage1+2 model Each of these 3 models are given weights corresponding to how well they fit the test data. These weights are then used to combine the PRS to give the single weighted combined PRS. The models, stage1, stage2 and stage1+2, should not be used unless users have a strong prior belief that the models is better, i.e. Stage 2 model reflects the belief that the target population GWAS is only informative in conjugtion with the base population GWAS. Stage 1 model reflects the belief that the target population GWAS is informative and the base population GWAS gives no addition information. Stage 1+2 model reflects the belief both the base and target population GWAS contribute independent information. EAS_weighted_combined_preds.dat has PRS predictions for samples in the validation data using all four models: stage1, stage2, stage1+2 and weighted. EAS_weighted_combined_snp_weights.dat has the SNP weights for the combined to allow this model to be applied to other samples. Using BridgePRS without target summary statistics Often GWAS summary statistics are only available in one population. BridgePRS can use these summary statistics and optimise them to estimate a PRS for another target population given individual level from the target population. Here is an example ./bridgePRS prs-single run -o out_single/ --config_files data/eur_eas.config --phenotype y --cores 10 Look at data/eur_eas.config , the file uses EUR GWAS summary statistics and EAS test and validation data. Results of interest are written to the folder out_single/prs-single_EAS/quantify/ . Model performance is shown in the file EAS_quantify_var_explained.txt and plotted in .... See hpw these results compare with the previous analysis which included EAS GWAS summary statistics. cat out_single/prs-single_EAS/quantify/EAS_quantify_var_explained.txt cat out/prs-combined_EAS-EUR/EAS_weighted_combined_var_explained.txt This single summary statistic analysis is equilvant to the stage 2 analysis previously but with all the weight on the EUR prior. The superior performance of the previous stage 2 analysis shows how the EAS summary statistics have been incorporated to improve the PRS. Further analysis with BridgePRS African analysis Run BridgePRS again to estimate PRS in Africans using afr.config . Qustions? In addition to pointing to differnt input files what other difference is there between the EAS and AFR config files? How do the results for EAS and AFR compare? Analyses with other GWAS summary statistics For each population the config files contain commented out links to GWAS summary statistics of the same phenotype using half the same size: 40k for EUR and 10k for both EAS and AFR. Edit eas.config to use the EAS 10k GWAS summary statistics. To run the analysis write results to a new output directory e.g. out_half_target . Run the similar analysis for African samples by editing afr.config . Compare with previous results using the 10k EAS and EAS GWAS. Compare EAS and AFR results. Check you've run the analyses using the correct GWAS summary statistics, e.g. less less out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log less less out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log or grep Sumstats out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log grep Sumstats out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log If you have made a mistake, correct and run again using the --restart flag which deletes the previously genereated results. Qustions? How has using the less well powered EAS and AFR GWAS affected the predictive accuracy of the BridgePRS models? How do AFR and EUR results compare? Analyses with smaller EUR GWAS summary statistics Edit the config files again to run analyses using the 40k EUR GWAS (i.e. EUR_half ) and the 20k EAS and AFR GWAS and write to results to a new directory e.g. out_half_eur . Qustions?","title":"Day4a.docx"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#bridgeprs","text":"","title":"BridgePRS"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#learning-objectives","text":"In the previous lecture we covered in detail the modelling used by BridgePRS. Here we will use the BridgePRS software to apply the method. The aim of this practical is to provide you with a basic understanding and some experience of running BridgePRS software. After completing this practical, you should: Be able to perform cross-population analyses. Set up the configuration files used as input by the software. Be familiar with running cross-ancestry PRS analyses using PRS-CSx.","title":"Learning Objectives"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#bridgeprs-input-data","text":"In the BridgePRS directory there is a data folder which we will use in this practical. View the data directory $ ls -l data total 5368 drwxr-xr-x 73 hoggac01 staff 2336 26 Jul 16:00 1000G_sample -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 afr.config -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 eas.config -rw-r--r-- 1 hoggac01 staff 410 12 Aug 14:35 eur.config drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_AFR drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_EAS drwxr-xr-x 5 hoggac01 staff 160 7 Aug 20:30 pop_EUR -rw-r--r-- 1 hoggac01 staff 200376 7 Aug 21:30 qc_snplist.txt The pop_* folders contain simulated genotype, phenotype and GWAS summary statistics representative of Europeans, East Asians and Africans for input to BridgePRS. Each pop_* folder is split into summary statistics, and individual level genotype and phenotype folders, e.g. $ ls -l data/pop_AFR/ total 0 drwxr-xr-x 68 hoggac01 staff 2176 14 Jul 17:22 genotypes drwxr-xr-x 4 hoggac01 staff 128 14 Jul 17:22 phenotypes drwxr-xr-x 68 hoggac01 staff 2176 12 Aug 11:02 sumstats Look at each directory e.g. ls pop_AFR/genotypes . There are two sets of summary statistics in each sumstats folder from the analysis of the same simulated continuos phenotype, the \"half\" files were generated using half the sample size. For computation speed the summary statistics only have a small subset of SNPs, 19k-20k genomewide zcat data/pop_EAS/sumstats/EAS.chr* | wc -l zcat data/pop_EUR/sumstats/EUR.chr* | wc -l zcat data/pop_AFR/sumstats/AFR.chr* | wc -l or on a Mac gzcat data/pop_EAS/sumstats/EAS.chr* | wc -l gzcat data/pop_EUR/sumstats/EUR.chr* | wc -l gzcat data/pop_AFR/sumstats/AFR.chr* | wc -l Results in these files are only shown for SNP with MAF>0. The SNPs are a subset of the HapMap panel, there seems to be a bias to polymorphoic EUR SNPs. Take a look a look at the files, e.g. zcat data/pop_AFR/sumstats/AFR.chr19.glm.linear.gz | head zcat data/pop_AFR/sumstats/AFR_half.chr19.glm.linear.gz | head again use gzcat on a Mac. In the OBS_CT column you'll see can that the \"_half\" summary statistics files have half the sample size, 10,000 compared to 20,000 for the EAS and AFR populations and 40,000 compared to 80,000 for the EUR population. The same SNPs are contained in each set of summary statistics. The phenotypes folders has two files: \"test\" and \"validation\" with IDs, the outcome phenotype and covariates. \"Test\" data is used to optimise the PRS and \"validation\" data is not used to estimate the PRS, it is just to assess model performance. The genotypes folders are in plink1.9 format and are split by chromosome. These folders contain the genetic data for individuals in the phenotypes folder. Test data will only be used for individuals with both genotype and phenotype information. Similarly model performance metrics will only use samples with both genotype and phenotype information, however, predictions are generated for all validation samples with genotype data.","title":"BridgePRS input data"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#passing-arguments-to-run-bridgeprs","text":"Example run of BridgePRS: ./bridgePRS pipeline go -o out/ --config_files data/eas.config data/eur.config --fst 0.11 --phenotype y --cores 4 --restart Arguments can be passed to BridgePRS on both the commandline and in config files. config files, used above, are a neat way to store population specific arguments, therefore for a standard two population analysis two config are required. By default the first config file is for the target population and the second is for the base population. The -o argument specifies the output folder. The --fst argument is used to specify a prior distribution used in the BridgePRS analysis and should be the Fst between the base and target populations used in the analysis. Our first analysis uses European base data and East Asian target data, the Fst between these populations is 0.11. The --phenotype argument specifies the column label of the phenotype in the test and validation files, e.g. EAS_valid.dat . The --cores argument specifies the number of cores used in the analysis. A full list of arguments that can be used on the commandline can be found here....","title":"Passing arguments to run BridgePRS"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#the-config-files","text":".config files to tell the software where to find the required input files and the column headers of the summary statistics files, take a look, e.g. cat data/eas.config LD_PATH=1000G_sample LDPOP=EAS POP=EAS SUMSTATS_PREFIX=pop_EAS/sumstats/EAS.chr #SUMSTATS_PREFIX=pop_EAS/sumstats/EAS_half.chr SUMSTATS_SUFFIX=.glm.linear.gz GENOTYPE_PREFIX=pop_EAS/genotypes/chr PHENOTYPE_FILE=pop_EAS/phenotypes/EAS_test.dat VALIDATION_FILE=pop_EAS/phenotypes/EAS_valid.dat COVARIATES=PC1,PC2 SNP_FILE=qc_snplist.txt SSF-P=P SSF-SNPID=ID SSF-SE=SE SSF-SS=OBS_CT SSF-BETA=BETA SSF-REF=REF SSF-ALT=A1 SSF-MAF=A1_FREQ This config file conatins all possible arguments that can be used in config files. config files use the same argument names as the commandline arguments but in uppercase, and use \"=\" instead of a space between the argument name and the argument being passed. The POP argument simply labels the population used in this .config file for output.","title":"The *.config files"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#estimating-linkage-dissequilibrium-ld","text":"BridgePRS requires individual level genetic data in plink1.9 binary format to estimate linkage dissequilibrium (LD) in the populations which produced the GWAS summary statistics. The genotype test and validation data could be used, i.e. data in these folders pop_/genotypes/. If these data are small, less than 500 samples, or are not representative of the GWAS population we provide 1000 Genomes (1000G) data to estimate LD. Suitable 1000G data for this analysis is in the 1000G_sample folder for the small subset of SNPs used in these examples. The .config points to the folder with reference LD data by the LD_PATH argument in the config file. LD reference data is available for the five 1000G super population (abbreviations required to use in brackets): East Asian (EAS), South Asian (SAS), European (Eur), African (AFR) and American (AMR). For real data analyses 1000G reference data for larger subsets of SNPs can be downloaded here Can you work out what the other arguments are doing?","title":"Estimating Linkage Dissequilibrium (LD)"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#bridgeprs-output","text":"The main output is in the folder out/prs-combined_EAS-EUR/ . First view the output summary plot evince out/prs-combined_AFR-EUR/bridge.afr-eur.prs-combined.result.pdf on a Mac simply use open instead of evince . The barplot at the top which shows the varaince explained (R2) by the three PRS BridgePRS estimates and the variance explained by a weighted average of the three model. The weighted model is BridgePRS estimated \"best\" PRS This weighted combined PRS should be used. The three separate PRS estimated by BridgePRS are: * PRS using a prior effect-size distribution from the European model -- stage2 model * PRS using only the target (Non-European) dataset, stage 1 analysis - stage 1 model * PRS using both stage 1 and stage 2 results - stage1+2 model Each of these 3 models are given weights corresponding to how well they fit the test data. These weights are then used to combine the PRS to give the single weighted combined PRS. The models, stage1, stage2 and stage1+2, should not be used unless users have a strong prior belief that the models is better, i.e. Stage 2 model reflects the belief that the target population GWAS is only informative in conjugtion with the base population GWAS. Stage 1 model reflects the belief that the target population GWAS is informative and the base population GWAS gives no addition information. Stage 1+2 model reflects the belief both the base and target population GWAS contribute independent information. EAS_weighted_combined_preds.dat has PRS predictions for samples in the validation data using all four models: stage1, stage2, stage1+2 and weighted. EAS_weighted_combined_snp_weights.dat has the SNP weights for the combined to allow this model to be applied to other samples.","title":"BridgePRS output"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#using-bridgeprs-without-target-summary-statistics","text":"Often GWAS summary statistics are only available in one population. BridgePRS can use these summary statistics and optimise them to estimate a PRS for another target population given individual level from the target population. Here is an example ./bridgePRS prs-single run -o out_single/ --config_files data/eur_eas.config --phenotype y --cores 10 Look at data/eur_eas.config , the file uses EUR GWAS summary statistics and EAS test and validation data. Results of interest are written to the folder out_single/prs-single_EAS/quantify/ . Model performance is shown in the file EAS_quantify_var_explained.txt and plotted in .... See hpw these results compare with the previous analysis which included EAS GWAS summary statistics. cat out_single/prs-single_EAS/quantify/EAS_quantify_var_explained.txt cat out/prs-combined_EAS-EUR/EAS_weighted_combined_var_explained.txt This single summary statistic analysis is equilvant to the stage 2 analysis previously but with all the weight on the EUR prior. The superior performance of the previous stage 2 analysis shows how the EAS summary statistics have been incorporated to improve the PRS.","title":"Using BridgePRS without target summary statistics"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#further-analysis-with-bridgeprs","text":"","title":"Further analysis with BridgePRS"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#african-analysis","text":"Run BridgePRS again to estimate PRS in Africans using afr.config .","title":"African analysis"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#qustions","text":"In addition to pointing to differnt input files what other difference is there between the EAS and AFR config files? How do the results for EAS and AFR compare?","title":"Qustions?"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#analyses-with-other-gwas-summary-statistics","text":"For each population the config files contain commented out links to GWAS summary statistics of the same phenotype using half the same size: 40k for EUR and 10k for both EAS and AFR. Edit eas.config to use the EAS 10k GWAS summary statistics. To run the analysis write results to a new output directory e.g. out_half_target . Run the similar analysis for African samples by editing afr.config . Compare with previous results using the 10k EAS and EAS GWAS. Compare EAS and AFR results. Check you've run the analyses using the correct GWAS summary statistics, e.g. less less out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log less less out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log or grep Sumstats out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log grep Sumstats out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log If you have made a mistake, correct and run again using the --restart flag which deletes the previously genereated results.","title":"Analyses with other GWAS summary statistics"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#qustions_1","text":"How has using the less well powered EAS and AFR GWAS affected the predictive accuracy of the BridgePRS models? How do AFR and EUR results compare?","title":"Qustions?"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#analyses-with-smaller-eur-gwas-summary-statistics","text":"Edit the config files again to run analyses using the 40k EUR GWAS (i.e. EUR_half ) and the 20k EAS and AFR GWAS and write to results to a new directory e.g. out_half_eur .","title":"Analyses with smaller EUR GWAS summary statistics"},{"location":"tmp/practical_docs_hidden/Day4a.docx/#qustions_2","text":"","title":"Qustions?"},{"location":"tmp/practical_docs_hidden/Day4b.docx/","text":"Day 4 - Practical 2: Introduction to Admixture analysis Module Goals The goal of this practical is to provide you with basic understanding of Admixture and the basic elements behind Admixture PRS scores. Upon completion of this practical, you should: * Gain familiarity with a variety of tools used in the context of admixed population research * Go through the basic steps of formulating admixture-informed polygenic risk scores Part1: Plot Decay of Ancestry LD over time Here we explore how Admixture LD varies over time and as a function of the genetic distance between loci. In R: library(ggplot2) library(reshape2) library(viridis) #range of values of r (recombination fraction) r = seq(0, 0.5, 0.1) dtmat = matrix(NA, nrow = 6, ncol = 10) # matrix to store values of dt for(i in 1:6){ dt = 0.25 for(j in 1:10){ dtmat[i,j] = dt dt = dt*(1 -r[i])^j } } dtmat = reshape2::melt(dtmat) colnames(dtmat) = c(\"r\",\"g\",\"Dt\") dtmat$r = (dtmat$r - 1)/10 ggplot(dtmat, aes(x = g, y = Dt, group = r, color = as.factor(r))) + geom_line(linewidth = 1.2) + theme_minimal(base_size = 14) + theme( axis.text = element_text(size = 14), axis.title = element_text(size = 16), legend.title = element_text(size = 14), legend.text = element_text(size = 12), plot.title = element_text(size = 18, face = \"bold\"), plot.subtitle = element_text(size = 14), panel.grid.major = element_line(color = \"gray80\") ) + scale_color_viridis_d() + scale_x_continuous(breaks = c(1:10)) + labs( title = \"Decay of Linkage Disequilibrium Over Generations\", subtitle = \"Effect of Recombination Fraction (r) on Admixture LD\", x = \"Generations since admixture (t)\", y = \"Admixture LD\", color = \"Recombination Fraction (r)\" ) Questions (i) Describe what happens to admixture LD over time? (ii) Why does recombination also have an impact? Part 2: Global Ancestry Inference We will now run an analysis using the software ADMIXTURE to calculate global ancestry proportions across a sample of 28 individuals. Here we perform a supervised analysis. Please execute the following code from location ~/RFMIX_WCS_2024/data/plink/ ./admixture samples_n28_qc_thin.bed 2 --supervised -j4 Questions (i) What do you think the number specified after the inout file represents? The next step is to create a plot the results # Plot Global Ancestry Results R library(ggplot2) library(reshape2) # Read the data from files fam <- read.table(\"samples_n28_qc_thin.fam\", header = FALSE) pop <- read.table(\"samples_n28_qc_thin.pop\", header = FALSE) Q <- read.table(\"samples_n28_qc_thin.2.Q\", header = FALSE) # Merge the data into one data frame merged_data <- cbind(fam, pop, Q) # Extract necessary columns (assuming the structure of the files as in the image) colnames(merged_data) <- c(\"FID\", \"IID\", \"PaternalID\", \"MaternalID\", \"Sex\", \"Phenotype\", \"Population\", \"AFR\", \"EUR\") # Order data by decreasing AFR merged_data <- merged_data[order(-merged_data$AFR), ] # Prepare data for plotting plot_data <- merged_data[, c(\"IID\", \"AFR\", \"EUR\")] plot_data$IID <- factor(plot_data$IID, levels = plot_data$IID) # Ensure order is maintained in plot plot_data_melted <- melt(plot_data, id.vars = \"IID\") # Create the plot p <- ggplot(plot_data_melted, aes(x = IID, y = value, fill = variable)) + geom_bar(stat = \"identity\", position = \"stack\") + scale_fill_manual(values = c(\"AFR\" = \"red\", \"EUR\" = \"darkgreen\")) + labs(x = \"Individual ID\", y = \"Ancestry Proportion\", fill = \"Ancestry\", title = \"Global Ancestry Proportions\") + theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10, face = \"bold\"), axis.text.y = element_text(face = \"bold\"), # Bold y-axis numbers axis.title.x = element_text(face = \"bold\"), axis.title.y = element_text(face = \"bold\"), legend.title = element_text(face = \"bold\"), plot.title = element_text(face = \"bold\", hjust = 0.5)) # Save the plot with specified dimensions ggsave(\"ancestry_plot.png\", plot = p, width = 10, height = 6, units = \"in\", dpi = 300) Questions (i) What are the ancestry assignments of the 28 individuals? (Provide estimated proportions where necessary) Part 3: Local Ancestry Inference Next we will use the RFMix software to calculate local ancestry on chromosome 22 for the same 28 individuals. The RFMix algorithm uses an unsupervised learning algorithm. # Run the following UNIX command from the home directory module load cmake module load bcftools/1.10.2 for i in {22..22}; do ./software/rfmix -f ./data/rfmix/chr1-22_phased.bcf.gz -r ./reference/chr1-22.b.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bcf.gz --analyze-range=26.86-31.80 -m ./data/rfmix/1KG_superpop_vs_ID.txt --chromosome=${i} -g ./reference/1kg_chr1-22.gmap --n-threads=4 -o ./out/rfmix/chr${i}.local_ancestry; done Questions (i) What information is provided in the simulation results table displayed on-screen ? Part 4: Plot local admixture on chromosome 22 In this step we will plot the output from the previous RFMix run. Execute the following code from the home directory R library(ggplot2) library(dplyr) library(tidyr) # Function to read the .msp.tsv file read_msp_file <- function(msp_file) { # Read the entire file as text lines <- readLines(msp_file) # Determine the number of header lines (lines starting with '#') header_lines <- lines[grepl(\"^#\", lines)] num_header_lines <- length(header_lines) # Extract column names from the last header line col_names <- strsplit(header_lines[num_header_lines], \"\\t\")[[1]] # Read the data skipping the header lines msp_df <- read.table(msp_file, header = FALSE, skip = num_header_lines, sep = \"\\t\") # Assign column names colnames(msp_df) <- col_names return(msp_df) } # Function to read the .Q file read_Q_file <- function(Q_file) { Q_df <- read.table(Q_file, header = TRUE, sep = \"\\t\", comment.char = \"#\") colnames(Q_df) <- c(\"sample\", \"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\") return(Q_df) } # Specification of file paths msp_file <- './out/rfmix/chr22.local_ancestry.msp.tsv' Q_file <- './out/rfmix/chr22.local_ancestry.rfmix.Q' # Read in files msp_df <- read_msp_file(msp_file) Q_df <- read_Q_file(Q_file) # Check for NA or empty column names print(colnames(msp_df)) # Extract ancestry columns based on pattern recognition of column names ancestry_cols <- colnames(msp_df)[grep(\"\\\\.0$|\\\\.1$\", colnames(msp_df))] # Function to determine ancestry based on RFMix codes determine_ancestry <- function(value) { ancestry_map <- c(\"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\") return(ancestry_map[value + 1]) } # Rename columns uniquely colnames(msp_df)[7:62] <- paste0(\"haplo_\", colnames(msp_df)[7:62]) # Prepare data for plotting plot_data <- msp_df %>% pivot_longer(cols = starts_with(\"haplo_\"), names_to = \"haplo_col\", values_to = \"ancestry_code\", names_repair = \"unique\") %>% mutate( individual = gsub(\"\\\\..*\", \"\", haplo_col), strand = ifelse(grepl(\"\\\\.0$\", haplo_col), \"Strand 1\", \"Strand 2\"), ancestry = determine_ancestry(ancestry_code) ) # Create plot of chromosome 22 across the sample plot <- ggplot(plot_data, aes(x = sgpos, xend = egpos, y = interaction(individual, strand, lex.order = TRUE), yend = interaction(individual, strand, lex.order = TRUE), color = ancestry)) + geom_segment(linewidth = 4) + scale_color_manual(values = c(\"AFR\" = \"blue\", \"AMR\" = \"orange\", \"EAS\" = \"green\", \"EUR\" = \"red\", \"SAS\" = \"purple\")) + labs(x = \"Genetic position (cM)\", y = \"Individual ID and Haplotype\", title = \"Local Ancestry Across Chromosome 22\", color = \"Ancestry\") + theme_minimal() + theme(axis.text.y = element_text(size = 8), axis.title.y = element_text(size = 10), axis.title.x = element_text(size = 10)) # Save the plot to a file ggsave(\"./out/rfmix/local_ancestry_chromosome22_5Mb_subregion.png\", plot = plot, width = 10, height = 8) Questions (i) How many different continental ancestries do you see represented across the 58 strands? (ii) Why is the number of different ancestry backgrounds higher than it was in the previous step? Part 5: Formatting of admixture files for analysis using PRSice Step 1 - Convert phased genotypes to GenomicRange format # Run from the home directory library(vcfR) library(memuse) library(panelr) library(GenomicRanges) library(data.table) clean_memory <- function(vars_to_remove) { rm(list = vars_to_remove) gc() } # Read in phased VCF file vcfr_inputfile_chr22 <- read.vcfR(\"./data/rfmix/chr22_phased.vcf.gz\", verbose = FALSE) extracted_haps22 <- extract.haps(vcfr_inputfile_chr22, mask = FALSE, unphased_as_NA = TRUE, verbose = TRUE) extracted_snp_info22 <- getFIX(vcfr_inputfile_chr22) # Convert haplotypes to data frame haps_df <- data.frame(extracted_haps22, check.names = FALSE) haps_dt <- setDT(haps_df, keep.rownames = \"snps\") # Convert SNP info to data frame snp_info_df <- data.frame(extracted_snp_info22) # Check for numerical and ordering consistency between haplotypes and SNP info if (!identical(haps_dt[['snps']], snp_info_df[['ID']])) { stop(\"Numerical and ordering inconsistency between haplotypes and SNP info\") } # Merge haplotypes and SNP info merge_chr22 <- cbind(snp_info_df, haps_dt) # Convert to long format using panelr chr22_haplo_long <- long_panel(merge_chr22, prefix = \"_\", begin = 0, end = 1, label_location = \"end\", as_panel_data = FALSE) # Insert 'end' column after 'POS' and create 'wave' column chr22_haplo_long$end <- chr22_haplo_long$POS chr22_haplo_long$wave <- ifelse(chr22_haplo_long$wave == \"0\", \"+\", ifelse(chr22_haplo_long$wave == \"1\", \"-\", \"Z\")) # Remove row names and drop redundant columns using base R rownames(chr22_haplo_long) <- NULL drops <- c(\"id\", \"snps\", \"QUAL\", \"FILTER\") chr22_haplo_long <- chr22_haplo_long[, !names(chr22_haplo_long) %in% drops] # Rename columns names(chr22_haplo_long)[3] <- \"start\" names(chr22_haplo_long)[1] <- \"strand\" header <- gsub(\".*_\", \"\", colnames(chr22_haplo_long)[7:ncol(chr22_haplo_long)]) names(chr22_haplo_long)[7:ncol(chr22_haplo_long)] <- header # Create GRanges object gr_obj_chr22 <- makeGRangesFromDataFrame(chr22_haplo_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Save the GRanges object saveRDS(gr_obj_chr22, file = \"./out/rfmix/chr22_phased_gr.rds\") # Clean up memory clean_memory(c(\"vcfr_inputfile_chr22\", \"extracted_haps22\", \"merge_chr22\", \"haps_df\", \"haps_dt\", \"snp_info_df\", \"chr22_haplo_long\", \"gr_obj_chr22\")) Part 5: Step 2 - Merge genotypes from Step 1 with local ancestry calls by RFMix # Read in MSP file msp <- fread(\"./out/rfmix/chr22.local_ancestry.msp.tsv\") # Reformat genome-wide local ancestry output as GRanges object colnames(msp)[1] <- \"chm\" msp_gr <- makeGRangesFromDataFrame(msp, seqnames.field = \"chm\", start.field = \"spos\", end.field = \"epos\", keep.extra.columns = TRUE) # Convert the elements of the GRange object into a dataframe chr22_rf <- data.frame(seqnames = seqnames(msp_gr), ranges = ranges(msp_gr), strand = strand(msp_gr), mcols(msp_gr), check.names = FALSE) names(chr22_rf)[1:5] <- c(\"chr\", \"start\", \"end\", \"width\", \"strand\") rownames(chr22_rf) <- NULL # Clean up column headers header <- gsub(\".*_\", \"\", colnames(chr22_rf)[9:ncol(chr22_rf)]) names(chr22_rf)[9:ncol(chr22_rf)] <- header # Convert local ancestry calls from wide to long format chr22_rf_long <- long_panel(chr22_rf, prefix = \".\", begin = 0, end = 1, label_location = \"end\", as_panel_data = FALSE) chr22_rf_long <- as.data.frame(chr22_rf_long, check.names = FALSE) chr22_rf_long$strand <- ifelse(chr22_rf_long$wave == \"0\", \"+\", ifelse(chr22_rf_long$wave == \"1\", \"-\", \"Z\")) # Drop redundant columns drops <- c(\"wave\", \"id\") chr22_rf_long <- chr22_rf_long[, !(names(chr22_rf_long) %in% drops)] rownames(chr22_rf_long) <- NULL # Convert the reconfigured dataframe file into a GRanges object chr22_msp_gr <- makeGRangesFromDataFrame(chr22_rf_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Ensure chr22_haplo_long is a GRanges object before finding overlaps chr22_haplo_gr <- makeGRangesFromDataFrame(chr22_haplo_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Find overlaps and store matching features # Matching is coordinates based. Base position (\"start\"/\"end\")is used to match the two files matched_regions <- findOverlaps(chr22_haplo_gr, chr22_msp_gr) chr22_haps_lanc_gr <- chr22_haplo_gr[queryHits(matched_regions)] #Store matching features in a new dataframe, add metadata from RFmix output. mcols(chr22_haps_lanc_gr) <- cbind.data.frame(mcols(chr22_haps_lanc_gr), mcols(chr22_msp_gr[subjectHits(matched_regions)])) # Local ancestry calls are now aligned with genotypic data and positional coordinates # Convert to dataframe without adding 'X' to numeric column names genes_df <- as.data.frame(chr22_haps_lanc_gr) names(genes_df) <- sub('^X', '', names(genes_df)) # Output the dataframe write.table(genes_df, file = \"./out/rfmix/chr22_phased_geno_lanc.txt\", quote = FALSE, row.names=F) # Clean up memory rm(list = c(\"chr22_haplo_gr\", \"chr22_haplo_long\", \"msp\", \"msp_gr\", \"chr22_rf\", \"header\", \"chr22_rf_long\", \"chr22_msp_gr\", \"matched_regions\", \"chr22_haps_lanc_gr\")) gc() Part 5: Step 3 - Create separate Plink files # Partition genotype and local ancestry data chr22_genos <- genes_df[, c(1, 2, 6, 9:36)] chr22_LA <- genes_df[, c(1, 2, 6, 40:ncol(genes_df))] # Reintegrate in interleaved format d <- chr22_genos[, -c(1:3)] # Retain ID columns only d2 <- chr22_LA[, -c(1:3)] # Prepare headers indx <- rbind(names(d), names(d2)) dmerge <- cbind(d, d2) dfinal <- dmerge[, indx] # Convert LAnc data from long to wide format LA_wide <- lapply(1:ncol(chr22_LA), function(i) as.data.frame(matrix(chr22_LA[, i], ncol = 2, byrow = TRUE))) # Check length of LA_wide length(LA_wide) # Expected number. Each item contains a set of matched strand pairs per individual LA_final <- as.data.frame(do.call(cbind, LA_wide)) LA_final <- LA_final[, -c(2, 4, 6)] # Remove duplicates of first 3 cols colnames(LA_final)[4:ncol(LA_final)] <- colnames(dfinal) # Apply headers # Convert genotype calls to horizontal orientation geno_wide <- lapply(1:ncol(chr22_genos), function(i) as.data.frame(matrix(chr22_genos[, i], ncol = 2, byrow = TRUE))) # Genotypic part: Get horizontal genotypes geno_final <- as.data.frame(do.call(cbind, geno_wide)) # Merge horizontal genotypes # Clean up and finalize geno_final geno_final <- geno_final[, -c(2, 4, 6)] # Redundant columns colnames(geno_final)[4:ncol(geno_final)] <- colnames(dfinal) # Name columns colnames(geno_final)[1:3] <- c(\"CHROM\", \"BP\", \"ID\") colnames(LA_final)[1:3] <- c(\"CHROM\", \"BP\", \"ID\") # Write final tables write.table(geno_final, \"./out/rfmix/chr22_geno.txt\", row.names = FALSE, quote = FALSE) write.table(LA_final, \"./out/rfmix/chr22_LA.txt\", row.names = FALSE, quote = FALSE) Part 5: Step 4 - Use custom software (RFTransform) to create Plink files for input into PRSice module load cmake ./software/RFTransform/build/RFTransformer ./out/rfmix/chr22_geno.txt ./out/rfmix/chr22_LA.txt ./out/plink/chr22 # Perform general QC ahead of running PRSice on ancestry-deconvolved individuals # (i) Remove SNPs with low minor allele count (MAC) # Plink - Remove monomorphic SNPs (minor allele count 0-4). #AFR for i in {22..22}; do ./software/plink2 \\ --bfile ./out/plink/chr${i}-AFR \\ --mac 5 \\ --make-bed \\ --out ./out/plink/chr${i}-AFR.mac done #EUR for i in {22..22}; do ./software/plink2 \\ --bfile ./out/plink/chr${i}-EUR \\ --mac 5 \\ --make-bed \\ --out ./out/plink//chr${i}-EUR.mac done # PRSice - Generate ancestry-specific weights # AFR Rscript ./software/PRSice.R \\ --prsice ./software/PRSice_linux \\ --base ./data/plink/AFR-BMI.Phenotype.glm.linear \\ --extract ./data/plink/snp.valid \\ --A1 A1 \\ --pvalue P \\ --stat BETA \\ --pheno ./data/plink/pheno.plink \\ --beta \\ --snp ID \\ --score sum \\ --target ./out/plink/chr22-AFR.mac \\ --binary-target F \\ --out ./out/prsice/BMI_AFR-base # EUR Rscript ./software/PRSice.R \\ --prsice ./software/PRSice_linux \\ --base ./data/plink/EUR-BMI.Phenotype.glm.linear \\ --extract ./data/plink/snp.valid \\ --A1 A1 \\ --pvalue P \\ --stat BETA \\ --pheno ./data/plink/pheno.plink \\ --beta \\ --snp ID \\ --score sum \\ --target ./out/plink/chr22-EUR.mac \\ --binary-target F \\ --out ./out/prsice/BMI_EUR-base Part 5: Step 5 - Evaluate the Admixture-informed PRS library(dplyr) # Read the PRS files into dataframes file1 <- read.table(\"./out/prsice/BMI_EUR-base.best\", header = TRUE, check.names=F) file2 <- read.table(\"./out/prsice/BMI_AFR-base.best\", header = TRUE, check.names=F) # Add the fourth column of both files file1$PRS_SUM <- file1$PRS + file2$PRS # Load the phenotype data pheno <- read.table(\"./data/plink/pheno.plink\", header = F) colnames(pheno) <- c(\"FID\", \"IID\", \"phenotype\") # Convert phenotype column to numeric pheno$phenotype <- as.numeric(pheno$phenotype) # Merge PRS data with phenotype data merged_data <- merge(file1[, c(\"FID\", \"IID\", \"PRS\", \"PRS_SUM\")], pheno, by = c(\"FID\", \"IID\")) merged_data <- merge(merged_data, file2[, c(\"FID\", \"IID\", \"PRS\")], by = c(\"FID\", \"IID\")) # Rename columns names(merged_data)[names(merged_data) == \"PRS.x\"] <- \"PRS1\" names(merged_data)[names(merged_data) == \"PRS.y\"] <- \"PRS2\" # Perform linear regression for each PRS and the combined PRS model1 <- lm(phenotype ~ PRS1, data = merged_data) model2 <- lm(phenotype ~ PRS2, data = merged_data) model_sum <- lm(phenotype ~ PRS_SUM, data = merged_data) # Extract R-squared values r_squared1 <- summary(model1)$r.squared r_squared2 <- summary(model2)$r.squared r_squared_sum <- summary(model_sum)$r.squared # Print the R-squared values cat(\"R-squared for PRS1: \", r_squared1, \"\\n\") cat(\"R-squared for PRS2: \", r_squared2, \"\\n\") cat(\"R-squared for PRS_SUM: \", r_squared_sum, \"\\n\") Questions (i) How does the R-squared of the combined-ancestry PRS perform relative to the 2 partial-genome PRSs?","title":"Day4b.docx"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#day-4-practical-2-introduction-to-admixture-analysis","text":"","title":"Day 4 - Practical 2: Introduction to Admixture analysis"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#module-goals","text":"The goal of this practical is to provide you with basic understanding of Admixture and the basic elements behind Admixture PRS scores. Upon completion of this practical, you should: * Gain familiarity with a variety of tools used in the context of admixed population research * Go through the basic steps of formulating admixture-informed polygenic risk scores","title":"Module Goals"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part1-plot-decay-of-ancestry-ld-over-time","text":"Here we explore how Admixture LD varies over time and as a function of the genetic distance between loci. In R: library(ggplot2) library(reshape2) library(viridis) #range of values of r (recombination fraction) r = seq(0, 0.5, 0.1) dtmat = matrix(NA, nrow = 6, ncol = 10) # matrix to store values of dt for(i in 1:6){ dt = 0.25 for(j in 1:10){ dtmat[i,j] = dt dt = dt*(1 -r[i])^j } } dtmat = reshape2::melt(dtmat) colnames(dtmat) = c(\"r\",\"g\",\"Dt\") dtmat$r = (dtmat$r - 1)/10 ggplot(dtmat, aes(x = g, y = Dt, group = r, color = as.factor(r))) + geom_line(linewidth = 1.2) + theme_minimal(base_size = 14) + theme( axis.text = element_text(size = 14), axis.title = element_text(size = 16), legend.title = element_text(size = 14), legend.text = element_text(size = 12), plot.title = element_text(size = 18, face = \"bold\"), plot.subtitle = element_text(size = 14), panel.grid.major = element_line(color = \"gray80\") ) + scale_color_viridis_d() + scale_x_continuous(breaks = c(1:10)) + labs( title = \"Decay of Linkage Disequilibrium Over Generations\", subtitle = \"Effect of Recombination Fraction (r) on Admixture LD\", x = \"Generations since admixture (t)\", y = \"Admixture LD\", color = \"Recombination Fraction (r)\" )","title":"Part1: Plot Decay of Ancestry LD over time"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#questions","text":"","title":"Questions"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#i-describe-what-happens-to-admixture-ld-over-time","text":"","title":"(i) Describe what happens to admixture LD over time?"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#ii-why-does-recombination-also-have-an-impact","text":"","title":"(ii) Why does recombination also have an impact?"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part-2-global-ancestry-inference","text":"We will now run an analysis using the software ADMIXTURE to calculate global ancestry proportions across a sample of 28 individuals. Here we perform a supervised analysis. Please execute the following code from location ~/RFMIX_WCS_2024/data/plink/ ./admixture samples_n28_qc_thin.bed 2 --supervised -j4","title":"Part 2: Global Ancestry Inference"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#questions_1","text":"","title":"Questions"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#i-what-do-you-think-the-number-specified-after-the-inout-file-represents","text":"The next step is to create a plot the results # Plot Global Ancestry Results R library(ggplot2) library(reshape2) # Read the data from files fam <- read.table(\"samples_n28_qc_thin.fam\", header = FALSE) pop <- read.table(\"samples_n28_qc_thin.pop\", header = FALSE) Q <- read.table(\"samples_n28_qc_thin.2.Q\", header = FALSE) # Merge the data into one data frame merged_data <- cbind(fam, pop, Q) # Extract necessary columns (assuming the structure of the files as in the image) colnames(merged_data) <- c(\"FID\", \"IID\", \"PaternalID\", \"MaternalID\", \"Sex\", \"Phenotype\", \"Population\", \"AFR\", \"EUR\") # Order data by decreasing AFR merged_data <- merged_data[order(-merged_data$AFR), ] # Prepare data for plotting plot_data <- merged_data[, c(\"IID\", \"AFR\", \"EUR\")] plot_data$IID <- factor(plot_data$IID, levels = plot_data$IID) # Ensure order is maintained in plot plot_data_melted <- melt(plot_data, id.vars = \"IID\") # Create the plot p <- ggplot(plot_data_melted, aes(x = IID, y = value, fill = variable)) + geom_bar(stat = \"identity\", position = \"stack\") + scale_fill_manual(values = c(\"AFR\" = \"red\", \"EUR\" = \"darkgreen\")) + labs(x = \"Individual ID\", y = \"Ancestry Proportion\", fill = \"Ancestry\", title = \"Global Ancestry Proportions\") + theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10, face = \"bold\"), axis.text.y = element_text(face = \"bold\"), # Bold y-axis numbers axis.title.x = element_text(face = \"bold\"), axis.title.y = element_text(face = \"bold\"), legend.title = element_text(face = \"bold\"), plot.title = element_text(face = \"bold\", hjust = 0.5)) # Save the plot with specified dimensions ggsave(\"ancestry_plot.png\", plot = p, width = 10, height = 6, units = \"in\", dpi = 300)","title":"(i) What do you think the number specified after the inout file represents?"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#questions_2","text":"","title":"Questions"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#i-what-are-the-ancestry-assignments-of-the-28-individuals-provide-estimated-proportions-where-necessary","text":"","title":"(i) What are the ancestry assignments of the 28 individuals? (Provide estimated proportions where necessary)"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part-3-local-ancestry-inference","text":"Next we will use the RFMix software to calculate local ancestry on chromosome 22 for the same 28 individuals. The RFMix algorithm uses an unsupervised learning algorithm. # Run the following UNIX command from the home directory module load cmake module load bcftools/1.10.2 for i in {22..22}; do ./software/rfmix -f ./data/rfmix/chr1-22_phased.bcf.gz -r ./reference/chr1-22.b.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bcf.gz --analyze-range=26.86-31.80 -m ./data/rfmix/1KG_superpop_vs_ID.txt --chromosome=${i} -g ./reference/1kg_chr1-22.gmap --n-threads=4 -o ./out/rfmix/chr${i}.local_ancestry; done","title":"Part 3: Local Ancestry Inference"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#questions_3","text":"","title":"Questions"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#i-what-information-is-provided-in-the-simulation-results-table-displayed-on-screen","text":"","title":"(i) What information is provided in the simulation results table displayed on-screen ?"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part-4-plot-local-admixture-on-chromosome-22","text":"In this step we will plot the output from the previous RFMix run. Execute the following code from the home directory R library(ggplot2) library(dplyr) library(tidyr) # Function to read the .msp.tsv file read_msp_file <- function(msp_file) { # Read the entire file as text lines <- readLines(msp_file) # Determine the number of header lines (lines starting with '#') header_lines <- lines[grepl(\"^#\", lines)] num_header_lines <- length(header_lines) # Extract column names from the last header line col_names <- strsplit(header_lines[num_header_lines], \"\\t\")[[1]] # Read the data skipping the header lines msp_df <- read.table(msp_file, header = FALSE, skip = num_header_lines, sep = \"\\t\") # Assign column names colnames(msp_df) <- col_names return(msp_df) } # Function to read the .Q file read_Q_file <- function(Q_file) { Q_df <- read.table(Q_file, header = TRUE, sep = \"\\t\", comment.char = \"#\") colnames(Q_df) <- c(\"sample\", \"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\") return(Q_df) } # Specification of file paths msp_file <- './out/rfmix/chr22.local_ancestry.msp.tsv' Q_file <- './out/rfmix/chr22.local_ancestry.rfmix.Q' # Read in files msp_df <- read_msp_file(msp_file) Q_df <- read_Q_file(Q_file) # Check for NA or empty column names print(colnames(msp_df)) # Extract ancestry columns based on pattern recognition of column names ancestry_cols <- colnames(msp_df)[grep(\"\\\\.0$|\\\\.1$\", colnames(msp_df))] # Function to determine ancestry based on RFMix codes determine_ancestry <- function(value) { ancestry_map <- c(\"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\") return(ancestry_map[value + 1]) } # Rename columns uniquely colnames(msp_df)[7:62] <- paste0(\"haplo_\", colnames(msp_df)[7:62]) # Prepare data for plotting plot_data <- msp_df %>% pivot_longer(cols = starts_with(\"haplo_\"), names_to = \"haplo_col\", values_to = \"ancestry_code\", names_repair = \"unique\") %>% mutate( individual = gsub(\"\\\\..*\", \"\", haplo_col), strand = ifelse(grepl(\"\\\\.0$\", haplo_col), \"Strand 1\", \"Strand 2\"), ancestry = determine_ancestry(ancestry_code) ) # Create plot of chromosome 22 across the sample plot <- ggplot(plot_data, aes(x = sgpos, xend = egpos, y = interaction(individual, strand, lex.order = TRUE), yend = interaction(individual, strand, lex.order = TRUE), color = ancestry)) + geom_segment(linewidth = 4) + scale_color_manual(values = c(\"AFR\" = \"blue\", \"AMR\" = \"orange\", \"EAS\" = \"green\", \"EUR\" = \"red\", \"SAS\" = \"purple\")) + labs(x = \"Genetic position (cM)\", y = \"Individual ID and Haplotype\", title = \"Local Ancestry Across Chromosome 22\", color = \"Ancestry\") + theme_minimal() + theme(axis.text.y = element_text(size = 8), axis.title.y = element_text(size = 10), axis.title.x = element_text(size = 10)) # Save the plot to a file ggsave(\"./out/rfmix/local_ancestry_chromosome22_5Mb_subregion.png\", plot = plot, width = 10, height = 8)","title":"Part 4: Plot local admixture on chromosome 22"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#questions_4","text":"","title":"Questions"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#i-how-many-different-continental-ancestries-do-you-see-represented-across-the-58-strands","text":"","title":"(i) How many different continental ancestries do you see represented across the 58 strands?"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#ii-why-is-the-number-of-different-ancestry-backgrounds-higher-than-it-was-in-the-previous-step","text":"","title":"(ii) Why is the number of different ancestry backgrounds higher than it was in the previous step?"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part-5-formatting-of-admixture-files-for-analysis-using-prsice","text":"","title":"Part 5: Formatting of admixture files for analysis using PRSice"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#step-1-convert-phased-genotypes-to-genomicrange-format","text":"# Run from the home directory library(vcfR) library(memuse) library(panelr) library(GenomicRanges) library(data.table) clean_memory <- function(vars_to_remove) { rm(list = vars_to_remove) gc() } # Read in phased VCF file vcfr_inputfile_chr22 <- read.vcfR(\"./data/rfmix/chr22_phased.vcf.gz\", verbose = FALSE) extracted_haps22 <- extract.haps(vcfr_inputfile_chr22, mask = FALSE, unphased_as_NA = TRUE, verbose = TRUE) extracted_snp_info22 <- getFIX(vcfr_inputfile_chr22) # Convert haplotypes to data frame haps_df <- data.frame(extracted_haps22, check.names = FALSE) haps_dt <- setDT(haps_df, keep.rownames = \"snps\") # Convert SNP info to data frame snp_info_df <- data.frame(extracted_snp_info22) # Check for numerical and ordering consistency between haplotypes and SNP info if (!identical(haps_dt[['snps']], snp_info_df[['ID']])) { stop(\"Numerical and ordering inconsistency between haplotypes and SNP info\") } # Merge haplotypes and SNP info merge_chr22 <- cbind(snp_info_df, haps_dt) # Convert to long format using panelr chr22_haplo_long <- long_panel(merge_chr22, prefix = \"_\", begin = 0, end = 1, label_location = \"end\", as_panel_data = FALSE) # Insert 'end' column after 'POS' and create 'wave' column chr22_haplo_long$end <- chr22_haplo_long$POS chr22_haplo_long$wave <- ifelse(chr22_haplo_long$wave == \"0\", \"+\", ifelse(chr22_haplo_long$wave == \"1\", \"-\", \"Z\")) # Remove row names and drop redundant columns using base R rownames(chr22_haplo_long) <- NULL drops <- c(\"id\", \"snps\", \"QUAL\", \"FILTER\") chr22_haplo_long <- chr22_haplo_long[, !names(chr22_haplo_long) %in% drops] # Rename columns names(chr22_haplo_long)[3] <- \"start\" names(chr22_haplo_long)[1] <- \"strand\" header <- gsub(\".*_\", \"\", colnames(chr22_haplo_long)[7:ncol(chr22_haplo_long)]) names(chr22_haplo_long)[7:ncol(chr22_haplo_long)] <- header # Create GRanges object gr_obj_chr22 <- makeGRangesFromDataFrame(chr22_haplo_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Save the GRanges object saveRDS(gr_obj_chr22, file = \"./out/rfmix/chr22_phased_gr.rds\") # Clean up memory clean_memory(c(\"vcfr_inputfile_chr22\", \"extracted_haps22\", \"merge_chr22\", \"haps_df\", \"haps_dt\", \"snp_info_df\", \"chr22_haplo_long\", \"gr_obj_chr22\"))","title":"Step 1 - Convert phased genotypes to GenomicRange format"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part-5-step-2-merge-genotypes-from-step-1-with-local-ancestry-calls-by-rfmix","text":"# Read in MSP file msp <- fread(\"./out/rfmix/chr22.local_ancestry.msp.tsv\") # Reformat genome-wide local ancestry output as GRanges object colnames(msp)[1] <- \"chm\" msp_gr <- makeGRangesFromDataFrame(msp, seqnames.field = \"chm\", start.field = \"spos\", end.field = \"epos\", keep.extra.columns = TRUE) # Convert the elements of the GRange object into a dataframe chr22_rf <- data.frame(seqnames = seqnames(msp_gr), ranges = ranges(msp_gr), strand = strand(msp_gr), mcols(msp_gr), check.names = FALSE) names(chr22_rf)[1:5] <- c(\"chr\", \"start\", \"end\", \"width\", \"strand\") rownames(chr22_rf) <- NULL # Clean up column headers header <- gsub(\".*_\", \"\", colnames(chr22_rf)[9:ncol(chr22_rf)]) names(chr22_rf)[9:ncol(chr22_rf)] <- header # Convert local ancestry calls from wide to long format chr22_rf_long <- long_panel(chr22_rf, prefix = \".\", begin = 0, end = 1, label_location = \"end\", as_panel_data = FALSE) chr22_rf_long <- as.data.frame(chr22_rf_long, check.names = FALSE) chr22_rf_long$strand <- ifelse(chr22_rf_long$wave == \"0\", \"+\", ifelse(chr22_rf_long$wave == \"1\", \"-\", \"Z\")) # Drop redundant columns drops <- c(\"wave\", \"id\") chr22_rf_long <- chr22_rf_long[, !(names(chr22_rf_long) %in% drops)] rownames(chr22_rf_long) <- NULL # Convert the reconfigured dataframe file into a GRanges object chr22_msp_gr <- makeGRangesFromDataFrame(chr22_rf_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Ensure chr22_haplo_long is a GRanges object before finding overlaps chr22_haplo_gr <- makeGRangesFromDataFrame(chr22_haplo_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Find overlaps and store matching features # Matching is coordinates based. Base position (\"start\"/\"end\")is used to match the two files matched_regions <- findOverlaps(chr22_haplo_gr, chr22_msp_gr) chr22_haps_lanc_gr <- chr22_haplo_gr[queryHits(matched_regions)] #Store matching features in a new dataframe, add metadata from RFmix output. mcols(chr22_haps_lanc_gr) <- cbind.data.frame(mcols(chr22_haps_lanc_gr), mcols(chr22_msp_gr[subjectHits(matched_regions)])) # Local ancestry calls are now aligned with genotypic data and positional coordinates # Convert to dataframe without adding 'X' to numeric column names genes_df <- as.data.frame(chr22_haps_lanc_gr) names(genes_df) <- sub('^X', '', names(genes_df)) # Output the dataframe write.table(genes_df, file = \"./out/rfmix/chr22_phased_geno_lanc.txt\", quote = FALSE, row.names=F) # Clean up memory rm(list = c(\"chr22_haplo_gr\", \"chr22_haplo_long\", \"msp\", \"msp_gr\", \"chr22_rf\", \"header\", \"chr22_rf_long\", \"chr22_msp_gr\", \"matched_regions\", \"chr22_haps_lanc_gr\")) gc()","title":"Part 5: Step 2 - Merge genotypes from Step 1 with local ancestry calls by RFMix"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part-5-step-3-create-separate-plink-files","text":"# Partition genotype and local ancestry data chr22_genos <- genes_df[, c(1, 2, 6, 9:36)] chr22_LA <- genes_df[, c(1, 2, 6, 40:ncol(genes_df))] # Reintegrate in interleaved format d <- chr22_genos[, -c(1:3)] # Retain ID columns only d2 <- chr22_LA[, -c(1:3)] # Prepare headers indx <- rbind(names(d), names(d2)) dmerge <- cbind(d, d2) dfinal <- dmerge[, indx] # Convert LAnc data from long to wide format LA_wide <- lapply(1:ncol(chr22_LA), function(i) as.data.frame(matrix(chr22_LA[, i], ncol = 2, byrow = TRUE))) # Check length of LA_wide length(LA_wide) # Expected number. Each item contains a set of matched strand pairs per individual LA_final <- as.data.frame(do.call(cbind, LA_wide)) LA_final <- LA_final[, -c(2, 4, 6)] # Remove duplicates of first 3 cols colnames(LA_final)[4:ncol(LA_final)] <- colnames(dfinal) # Apply headers # Convert genotype calls to horizontal orientation geno_wide <- lapply(1:ncol(chr22_genos), function(i) as.data.frame(matrix(chr22_genos[, i], ncol = 2, byrow = TRUE))) # Genotypic part: Get horizontal genotypes geno_final <- as.data.frame(do.call(cbind, geno_wide)) # Merge horizontal genotypes # Clean up and finalize geno_final geno_final <- geno_final[, -c(2, 4, 6)] # Redundant columns colnames(geno_final)[4:ncol(geno_final)] <- colnames(dfinal) # Name columns colnames(geno_final)[1:3] <- c(\"CHROM\", \"BP\", \"ID\") colnames(LA_final)[1:3] <- c(\"CHROM\", \"BP\", \"ID\") # Write final tables write.table(geno_final, \"./out/rfmix/chr22_geno.txt\", row.names = FALSE, quote = FALSE) write.table(LA_final, \"./out/rfmix/chr22_LA.txt\", row.names = FALSE, quote = FALSE)","title":"Part 5: Step 3 - Create separate Plink files"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part-5-step-4-use-custom-software-rftransform-to-create-plink-files-for-input-into-prsice","text":"module load cmake ./software/RFTransform/build/RFTransformer ./out/rfmix/chr22_geno.txt ./out/rfmix/chr22_LA.txt ./out/plink/chr22 # Perform general QC ahead of running PRSice on ancestry-deconvolved individuals # (i) Remove SNPs with low minor allele count (MAC) # Plink - Remove monomorphic SNPs (minor allele count 0-4). #AFR for i in {22..22}; do ./software/plink2 \\ --bfile ./out/plink/chr${i}-AFR \\ --mac 5 \\ --make-bed \\ --out ./out/plink/chr${i}-AFR.mac done #EUR for i in {22..22}; do ./software/plink2 \\ --bfile ./out/plink/chr${i}-EUR \\ --mac 5 \\ --make-bed \\ --out ./out/plink//chr${i}-EUR.mac done # PRSice - Generate ancestry-specific weights # AFR Rscript ./software/PRSice.R \\ --prsice ./software/PRSice_linux \\ --base ./data/plink/AFR-BMI.Phenotype.glm.linear \\ --extract ./data/plink/snp.valid \\ --A1 A1 \\ --pvalue P \\ --stat BETA \\ --pheno ./data/plink/pheno.plink \\ --beta \\ --snp ID \\ --score sum \\ --target ./out/plink/chr22-AFR.mac \\ --binary-target F \\ --out ./out/prsice/BMI_AFR-base # EUR Rscript ./software/PRSice.R \\ --prsice ./software/PRSice_linux \\ --base ./data/plink/EUR-BMI.Phenotype.glm.linear \\ --extract ./data/plink/snp.valid \\ --A1 A1 \\ --pvalue P \\ --stat BETA \\ --pheno ./data/plink/pheno.plink \\ --beta \\ --snp ID \\ --score sum \\ --target ./out/plink/chr22-EUR.mac \\ --binary-target F \\ --out ./out/prsice/BMI_EUR-base","title":"Part 5: Step 4 - Use custom software (RFTransform) to create Plink files for input into PRSice"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#part-5-step-5-evaluate-the-admixture-informed-prs","text":"library(dplyr) # Read the PRS files into dataframes file1 <- read.table(\"./out/prsice/BMI_EUR-base.best\", header = TRUE, check.names=F) file2 <- read.table(\"./out/prsice/BMI_AFR-base.best\", header = TRUE, check.names=F) # Add the fourth column of both files file1$PRS_SUM <- file1$PRS + file2$PRS # Load the phenotype data pheno <- read.table(\"./data/plink/pheno.plink\", header = F) colnames(pheno) <- c(\"FID\", \"IID\", \"phenotype\") # Convert phenotype column to numeric pheno$phenotype <- as.numeric(pheno$phenotype) # Merge PRS data with phenotype data merged_data <- merge(file1[, c(\"FID\", \"IID\", \"PRS\", \"PRS_SUM\")], pheno, by = c(\"FID\", \"IID\")) merged_data <- merge(merged_data, file2[, c(\"FID\", \"IID\", \"PRS\")], by = c(\"FID\", \"IID\")) # Rename columns names(merged_data)[names(merged_data) == \"PRS.x\"] <- \"PRS1\" names(merged_data)[names(merged_data) == \"PRS.y\"] <- \"PRS2\" # Perform linear regression for each PRS and the combined PRS model1 <- lm(phenotype ~ PRS1, data = merged_data) model2 <- lm(phenotype ~ PRS2, data = merged_data) model_sum <- lm(phenotype ~ PRS_SUM, data = merged_data) # Extract R-squared values r_squared1 <- summary(model1)$r.squared r_squared2 <- summary(model2)$r.squared r_squared_sum <- summary(model_sum)$r.squared # Print the R-squared values cat(\"R-squared for PRS1: \", r_squared1, \"\\n\") cat(\"R-squared for PRS2: \", r_squared2, \"\\n\") cat(\"R-squared for PRS_SUM: \", r_squared_sum, \"\\n\")","title":"Part 5: Step 5 - Evaluate the Admixture-informed PRS"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#questions_5","text":"","title":"Questions"},{"location":"tmp/practical_docs_hidden/Day4b.docx/#i-how-does-the-r-squared-of-the-combined-ancestry-prs-perform-relative-to-the-2-partial-genome-prss","text":"","title":"(i) How does the R-squared of the combined-ancestry PRS perform relative to the 2 partial-genome PRSs?"},{"location":"tmp/practical_docs_hidden/Day5_Projects/","text":"Integration of Polygenic Risk Scores Task \u2013 PRSmix calculation [3.5 hrs] You have just completed the Wellcome Connecting Science PRS course and are now acquainted with tools such as PRSCSx and BRIDGEPRS. You also got to hear a talk by Prof Nilanjan Chatterjee, who you later realized has been involved in developing three latest PRS software programs, PROSPER, MUSSEL, and CT-SLEB, that claim to improve PRS prediction in Africans. You are now getting overwhelmed by the sheer number of tools to test out and do not know which tool to use for your PRS project, which involves continental Africans. You decide to read more, and you then stumble across a novel approach called PRSmix, which integrates PRSs developed using diverse methods, forming an integrated PRS that has been noted to outperform previously reported PRS, as shown below. This seems as a much more pragmatic approach, and you are eager to apply it to your PRS projects. Qn1. May you outline the steps (analysis plan) that you will follow to apply the PRSmix approach to the trait you have been assigned. Indicate the metrics you will use to evaluate the predictivity of the PRS for the trait you have been assigned? Qn2. You have been given 15 to 23 PRSs, phenotype, age, sex and PCs depending on your group data files. May you implement your analysis plan and illustrate the codes and outputs that you will share in the form of an Rmarkdown file . May plot the predictivity of the PRSmix vs other PGS in your data file? Qn3. State the pros and cons of using the PRSmix approach in continental Africans? Figure 1 Predictivity of various PRSs compared to PRSmix (Adopted Buu et al. 2024) Group project data files Group 1 https://github.com/tinashedoc/cvx/blob/main/monodta.txt Group 2 https://github.com/tinashedoc/cvx/blob/main/wbcdta.txt Group 3 https://github.com/tinashedoc/cvx/blob/main/pltdta.txt Group 4 https://github.com/tinashedoc/cvx/blob/main/eosdta.txt","title":"Integration of Polygenic Risk Scores"},{"location":"tmp/practical_docs_hidden/Day5_Projects/#integration-of-polygenic-risk-scores","text":"","title":"Integration of Polygenic Risk Scores"},{"location":"tmp/practical_docs_hidden/Day5_Projects/#task-prsmix-calculation-35-hrs","text":"You have just completed the Wellcome Connecting Science PRS course and are now acquainted with tools such as PRSCSx and BRIDGEPRS. You also got to hear a talk by Prof Nilanjan Chatterjee, who you later realized has been involved in developing three latest PRS software programs, PROSPER, MUSSEL, and CT-SLEB, that claim to improve PRS prediction in Africans. You are now getting overwhelmed by the sheer number of tools to test out and do not know which tool to use for your PRS project, which involves continental Africans. You decide to read more, and you then stumble across a novel approach called PRSmix, which integrates PRSs developed using diverse methods, forming an integrated PRS that has been noted to outperform previously reported PRS, as shown below. This seems as a much more pragmatic approach, and you are eager to apply it to your PRS projects. Qn1. May you outline the steps (analysis plan) that you will follow to apply the PRSmix approach to the trait you have been assigned. Indicate the metrics you will use to evaluate the predictivity of the PRS for the trait you have been assigned? Qn2. You have been given 15 to 23 PRSs, phenotype, age, sex and PCs depending on your group data files. May you implement your analysis plan and illustrate the codes and outputs that you will share in the form of an Rmarkdown file . May plot the predictivity of the PRSmix vs other PGS in your data file? Qn3. State the pros and cons of using the PRSmix approach in continental Africans? Figure 1 Predictivity of various PRSs compared to PRSmix (Adopted Buu et al. 2024)","title":"Task \u2013 PRSmix calculation [3.5 hrs]"},{"location":"tmp/practical_docs_hidden/Day5_Projects/#group-project-data-files","text":"","title":"Group project data files"},{"location":"tmp/practical_docs_hidden/Day5_Projects/#group-1","text":"https://github.com/tinashedoc/cvx/blob/main/monodta.txt","title":"Group 1"},{"location":"tmp/practical_docs_hidden/Day5_Projects/#group-2","text":"https://github.com/tinashedoc/cvx/blob/main/wbcdta.txt","title":"Group 2"},{"location":"tmp/practical_docs_hidden/Day5_Projects/#group-3","text":"https://github.com/tinashedoc/cvx/blob/main/pltdta.txt","title":"Group 3"},{"location":"tmp/practical_docs_hidden/Day5_Projects/#group-4","text":"https://github.com/tinashedoc/cvx/blob/main/eosdta.txt","title":"Group 4"},{"location":"tmp/practical_docs_hidden/practical_images/base/","text":"A place to put the images for the course","title":"Base"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/","text":"Polygenic Risk Score Analyses Workshop 2022 {width=\"2.939998906386702in\" height=\"2.8874989063867016in\"} Day 2: Introduction to Polygenic Risk Scores Day 2 Timetable +------------+--------+-------------------------+---------------------+ | > Time | > T | | > **Presenter | | | itle** | | | +============+========+=========================+=====================+ | > 9:00 - | A | | > - | | > 9:15 | rrival | | | +------------+--------+-------------------------+---------------------+ | > 9:15 - | [Lec | > Introduction to PRS I | > Dr Paul O'Reilly | | > 10:30 | ture]{ | | | | | .under | | | | | line}: | | | +------------+--------+-------------------------+---------------------+ | 10:30 - | > | | > - | | 11:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 11:00 - | > [Lec | | > Dr Paul O'Reilly | | 12:00 | ture]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 12:00 - | > | | > - | | 13:30 | Lunch | | | +------------+--------+-------------------------+---------------------+ | 13:30 - | > | | > Dr Conrad Iyegbe | | 14:30 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > I | | | +------------+--------+-------------------------+---------------------+ | 14:30 - | > | | > - | | 15:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 15:00 - | > | | > Dr Conrad Iyegbe | | 16:00 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 16:00 - | > [S | | > Dr Nicki Tiffin | | 17:00 | pecial | | | | | > Sem | | | | | inar]{ | | | | | .under | | | | | line}: | | | | | > Pol | | | | | ygenic | | | | | > Risk | | | | | > | | | | | Scores | | | | | > | | | | | > + | | | | | > and | | | | | > | | | | | Ethics | | | +------------+--------+-------------------------+---------------------+ Contents Day 2 Timetable 1 Day 2 Timetable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction to Polygenic Score > Analyses 3 Key Learning Outcomes . . . . . . . . . . . . . . . . . . . . . . . . 3 Resources you will be using . . . . . . . . . . . . . . . . . . . . . . 3 Data Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Understanding GWAS Summary Statistics . . . . . . . . . . . . . . 5 Matching the Base and Target Data sets . . . . . . . . . . . . . . . 6 Linkage Disequilibrium in PRS Analyses . . . . . . . . . . . . . . . 7 Performing Clumping . . . . . . . . . . . . . . . . . . . . . . 7 P-Value Thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Height PRS using GW-significant SNPs only . . . . . . . . . 8 Height PRS across multiple P-value thresholds 10 High Resolution Scoring 12 Stratifying Samples by PRS 15 Case Control Studies 17 Cross-Trait Analysis 18 Introduction to Polygenic Score Analyses Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice (Euesden, Lewis & O'Reilly 2015; Choi & O'Reilly 2019) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome Wide Association Stud- ies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals ( wood_defining_2014 ) Download Link Coronary artery disease (CAD) CARDIoGRAM plus C4D consortium GWAS on 60,801 CAD cases and 123,504 controls Download Link (consortium_comprehensive_2015) Data Structure You will find all practical materials in the PRS_Workshop/Day_2 directory. Relevant materials that you should see there at the start of the practical are as follows: Practical Base_Data GIANT_Height.txt cad.add.txt cad.add.readme Target_Data TAR.fam TAR.bim TAR.bed TAR.height TAR.cad TAR.covariate Software plink_mac plink_linux plink.exe PRSice.R PRSice_mac PRSice_linux PRSice_win64.exe {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"} Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a pheno- type, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymor- phism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS sum- mary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs - and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed, where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"} Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes iden- tifying the independent genetic effects (or their best proxies if these are not geno- typed/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of meth- ods using the different options to date ( mak_polygenic_2017 ). In this work- shop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LD- pred ( vilhjalmsson_modeling_2015 ) and lassosum ( mak_polygenic_2017 ) papers. Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 > 0.1, with \ud835\udc5f 2 typically calculated from \ud835\udc5d\u210e\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \u210e\ud835\udc4e\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52 data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( chang_second_2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: 1 cd \\~/Desktop/PRS\\_Workshop/ Next type the following command (NB. See warning below): 1 ./Software/plink_linux 2 --bfile Target_Data/TAR 3 --clump Base_Data/GIANT_Height.txt 4 --clump-p1 1 5 --clump-snp-field MarkerName 6 --clump-field p 7 --clump-kb 250 8 --clump-r2 0.1 9 --out Results/Height {width=\"0.3229155730533683in\" height=\"0.3229166666666667in\"} The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 > 0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43 -value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43 -value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the PRS_Workshop/Day_2 directory, run the following command in the terminal: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --bar-levels 5e-8 14 --no-full 15 --fastscore 16 --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID (--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43 -value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addi- tion, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43 -value \\< 5*\u00d7*10 *\u2212*8 . {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the em- pirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"} Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43 -value threshold provides the \\\"best\\\" predic- tion for our particular data, then we can calculate the PRS under several \ud835\udc43 -value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. []{#_bookmark13 .anchor}Figure 1.1: BARPLOT generated by PRSice {width=\"2.7440616797900264in\" height=\"2.761874453193351in\"} See dudbridge_power_2013 for theory on factors affecting the best-fit PRS). This process is implemented in PRSice and can be performed automatically as fol- lows: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --fastscore 15 --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT (fig. 1.1) generated by PRSice {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43 -value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a large number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot (fig. 1.2) presenting the model fit of PRS calculated at all P-value thresholds. []{#_bookmark15 .anchor}Figure 1.2: High Resolution Plot generated by PRSice {width=\"2.463332239720035in\" height=\"2.455in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user in- puts, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --out Results/Height.sex When covariates were include in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43 \ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by minusing the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43 \ud835\udc45\ud835\udc46). Usually, with categorical variables, dummy variables have to be generated to rep- resent the different categories. Alternatively, residualized phenotype, generated by regresing the covariates against the phenotype, can be used for downstream anal- yses. A useful feature of PRSice is to automatically generate the dummy variable for users. This can be achieved with the following command: 1 Rscript.exe ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --cov-factor Sex 16 --out Results/Height.sex []{#_bookmark16 .anchor}Figure 1.3: Example of a quantile plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot (fig. 1.3). To generate quantile plots in PRSice, simply add --quantile 10 option. {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 10 17 --out Results/Height.sex {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} Figure 1.4: Example of a strata plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} A disadvantage of the quantile plot is that it only seperate samples into quantiles of equal size. However, it is somtimes interesting to investigate whether a specific strata (e.g. top 5% of samples), contain a higher PRS than the reference strata. For example, mavaddat_prediction_2015 found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break, which represents the upper bound of each strata, and --quant-ref, which represents the upper bound of the reference quantile: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 100 17 --quant-break 1,5,10,20,40,60,80,90,95,99,100 18 --quant-ref 60 19 --out Results/Height.sex {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Tar- get_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/cad.add.txt 4 --target Target_Data/TAR 5 --snp markername 6 --A1 effect_allele 7 --A2 noneffect_allele 8 --chr chr 9 --bp bp_hg19 10 --stat beta 11 --beta 12 --pvalue p_dgc 13 --pheno Target_Data/CAD.pheno 14 --binary-target T 15 --out Results/CAD.highres {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"3.5316666666666667in\" height=\"2.066457786526684in\"} []{#_bookmark19 .anchor}Figure 1.5: Plot taken from Ruderfer et al. 2014 {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ruderfer_polygenic_2014 (fig. 1.5), which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/CAD.pheno 12 --binary-target T 13 --out Results/Cross.highres {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Day2.docx"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#day-2-timetable","text":"+------------+--------+-------------------------+---------------------+ | > Time | > T | | > **Presenter | | | itle** | | | +============+========+=========================+=====================+ | > 9:00 - | A | | > - | | > 9:15 | rrival | | | +------------+--------+-------------------------+---------------------+ | > 9:15 - | [Lec | > Introduction to PRS I | > Dr Paul O'Reilly | | > 10:30 | ture]{ | | | | | .under | | | | | line}: | | | +------------+--------+-------------------------+---------------------+ | 10:30 - | > | | > - | | 11:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 11:00 - | > [Lec | | > Dr Paul O'Reilly | | 12:00 | ture]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 12:00 - | > | | > - | | 13:30 | Lunch | | | +------------+--------+-------------------------+---------------------+ | 13:30 - | > | | > Dr Conrad Iyegbe | | 14:30 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > I | | | +------------+--------+-------------------------+---------------------+ | 14:30 - | > | | > - | | 15:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 15:00 - | > | | > Dr Conrad Iyegbe | | 16:00 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 16:00 - | > [S | | > Dr Nicki Tiffin | | 17:00 | pecial | | | | | > Sem | | | | | inar]{ | | | | | .under | | | | | line}: | | | | | > Pol | | | | | ygenic | | | | | > Risk | | | | | > | | | | | Scores | | | | | > | | | | | > + | | | | | > and | | | | | > | | | | | Ethics | | | +------------+--------+-------------------------+---------------------+ Contents Day 2 Timetable 1 Day 2 Timetable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction to Polygenic Score > Analyses 3 Key Learning Outcomes . . . . . . . . . . . . . . . . . . . . . . . . 3 Resources you will be using . . . . . . . . . . . . . . . . . . . . . . 3 Data Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Understanding GWAS Summary Statistics . . . . . . . . . . . . . . 5 Matching the Base and Target Data sets . . . . . . . . . . . . . . . 6 Linkage Disequilibrium in PRS Analyses . . . . . . . . . . . . . . . 7 Performing Clumping . . . . . . . . . . . . . . . . . . . . . . 7 P-Value Thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Height PRS using GW-significant SNPs only . . . . . . . . . 8 Height PRS across multiple P-value thresholds 10 High Resolution Scoring 12 Stratifying Samples by PRS 15 Case Control Studies 17 Cross-Trait Analysis 18","title":"Day 2 Timetable"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#introduction-to-polygenic-score-analyses","text":"","title":"Introduction to Polygenic Score Analyses"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice (Euesden, Lewis & O'Reilly 2015; Choi & O'Reilly 2019) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome Wide Association Stud- ies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals ( wood_defining_2014 ) Download Link Coronary artery disease (CAD) CARDIoGRAM plus C4D consortium GWAS on 60,801 CAD cases and 123,504 controls Download Link","title":"Resources you will be using"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#consortium_comprehensive_2015","text":"","title":"(consortium_comprehensive_2015)"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#data-structure","text":"You will find all practical materials in the PRS_Workshop/Day_2 directory. Relevant materials that you should see there at the start of the practical are as follows: Practical Base_Data GIANT_Height.txt cad.add.txt cad.add.readme Target_Data TAR.fam TAR.bim TAR.bed TAR.height TAR.cad TAR.covariate Software plink_mac plink_linux plink.exe PRSice.R PRSice_mac PRSice_linux PRSice_win64.exe {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"}","title":"Data Structure"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a pheno- type, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymor- phism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Understanding GWAS Summary Statistics"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS sum- mary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs - and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed, where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"}","title":"Matching the Base and Target Data sets"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes iden- tifying the independent genetic effects (or their best proxies if these are not geno- typed/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of meth- ods using the different options to date ( mak_polygenic_2017 ). In this work- shop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LD- pred ( vilhjalmsson_modeling_2015 ) and lassosum ( mak_polygenic_2017 ) papers.","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 > 0.1, with \ud835\udc5f 2 typically calculated from \ud835\udc5d\u210e\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \u210e\ud835\udc4e\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52 data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( chang_second_2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: 1 cd \\~/Desktop/PRS\\_Workshop/ Next type the following command (NB. See warning below): 1 ./Software/plink_linux 2 --bfile Target_Data/TAR 3 --clump Base_Data/GIANT_Height.txt 4 --clump-p1 1 5 --clump-snp-field MarkerName 6 --clump-field p 7 --clump-kb 250 8 --clump-r2 0.1 9 --out Results/Height {width=\"0.3229155730533683in\" height=\"0.3229166666666667in\"} The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 > 0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Performing Clumping"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43 -value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43 -value thresholds.","title":"P-Value Thresholding"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the PRS_Workshop/Day_2 directory, run the following command in the terminal: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --bar-levels 5e-8 14 --no-full 15 --fastscore 16 --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID (--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43 -value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addi- tion, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43 -value \\< 5*\u00d7*10 *\u2212*8 . {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the em- pirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43 -value threshold provides the \\\"best\\\" predic- tion for our particular data, then we can calculate the PRS under several \ud835\udc43 -value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. []{#_bookmark13 .anchor}Figure 1.1: BARPLOT generated by PRSice {width=\"2.7440616797900264in\" height=\"2.761874453193351in\"} See dudbridge_power_2013 for theory on factors affecting the best-fit PRS). This process is implemented in PRSice and can be performed automatically as fol- lows: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --fastscore 15 --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT (fig. 1.1) generated by PRSice {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43 -value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a large number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot (fig. 1.2) presenting the model fit of PRS calculated at all P-value thresholds. []{#_bookmark15 .anchor}Figure 1.2: High Resolution Plot generated by PRSice {width=\"2.463332239720035in\" height=\"2.455in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user in- puts, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --out Results/Height.sex When covariates were include in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43 \ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by minusing the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43 \ud835\udc45\ud835\udc46). Usually, with categorical variables, dummy variables have to be generated to rep- resent the different categories. Alternatively, residualized phenotype, generated by regresing the covariates against the phenotype, can be used for downstream anal- yses. A useful feature of PRSice is to automatically generate the dummy variable for users. This can be achieved with the following command: 1 Rscript.exe ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --cov-factor Sex 16 --out Results/Height.sex []{#_bookmark16 .anchor}Figure 1.3: Example of a quantile plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"}","title":"High Resolution Scoring"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot (fig. 1.3). To generate quantile plots in PRSice, simply add --quantile 10 option. {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 10 17 --out Results/Height.sex {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} Figure 1.4: Example of a strata plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} A disadvantage of the quantile plot is that it only seperate samples into quantiles of equal size. However, it is somtimes interesting to investigate whether a specific strata (e.g. top 5% of samples), contain a higher PRS than the reference strata. For example, mavaddat_prediction_2015 found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break, which represents the upper bound of each strata, and --quant-ref, which represents the upper bound of the reference quantile: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 100 17 --quant-break 1,5,10,20,40,60,80,90,95,99,100 18 --quant-ref 60 19 --out Results/Height.sex {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"}","title":"Stratifying Samples by PRS"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Tar- get_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/cad.add.txt 4 --target Target_Data/TAR 5 --snp markername 6 --A1 effect_allele 7 --A2 noneffect_allele 8 --chr chr 9 --bp bp_hg19 10 --stat beta 11 --beta 12 --pvalue p_dgc 13 --pheno Target_Data/CAD.pheno 14 --binary-target T 15 --out Results/CAD.highres {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"3.5316666666666667in\" height=\"2.066457786526684in\"} []{#_bookmark19 .anchor}Figure 1.5: Plot taken from Ruderfer et al. 2014 {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Case Control Studies"},{"location":"tmp/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ruderfer_polygenic_2014 (fig. 1.5), which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/CAD.pheno 12 --binary-target T 13 --out Results/Cross.highres {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Cross-Trait Analysis"},{"location":"tmp/practical_docs_hidden/practical_images/day3/base/","text":"base","title":"Base"},{"location":"tmp/practical_docs_hidden/scripts/base/","text":"scripts base","title":"Base"},{"location":"tmp/practical_docs_hidden/scripts/day4update/","text":"wget https://raw.githubusercontent.com/WCSCourses/PRS2024/main/scripts/prs24_day4_builds.sh chmod +x prs24_day4_builds.sh ./prs24_day4_builds.sh","title":"Day4update"},{"location":"tmp/prs_2023-main/","text":"Polygenic Risk Scores Uganda 2023 Base for the Polygenic Risk Scores course Repository Course overview The boost in collections of African genomic datasets is providing opportunities for further in-depth understanding of the causes of human diseases. As African genomic data from genome-wide analytical studies continues to grow, it is imperative that African scientists are empowered with skills to analyse these data using the latest tools and approaches for advancing research and genomics applications in Africa and globally. This short course will equip scientists based in Africa with tools and approaches for polygenic risk scores (PRS) analysis. The course will cover both applied and theoretical topics in PRS research, delivered across a variety of lectures, tutorials, computational practicals and special guest seminars from experts in the field. By the end of the workshop, attendees should have an in-depth theoretical understanding and practical skills in PRS analysis of global populations. The course will begin with an overview of genome-wide association studies, an introduction to PRS analysis, advanced topics in PRS (e.g., pathway-based PRS, PRS Environment interactions, PRS to identify rare variants). This will be followed by the key topic of the \u2018PRS Portability Problem\u2019 and how to address it using PRS methods developed for application to diverse and admixed ancestry samples. Finally, attendees will devise, perform and present their own research project as part of a group on a topic relevant to the content of the course, with feedback from the workshop team. PRS Course website Instructors Marion Amujal , Makerere University, Uganda Shakuntala Baichoo , University of Mauritius, Mauritius Palwende Boua , Institut de Recherche en Sciences de la Sant\u00e9, Burkina Faso Tinashe Chikowore , University of the Witwatersrand, South Africa Itunuoluwa Isewon , Covenant University, Nigeria Conrad Iyegbe , Icahn School of Medicine, USA Christopher Kintu ,Makerere University, Uganda Carene Ndong Sima ,Stellenbosch University, South Africa Tsaone Tamuhla, University of Cape Town, South Africa Lesedi Williams , University of Botswana Overview Detailed timetable View Timetable here - \"in dev\" Course manual LMS LMS Link DAILY FEEDBACK Please provide anonymous feedback here Day 1 - GWAS and Relevant Statistics Day 1 Part A Online Manual Day 1 Part B Online Manual Day 2 - Introduction to PRS Day 2 Online Manual - Introduction to PRS Day 3 - Advanced PRS Analyses Day 3 Online Manual - Introduction to PRS Day 4 - Genetic Variation and Population Genetics Day 4 Online Manual - Introduction to PRS Day 5 - Group Projects Day 5 Project Description Appendix Any reuse of the course materials, data or code is encouraged with due acknowledgement. License This work is licensed under a Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) .","title":"Polygenic Risk Scores Uganda 2023"},{"location":"tmp/prs_2023-main/#polygenic-risk-scores-uganda-2023","text":"Base for the Polygenic Risk Scores course Repository","title":"Polygenic Risk Scores Uganda 2023"},{"location":"tmp/prs_2023-main/#course-overview","text":"The boost in collections of African genomic datasets is providing opportunities for further in-depth understanding of the causes of human diseases. As African genomic data from genome-wide analytical studies continues to grow, it is imperative that African scientists are empowered with skills to analyse these data using the latest tools and approaches for advancing research and genomics applications in Africa and globally. This short course will equip scientists based in Africa with tools and approaches for polygenic risk scores (PRS) analysis. The course will cover both applied and theoretical topics in PRS research, delivered across a variety of lectures, tutorials, computational practicals and special guest seminars from experts in the field. By the end of the workshop, attendees should have an in-depth theoretical understanding and practical skills in PRS analysis of global populations. The course will begin with an overview of genome-wide association studies, an introduction to PRS analysis, advanced topics in PRS (e.g., pathway-based PRS, PRS Environment interactions, PRS to identify rare variants). This will be followed by the key topic of the \u2018PRS Portability Problem\u2019 and how to address it using PRS methods developed for application to diverse and admixed ancestry samples. Finally, attendees will devise, perform and present their own research project as part of a group on a topic relevant to the content of the course, with feedback from the workshop team. PRS Course website","title":"Course overview"},{"location":"tmp/prs_2023-main/#instructors","text":"Marion Amujal , Makerere University, Uganda Shakuntala Baichoo , University of Mauritius, Mauritius Palwende Boua , Institut de Recherche en Sciences de la Sant\u00e9, Burkina Faso Tinashe Chikowore , University of the Witwatersrand, South Africa Itunuoluwa Isewon , Covenant University, Nigeria Conrad Iyegbe , Icahn School of Medicine, USA Christopher Kintu ,Makerere University, Uganda Carene Ndong Sima ,Stellenbosch University, South Africa Tsaone Tamuhla, University of Cape Town, South Africa Lesedi Williams , University of Botswana","title":"Instructors"},{"location":"tmp/prs_2023-main/#overview","text":"","title":"Overview"},{"location":"tmp/prs_2023-main/#detailed-timetable","text":"View Timetable here - \"in dev\"","title":"Detailed timetable"},{"location":"tmp/prs_2023-main/#course-manual","text":"LMS LMS Link DAILY FEEDBACK Please provide anonymous feedback here Day 1 - GWAS and Relevant Statistics Day 1 Part A Online Manual Day 1 Part B Online Manual Day 2 - Introduction to PRS Day 2 Online Manual - Introduction to PRS Day 3 - Advanced PRS Analyses Day 3 Online Manual - Introduction to PRS Day 4 - Genetic Variation and Population Genetics Day 4 Online Manual - Introduction to PRS Day 5 - Group Projects Day 5 Project Description Appendix Any reuse of the course materials, data or code is encouraged with due acknowledgement.","title":"Course manual"},{"location":"tmp/prs_2023-main/#license","text":"This work is licensed under a Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) .","title":"License"},{"location":"tmp/prs_2023-main/course_data/readME/","text":"This is a directory for course data Files can be uploaded via command line or web portal You can upload large files via git-lfs https://git-lfs.github.com","title":"This is a directory for course data"},{"location":"tmp/prs_2023-main/course_data/readME/#this-is-a-directory-for-course-data","text":"Files can be uploaded via command line or web portal You can upload large files via git-lfs https://git-lfs.github.com","title":"This is a directory for course data"},{"location":"tmp/prs_2023-main/images/base/","text":"A place to put the images for the course","title":"Base"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/","text":"Polygenic Risk Score Analyses Workshop 2022 {width=\"2.939998906386702in\" height=\"2.8874989063867016in\"} Day 2: Introduction to Polygenic Risk Scores Day 2 Timetable +------------+--------+-------------------------+---------------------+ | > Time | > T | | > **Presenter | | | itle** | | | +============+========+=========================+=====================+ | > 9:00 - | A | | > - | | > 9:15 | rrival | | | +------------+--------+-------------------------+---------------------+ | > 9:15 - | [Lec | > Introduction to PRS I | > Dr Paul O'Reilly | | > 10:30 | ture]{ | | | | | .under | | | | | line}: | | | +------------+--------+-------------------------+---------------------+ | 10:30 - | > | | > - | | 11:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 11:00 - | > [Lec | | > Dr Paul O'Reilly | | 12:00 | ture]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 12:00 - | > | | > - | | 13:30 | Lunch | | | +------------+--------+-------------------------+---------------------+ | 13:30 - | > | | > Dr Conrad Iyegbe | | 14:30 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > I | | | +------------+--------+-------------------------+---------------------+ | 14:30 - | > | | > - | | 15:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 15:00 - | > | | > Dr Conrad Iyegbe | | 16:00 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 16:00 - | > [S | | > Dr Nicki Tiffin | | 17:00 | pecial | | | | | > Sem | | | | | inar]{ | | | | | .under | | | | | line}: | | | | | > Pol | | | | | ygenic | | | | | > Risk | | | | | > | | | | | Scores | | | | | > | | | | | > + | | | | | > and | | | | | > | | | | | Ethics | | | +------------+--------+-------------------------+---------------------+ Contents Day 2 Timetable 1 Day 2 Timetable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction to Polygenic Score > Analyses 3 Key Learning Outcomes . . . . . . . . . . . . . . . . . . . . . . . . 3 Resources you will be using . . . . . . . . . . . . . . . . . . . . . . 3 Data Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Understanding GWAS Summary Statistics . . . . . . . . . . . . . . 5 Matching the Base and Target Data sets . . . . . . . . . . . . . . . 6 Linkage Disequilibrium in PRS Analyses . . . . . . . . . . . . . . . 7 Performing Clumping . . . . . . . . . . . . . . . . . . . . . . 7 P-Value Thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Height PRS using GW-significant SNPs only . . . . . . . . . 8 Height PRS across multiple P-value thresholds 10 High Resolution Scoring 12 Stratifying Samples by PRS 15 Case Control Studies 17 Cross-Trait Analysis 18 Introduction to Polygenic Score Analyses Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice (Euesden, Lewis & O'Reilly 2015; Choi & O'Reilly 2019) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome Wide Association Stud- ies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals ( wood_defining_2014 ) Download Link Coronary artery disease (CAD) CARDIoGRAM plus C4D consortium GWAS on 60,801 CAD cases and 123,504 controls Download Link (consortium_comprehensive_2015) Data Structure You will find all practical materials in the PRS_Workshop/Day_2 directory. Relevant materials that you should see there at the start of the practical are as follows: Practical Base_Data GIANT_Height.txt cad.add.txt cad.add.readme Target_Data TAR.fam TAR.bim TAR.bed TAR.height TAR.cad TAR.covariate Software plink_mac plink_linux plink.exe PRSice.R PRSice_mac PRSice_linux PRSice_win64.exe {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"} Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a pheno- type, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymor- phism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS sum- mary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs - and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed, where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"} Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes iden- tifying the independent genetic effects (or their best proxies if these are not geno- typed/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of meth- ods using the different options to date ( mak_polygenic_2017 ). In this work- shop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LD- pred ( vilhjalmsson_modeling_2015 ) and lassosum ( mak_polygenic_2017 ) papers. Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 > 0.1, with \ud835\udc5f 2 typically calculated from \ud835\udc5d\u210e\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \u210e\ud835\udc4e\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52 data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( chang_second_2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: 1 cd \\~/Desktop/PRS\\_Workshop/ Next type the following command (NB. See warning below): 1 ./Software/plink_linux 2 --bfile Target_Data/TAR 3 --clump Base_Data/GIANT_Height.txt 4 --clump-p1 1 5 --clump-snp-field MarkerName 6 --clump-field p 7 --clump-kb 250 8 --clump-r2 0.1 9 --out Results/Height {width=\"0.3229155730533683in\" height=\"0.3229166666666667in\"} The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 > 0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43 -value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43 -value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the PRS_Workshop/Day_2 directory, run the following command in the terminal: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --bar-levels 5e-8 14 --no-full 15 --fastscore 16 --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID (--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43 -value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addi- tion, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43 -value \\< 5*\u00d7*10 *\u2212*8 . {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the em- pirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"} Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43 -value threshold provides the \\\"best\\\" predic- tion for our particular data, then we can calculate the PRS under several \ud835\udc43 -value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. []{#_bookmark13 .anchor}Figure 1.1: BARPLOT generated by PRSice {width=\"2.7440616797900264in\" height=\"2.761874453193351in\"} See dudbridge_power_2013 for theory on factors affecting the best-fit PRS). This process is implemented in PRSice and can be performed automatically as fol- lows: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --fastscore 15 --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT (fig. 1.1) generated by PRSice {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43 -value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a large number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot (fig. 1.2) presenting the model fit of PRS calculated at all P-value thresholds. []{#_bookmark15 .anchor}Figure 1.2: High Resolution Plot generated by PRSice {width=\"2.463332239720035in\" height=\"2.455in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user in- puts, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --out Results/Height.sex When covariates were include in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43 \ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by minusing the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43 \ud835\udc45\ud835\udc46). Usually, with categorical variables, dummy variables have to be generated to rep- resent the different categories. Alternatively, residualized phenotype, generated by regresing the covariates against the phenotype, can be used for downstream anal- yses. A useful feature of PRSice is to automatically generate the dummy variable for users. This can be achieved with the following command: 1 Rscript.exe ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --cov-factor Sex 16 --out Results/Height.sex []{#_bookmark16 .anchor}Figure 1.3: Example of a quantile plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot (fig. 1.3). To generate quantile plots in PRSice, simply add --quantile 10 option. {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 10 17 --out Results/Height.sex {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} Figure 1.4: Example of a strata plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} A disadvantage of the quantile plot is that it only seperate samples into quantiles of equal size. However, it is somtimes interesting to investigate whether a specific strata (e.g. top 5% of samples), contain a higher PRS than the reference strata. For example, mavaddat_prediction_2015 found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break, which represents the upper bound of each strata, and --quant-ref, which represents the upper bound of the reference quantile: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 100 17 --quant-break 1,5,10,20,40,60,80,90,95,99,100 18 --quant-ref 60 19 --out Results/Height.sex {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Tar- get_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/cad.add.txt 4 --target Target_Data/TAR 5 --snp markername 6 --A1 effect_allele 7 --A2 noneffect_allele 8 --chr chr 9 --bp bp_hg19 10 --stat beta 11 --beta 12 --pvalue p_dgc 13 --pheno Target_Data/CAD.pheno 14 --binary-target T 15 --out Results/CAD.highres {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"3.5316666666666667in\" height=\"2.066457786526684in\"} []{#_bookmark19 .anchor}Figure 1.5: Plot taken from Ruderfer et al. 2014 {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ruderfer_polygenic_2014 (fig. 1.5), which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/CAD.pheno 12 --binary-target T 13 --out Results/Cross.highres {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Day2.docx"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#day-2-timetable","text":"+------------+--------+-------------------------+---------------------+ | > Time | > T | | > **Presenter | | | itle** | | | +============+========+=========================+=====================+ | > 9:00 - | A | | > - | | > 9:15 | rrival | | | +------------+--------+-------------------------+---------------------+ | > 9:15 - | [Lec | > Introduction to PRS I | > Dr Paul O'Reilly | | > 10:30 | ture]{ | | | | | .under | | | | | line}: | | | +------------+--------+-------------------------+---------------------+ | 10:30 - | > | | > - | | 11:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 11:00 - | > [Lec | | > Dr Paul O'Reilly | | 12:00 | ture]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 12:00 - | > | | > - | | 13:30 | Lunch | | | +------------+--------+-------------------------+---------------------+ | 13:30 - | > | | > Dr Conrad Iyegbe | | 14:30 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > I | | | +------------+--------+-------------------------+---------------------+ | 14:30 - | > | | > - | | 15:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 15:00 - | > | | > Dr Conrad Iyegbe | | 16:00 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 16:00 - | > [S | | > Dr Nicki Tiffin | | 17:00 | pecial | | | | | > Sem | | | | | inar]{ | | | | | .under | | | | | line}: | | | | | > Pol | | | | | ygenic | | | | | > Risk | | | | | > | | | | | Scores | | | | | > | | | | | > + | | | | | > and | | | | | > | | | | | Ethics | | | +------------+--------+-------------------------+---------------------+ Contents Day 2 Timetable 1 Day 2 Timetable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction to Polygenic Score > Analyses 3 Key Learning Outcomes . . . . . . . . . . . . . . . . . . . . . . . . 3 Resources you will be using . . . . . . . . . . . . . . . . . . . . . . 3 Data Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Understanding GWAS Summary Statistics . . . . . . . . . . . . . . 5 Matching the Base and Target Data sets . . . . . . . . . . . . . . . 6 Linkage Disequilibrium in PRS Analyses . . . . . . . . . . . . . . . 7 Performing Clumping . . . . . . . . . . . . . . . . . . . . . . 7 P-Value Thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Height PRS using GW-significant SNPs only . . . . . . . . . 8 Height PRS across multiple P-value thresholds 10 High Resolution Scoring 12 Stratifying Samples by PRS 15 Case Control Studies 17 Cross-Trait Analysis 18","title":"Day 2 Timetable"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#introduction-to-polygenic-score-analyses","text":"","title":"Introduction to Polygenic Score Analyses"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice (Euesden, Lewis & O'Reilly 2015; Choi & O'Reilly 2019) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome Wide Association Stud- ies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals ( wood_defining_2014 ) Download Link Coronary artery disease (CAD) CARDIoGRAM plus C4D consortium GWAS on 60,801 CAD cases and 123,504 controls Download Link","title":"Resources you will be using"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#consortium_comprehensive_2015","text":"","title":"(consortium_comprehensive_2015)"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#data-structure","text":"You will find all practical materials in the PRS_Workshop/Day_2 directory. Relevant materials that you should see there at the start of the practical are as follows: Practical Base_Data GIANT_Height.txt cad.add.txt cad.add.readme Target_Data TAR.fam TAR.bim TAR.bed TAR.height TAR.cad TAR.covariate Software plink_mac plink_linux plink.exe PRSice.R PRSice_mac PRSice_linux PRSice_win64.exe {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"}","title":"Data Structure"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a pheno- type, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymor- phism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Understanding GWAS Summary Statistics"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS sum- mary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs - and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed, where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"}","title":"Matching the Base and Target Data sets"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes iden- tifying the independent genetic effects (or their best proxies if these are not geno- typed/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of meth- ods using the different options to date ( mak_polygenic_2017 ). In this work- shop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LD- pred ( vilhjalmsson_modeling_2015 ) and lassosum ( mak_polygenic_2017 ) papers.","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 > 0.1, with \ud835\udc5f 2 typically calculated from \ud835\udc5d\u210e\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \u210e\ud835\udc4e\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52 data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( chang_second_2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: 1 cd \\~/Desktop/PRS\\_Workshop/ Next type the following command (NB. See warning below): 1 ./Software/plink_linux 2 --bfile Target_Data/TAR 3 --clump Base_Data/GIANT_Height.txt 4 --clump-p1 1 5 --clump-snp-field MarkerName 6 --clump-field p 7 --clump-kb 250 8 --clump-r2 0.1 9 --out Results/Height {width=\"0.3229155730533683in\" height=\"0.3229166666666667in\"} The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 > 0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Performing Clumping"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43 -value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43 -value thresholds.","title":"P-Value Thresholding"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the PRS_Workshop/Day_2 directory, run the following command in the terminal: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --bar-levels 5e-8 14 --no-full 15 --fastscore 16 --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID (--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43 -value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addi- tion, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43 -value \\< 5*\u00d7*10 *\u2212*8 . {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the em- pirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43 -value threshold provides the \\\"best\\\" predic- tion for our particular data, then we can calculate the PRS under several \ud835\udc43 -value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. []{#_bookmark13 .anchor}Figure 1.1: BARPLOT generated by PRSice {width=\"2.7440616797900264in\" height=\"2.761874453193351in\"} See dudbridge_power_2013 for theory on factors affecting the best-fit PRS). This process is implemented in PRSice and can be performed automatically as fol- lows: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --fastscore 15 --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT (fig. 1.1) generated by PRSice {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43 -value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a large number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot (fig. 1.2) presenting the model fit of PRS calculated at all P-value thresholds. []{#_bookmark15 .anchor}Figure 1.2: High Resolution Plot generated by PRSice {width=\"2.463332239720035in\" height=\"2.455in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user in- puts, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --out Results/Height.sex When covariates were include in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43 \ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by minusing the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43 \ud835\udc45\ud835\udc46). Usually, with categorical variables, dummy variables have to be generated to rep- resent the different categories. Alternatively, residualized phenotype, generated by regresing the covariates against the phenotype, can be used for downstream anal- yses. A useful feature of PRSice is to automatically generate the dummy variable for users. This can be achieved with the following command: 1 Rscript.exe ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --cov-factor Sex 16 --out Results/Height.sex []{#_bookmark16 .anchor}Figure 1.3: Example of a quantile plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"}","title":"High Resolution Scoring"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot (fig. 1.3). To generate quantile plots in PRSice, simply add --quantile 10 option. {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 10 17 --out Results/Height.sex {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} Figure 1.4: Example of a strata plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} A disadvantage of the quantile plot is that it only seperate samples into quantiles of equal size. However, it is somtimes interesting to investigate whether a specific strata (e.g. top 5% of samples), contain a higher PRS than the reference strata. For example, mavaddat_prediction_2015 found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break, which represents the upper bound of each strata, and --quant-ref, which represents the upper bound of the reference quantile: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 100 17 --quant-break 1,5,10,20,40,60,80,90,95,99,100 18 --quant-ref 60 19 --out Results/Height.sex {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"}","title":"Stratifying Samples by PRS"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Tar- get_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/cad.add.txt 4 --target Target_Data/TAR 5 --snp markername 6 --A1 effect_allele 7 --A2 noneffect_allele 8 --chr chr 9 --bp bp_hg19 10 --stat beta 11 --beta 12 --pvalue p_dgc 13 --pheno Target_Data/CAD.pheno 14 --binary-target T 15 --out Results/CAD.highres {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"3.5316666666666667in\" height=\"2.066457786526684in\"} []{#_bookmark19 .anchor}Figure 1.5: Plot taken from Ruderfer et al. 2014 {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Case Control Studies"},{"location":"tmp/prs_2023-main/images/Day2.docxfolder/Day2.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ruderfer_polygenic_2014 (fig. 1.5), which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/CAD.pheno 12 --binary-target T 13 --out Results/Cross.highres {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Cross-Trait Analysis"},{"location":"tmp/prs_2023-main/images/day3/base/","text":"base","title":"Base"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/","text":"Polygenic Risk Score Analyses Workshop 2023 Day 1a: GWAS & relevant Statistics Introduction to Bash Most software in Bioinformatics and Statistical Genetics need to be run in a Unix environment (e.g. Linux or Mac OS) and most high-performance computer clusters run Unix systems. Therefore, although there are alternatives available on Windows (command line, Linux subsystems or Virtual Machines), it will be highly beneficial to become familiar with performing research in a Unix-only environment. Moving around the File System To begin our practical, please open up a \\\"terminal\\\" on your computer (on a Mac this is stored in Applications/Utilities/). We can change our directory using the following command: cd \\<Path>\\ where *\\ * is the path to the target directory. Some common usage of cd includes cd ~/ # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd XXX # will bring you to the XXX directory, so long as it is in the current directory As an example, we can move to the data directory by typing: cd data/ Looking at the Current Directory Next we can move into the ~/data/Data_Day1b/ folder (from the data/ folder type: cd Data_Day1b/). We can list out the folder content by typing: ls For ls, there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size Counting Number of Lines in File We can also count the number of lines in a file with the following command (where *\\ * is the file of interest): wc -l <file> Often we would like to store the output of a command, which we can do by redirecting the output of the command to a file. For example, we can redirect the count of the GIANT_Height.txt to giant_count using the following command: wc -l GIANT_Height.txt > giant_count.txt Search File Content Another common task is to search for specific words or characters in a file (e.g. does this file contain our gene of interest?). This can be performed using the \"grep\" command as follows: grep <string> file For example, to check if the Single Nucleotide Polymorphism (SNP) rs10786427 is present in GIANT_Height.txt , we can do: grep rs10786427 GIANT_Height.txt In addition, grep allows us to check if patterns contained in one file can be found in another file. For example, if we want to extract a subset of samples from the phenotype file (e.g. extract the list of samples in Data/Day_1a/TAR.height ), we can do: grep -f Select.sample TAR.height An extremely useful feature of the terminal is chaining multiple commands into one command, which we call piping . For example, we can use piping to count the number of samples in Select.sample that were found in TAR.height in a single command, as follows: bash grep -f Select.sample TAR.height | wc -l Filtering and Reshu\ufb04ing Files A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new results file that only contains SNP rsIDs (column 1), allele frequencies (column 4) and P -values (column 7) as follows: awk '{ print $1,$4,$7}' GIANT_Height.txt > GIANT_Height_3cols.txt We can also use a \\\"conditional statement\\\" in awk to extract all significant [SNPs] from the results file, using the following command: awk '{if($7 < 5e-8) { print } }' GIANT_Height.txt > Significant_SNPs.txt Or the short form: awk '$7 < 5e-8{ print}' GIANT_Height.txt > Significant_SNPs.txt \"if( \\(7<5e-8)\" and \"\\) 7 < 5e-8\" tell awk to extract any rows with column 7 (the column containing P -value) with a value of smaller than 5e-8 and {print} means that we would like to print the entire row when this criterion is met. Introduction to R R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop. Basics If you are not using R Studio then you can type R in your terminal to run R in the terminal. ## Adding script to working dir cd ~/data/Day1a_Data/Day1a_Data wget https://raw.githubusercontent.com/WCSCourses/prs_2023/main/scripts/nagelkerke.R Working Directory When we start R , we will be working in a specific folder called the working directory . We can check the current/working directory we are in by typing: getwd() And we can change our working directory to the Practical folder by setwd(\"~/data/Day1a_Data/Day1a_Data\") Libraries Most functionality of R is organised in \\\"packages\\\" or \\\"libraries\\\". To access these functions, we will have to install and \\\"load\\\" these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Alternatively, we can import functions (e.g. that we have written) from an R script file on our computer. For example, you can load the Nagelkerke R2 function by typing source(\"nagelkerke.R\") And you are now able to use the Nagelkerke R2 function (we will use this function at the end of this worksheet). Variables in R You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\") Functions You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2) Plotting While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point() Regression Models In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial)) We will need the NagelkerkeR2 function to calculate the pseudo R2 for logistic model source(\"Software/nagelkerke.R\") reg <- glm(y~x, family=binomial) Calculate the Nagelkerke R2 using the NagelkerkeR2 function NagelkerkeR2(reg)","title":"Polygenic Risk Score Analyses Workshop 2023"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#polygenic-risk-score-analyses-workshop-2023","text":"","title":"Polygenic Risk Score Analyses Workshop 2023"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#day-1a-gwas-relevant-statistics","text":"","title":"Day 1a: GWAS &amp; relevant Statistics"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#introduction-to-bash","text":"Most software in Bioinformatics and Statistical Genetics need to be run in a Unix environment (e.g. Linux or Mac OS) and most high-performance computer clusters run Unix systems. Therefore, although there are alternatives available on Windows (command line, Linux subsystems or Virtual Machines), it will be highly beneficial to become familiar with performing research in a Unix-only environment.","title":"Introduction to Bash"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#moving-around-the-file-system","text":"To begin our practical, please open up a \\\"terminal\\\" on your computer (on a Mac this is stored in Applications/Utilities/). We can change our directory using the following command: cd \\<Path>\\ where *\\ * is the path to the target directory. Some common usage of cd includes cd ~/ # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd XXX # will bring you to the XXX directory, so long as it is in the current directory As an example, we can move to the data directory by typing: cd data/","title":"Moving around the File System"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#looking-at-the-current-directory","text":"Next we can move into the ~/data/Data_Day1b/ folder (from the data/ folder type: cd Data_Day1b/). We can list out the folder content by typing: ls For ls, there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size","title":"Looking at the Current Directory"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#counting-number-of-lines-in-file","text":"We can also count the number of lines in a file with the following command (where *\\ * is the file of interest): wc -l <file> Often we would like to store the output of a command, which we can do by redirecting the output of the command to a file. For example, we can redirect the count of the GIANT_Height.txt to giant_count using the following command: wc -l GIANT_Height.txt > giant_count.txt","title":"Counting Number of Lines in File"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#search-file-content","text":"Another common task is to search for specific words or characters in a file (e.g. does this file contain our gene of interest?). This can be performed using the \"grep\" command as follows: grep <string> file For example, to check if the Single Nucleotide Polymorphism (SNP) rs10786427 is present in GIANT_Height.txt , we can do: grep rs10786427 GIANT_Height.txt In addition, grep allows us to check if patterns contained in one file can be found in another file. For example, if we want to extract a subset of samples from the phenotype file (e.g. extract the list of samples in Data/Day_1a/TAR.height ), we can do: grep -f Select.sample TAR.height An extremely useful feature of the terminal is chaining multiple commands into one command, which we call piping . For example, we can use piping to count the number of samples in Select.sample that were found in TAR.height in a single command, as follows: bash grep -f Select.sample TAR.height | wc -l","title":"Search File Content"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#filtering-and-reshuffling-files","text":"A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new results file that only contains SNP rsIDs (column 1), allele frequencies (column 4) and P -values (column 7) as follows: awk '{ print $1,$4,$7}' GIANT_Height.txt > GIANT_Height_3cols.txt We can also use a \\\"conditional statement\\\" in awk to extract all significant [SNPs] from the results file, using the following command: awk '{if($7 < 5e-8) { print } }' GIANT_Height.txt > Significant_SNPs.txt Or the short form: awk '$7 < 5e-8{ print}' GIANT_Height.txt > Significant_SNPs.txt \"if( \\(7<5e-8)\" and \"\\) 7 < 5e-8\" tell awk to extract any rows with column 7 (the column containing P -value) with a value of smaller than 5e-8 and {print} means that we would like to print the entire row when this criterion is met.","title":"Filtering and Reshu\ufb04ing Files"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#introduction-to-r","text":"R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop.","title":"Introduction to R"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#basics","text":"If you are not using R Studio then you can type R in your terminal to run R in the terminal. ## Adding script to working dir cd ~/data/Day1a_Data/Day1a_Data wget https://raw.githubusercontent.com/WCSCourses/prs_2023/main/scripts/nagelkerke.R","title":"Basics"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#working-directory","text":"When we start R , we will be working in a specific folder called the working directory . We can check the current/working directory we are in by typing: getwd() And we can change our working directory to the Practical folder by setwd(\"~/data/Day1a_Data/Day1a_Data\")","title":"Working Directory"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#libraries","text":"Most functionality of R is organised in \\\"packages\\\" or \\\"libraries\\\". To access these functions, we will have to install and \\\"load\\\" these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Alternatively, we can import functions (e.g. that we have written) from an R script file on our computer. For example, you can load the Nagelkerke R2 function by typing source(\"nagelkerke.R\") And you are now able to use the Nagelkerke R2 function (we will use this function at the end of this worksheet).","title":"Libraries"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#variables-in-r","text":"You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\")","title":"Variables in R"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#functions","text":"You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2)","title":"Functions"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#plotting","text":"While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point()","title":"Plotting"},{"location":"tmp/prs_2023-main/modules/Day1a.docx/#regression-models","text":"In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial)) We will need the NagelkerkeR2 function to calculate the pseudo R2 for logistic model source(\"Software/nagelkerke.R\") reg <- glm(y~x, family=binomial) Calculate the Nagelkerke R2 using the NagelkerkeR2 function NagelkerkeR2(reg)","title":"Regression Models"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/","text":"Polygenic Risk Score Analyses Workshop 2023 Practical 1 Introduction to PLINK I: basics Key Learning Outcomes After completing this practical, you should be able to: Explore and generate genetic data sets needed for GWAS Recode and reorder allelic data Use the PLINK website 4. Select and exclude lists of samples and SNPs \u26a0\ufe0f All data used in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Introduction PLINK is the most popular software program for performing genome-wide association analyses it is extremely extensive, allowing a huge number of analyses to be performed. It also includes many options for reformatting your data and provides useful data summaries. Software packages are usually best learnt by having a go at running some of their basic applications and progressing from there (rather than reading the entire user manual first!) - so we begin by running some basic PLINK commands and then work steadily towards performing more sophisticated analyses through these PLINK tutorials. Command line basics In all of the instructions below: - Anything in between the symbols \\<> needs to be changed in some way. For example, \\<file_name> indicates that you should replace that entire statement (including the \\<> symbols) with the appropriate file name. - Bold indicates non- command-line instructions (e.g. right-click ) Let's begin Open up a terminal Navigate to the Day 1b working directory cd ~/data/Data_Day1b/ List all files in this directory by typing ls Test PLINK with no input by typing plink Note that you can see lots of PLINK options by using the built-in help function: plink --help \ud83d\udcdd Calling PLINK with no output will test if PLINK is installed and available in the directory, because you should see some output showing the PLINK license and some commands. If you do not see this, then please ask for help now! Exploring Data Sets Open an Explorer window ('Finder' on a Mac) and navigate to your PLINK working directory. \ud83d\udcdd An explorer window should show the same files as the ls command Open the file called 'D1D.map' with a Text Editor e.g. by typing right-click > Open . Open the file 'D1D.ped'. Note this is a large file - if it will not open or is very slow, skip this step. Go to the PLINK website http://zzz.bwh.harvard.edu/plink/download.shtml and investigate the format of the MAP/PED files (Look in the blue column on the left side) What do you observe? - What are the 4 columns in the map file? - What are the first 6 columns in a ped file? - What information is in the remaining columns of the ped file? Create 'binary' format PLINK files using the recode command: plink --file D1D --make-bed --out D1D List files ( ls ) and check which new files have appeared Open and examine files ending .bim and .fam. Do not open the .bed file. Open and skim the '.log' file. What do you observe? How is the fam file similar to the ped file? How is it different? How is the bim file similar to the map file? How is it different? (Use the PLINK website if necessary) Recoding alleles as counts Genotype data in allele count format is very useful, for example to use in regression modelling in statistical software such as R. Generate the D1D data in allele count format: plink --bfile D1D --recodeA --out D1D_AC \ud83d\udcdd There are several options for recoding SNPs in different ways - more information on the PLINK website (see next section). Again note that a log file was created - skim the log file or screen output Look inside the .raw file. What do you think the 0/1/2 represent? Do there appear to be more 0s or 2s? Why might this be? PLINK website Go to http://zzz.bwh.harvard.edu/plink/download.shtml and skim through the front page to get an idea of PLINK's functionality. Note the list of clickable links on the left side of the website. Under 'Data Management' (click the heading on the left) and read the list of the di\ufb00erent ways you may want to recode and reorder data sets. Don't attempt to read much further as this is a very large and detailed section - a useful future resource but too much for today. Under 'Data Management', click 'Write SNP list' and read the instructions there to write SNP lists. Write SNP list and extract SNPs You will now use the information that you found on the PLINK website to create a command to extract a list of SNPs. Below is a list of requirements - try to do this before you go to the end of this section, where the full command is given and explained. Set the D1D binary file as input Set MAF threshold to 0.05 Set SNP missingness threshold to 0.05 Add the appropriate command to write out a snp list containing only those SNPs with MAF above 0.05 and missingness below 0.05 Use 'D1D_snps' as the output file name After the command has run, check the output for your SNP list and look at it with the default viewer. You will now use the SNP list that you have created to extract those SNPs and create a new set of data files in a single command. Use the D1D binary file set as input Find the command for extracting a set of SNPs listed in a file (hint: Data Management section) and combine it with a command that you learned above to create binary files Use the output file name 'D1D_MAF_MISS' \ud83d\udcdd Log files are uselful to check that the number of SNPs and samples is as expected. Always check your your log files to ensure that they are sensible. SNP lists can also be used to EXCLUDE SNPs - select 'exclude' above instead of 'extract'. Sample ID lists can also be used to 'keep' or 'remove' individuals in the same 'filter' window. Note that both sample IDs (FID IID,separated by a space are required in the sample file list. Solution 1: TO BE REVEALED LATER!! Solution 2: TO BE REVEALED LATER!! Practical 2 Introduction to PLINK II: Performing QC & GWAS Key Learning Outcomes After completing this practical, you should be able to: Generate summaries of the data needed for QC Apply QC thresholds Perform GWAS Generate summaries to perform QC There are many kinds of summaries of the data that can generated in PLINK in order to perform particular quality control (QC) steps, which help to make our data more reliable. Some of these involve summaries in relation to the individuals (e.g. individual missingness, sex-check) and some relate to summaries of SNP data (e.g. MAF, Hardy-Weinburg Equilibrium). Over the next few sub-sections you will go through some examples of generating summary statistics that can be used to perform QC. Individual missingness Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Open the 2 files that were generated (lmiss & imiss). What do the two output files contain? In the imiss file, what is the meaning of the data in the column headed \"F_MISS\"? SNP Missingness Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Look inside the file containing SNP missingness information: D1D_miss.lmiss. What is the meaning of the value under F_MISS? What does the command --test-missing do and why might it be useful? Hardy-Weinberg Equilibrium Generate HWE statistics using the --hardy option. Use output file name D1D_hardy. Open and examine results. Why are there multiple rows for each SNP and what does each mean? Which of the rows do you think should be used to exclude SNPs from the subsequent analysis (if any) for failing the HWE test? Why? Allele frequencies Generate allele frequencies using the command *--*freq. Use D1D_freq as the output name. Examine the output. What is the heading of the column that tells you which nucleotide is the minor allele? \ud83d\udcdd This information is important to remember as many PLINK files use this notation. The minor allele is always labeled the same way Apply QC filters There are di\ufb00erent strategies for performing QC on your data: (a) Create lists of SNPs and individuals and use --remove, --extract, --exclude, --include to create new file sets (good for documentation, collaboration) (b) Apply thresholds one at a time and generate new bed/bim/fam file (good for applying sequential filters) (c) Use options (e.g. --maf ) in other commands (e.g. --assoc) to remove SNPs or samples at required QC thresholds during analysis. \ud83d\udcdd We have already seen how to select or exclude individuals or SNPs by first creating lists (a), so in this section we will set thresholds to generate new files sets in a single command. However, it is useful to have lists of all SNPs and individuals excluded pre-analysis, according to the reason for exclusion, so generating and retaining such files using the techniques that we used before for good practice. Apply individual missingness thresholds Generate new binary file sets (--make-bed) from the 'D1D' binary file set, removing individuals with missingness greater than 3% using a single command (hint: In the 'Inclusion thresholds' section, see the 'Missing/person' sub-section). Use the output file name 'D1D_imiss3pc' Examine the output files (no need to open, and remember the bed file cannot be read) and the log file How many individuals were in the original file? How many individuals were removed? How many males and females were left after screening? Apply SNP missingness and MAF thresholds Create new binary file sets from the 'D1D_imiss3pc' binary file set (NOT the original D1D files) by setting MAF threshold to 0.05 and SNP missingness threshold to 0.02 (See 'Inclusion thresholds' to obtain the correct threshold flags). Use the output file name'D1D_imiss3pc_lmiss2pc_maf5pc Examine the output files and the log file How many SNPs were in the original files? How many SNPs were removed for low minor allele frequency? How many SNPs were removed for missingness? Apply Hardy-Weinberg thresholds Generate a new binary file set called 'D1D_QC' from the D1D_imiss3pc_lmiss2pc_maf5pc file, applying a HWE threshold of 0.0001. This is our final, QC'ed file set. Examine log and output files. -How many SNPs were removed for HWE p-values below the threshold? \ud83d\udcdd It is useful to know how to do this, but be careful about setting this threshold - strong association signals can cause departure from HWE and you may remove great results! Use a lenient threshold and apply to controls only to avoid this problem. HWE can also be checked post-hoc for each SNP. Perform GWAS Case/Control GWAS - no covariates Run the following code, which performs a genetic association study using logistic regression on some case/control data: plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --out D1D_CC What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Are there any other significant associations? Case/Control GWAS - with covariates Here we repeat the previous analysis but this time including some covariates. The file D1D.pcs1234 contains the first 4 principal components from a PCA on the genetic data. Run the analysis specifying the covariates file: plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --covar D1D.pcs.1234 --out D1D_CC_PCadj What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Suggest a reason for the different results when adjusting for the 4 PCs? License This work is licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License and the below text is a summary of the main terms of the full Legal Code (the full licence) available at https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode You are free to: Share --- copy and redistribute the material in any medium or format Adapt --- remix, transform, and build upon the material The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: Attribution --- You must give appropriate credit, providea link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. NonCommercial --- You may not use the material for commercial purposes. ShareAlike --- If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictions --- You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. Notices: You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation. No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.","title":"Day1b.docx"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#practical-1","text":"","title":"Practical 1"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#introduction-to-plink-i-basics","text":"","title":"Introduction to PLINK I: basics"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Explore and generate genetic data sets needed for GWAS Recode and reorder allelic data Use the PLINK website","title":"Key Learning Outcomes"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#4-select-and-exclude-lists-of-samples-and-snps","text":"\u26a0\ufe0f All data used in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only.","title":"4.  Select and exclude lists of samples and SNPs"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#introduction","text":"PLINK is the most popular software program for performing genome-wide association analyses it is extremely extensive, allowing a huge number of analyses to be performed. It also includes many options for reformatting your data and provides useful data summaries. Software packages are usually best learnt by having a go at running some of their basic applications and progressing from there (rather than reading the entire user manual first!) - so we begin by running some basic PLINK commands and then work steadily towards performing more sophisticated analyses through these PLINK tutorials.","title":"Introduction"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#command-line-basics","text":"In all of the instructions below: - Anything in between the symbols \\<> needs to be changed in some way. For example, \\<file_name> indicates that you should replace that entire statement (including the \\<> symbols) with the appropriate file name. - Bold indicates non- command-line instructions (e.g. right-click )","title":"Command line basics"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#lets-begin","text":"Open up a terminal Navigate to the Day 1b working directory cd ~/data/Data_Day1b/ List all files in this directory by typing ls Test PLINK with no input by typing plink Note that you can see lots of PLINK options by using the built-in help function: plink --help \ud83d\udcdd Calling PLINK with no output will test if PLINK is installed and available in the directory, because you should see some output showing the PLINK license and some commands. If you do not see this, then please ask for help now!","title":"Let's begin"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#exploring-data-sets","text":"Open an Explorer window ('Finder' on a Mac) and navigate to your PLINK working directory. \ud83d\udcdd An explorer window should show the same files as the ls command Open the file called 'D1D.map' with a Text Editor e.g. by typing right-click > Open . Open the file 'D1D.ped'. Note this is a large file - if it will not open or is very slow, skip this step. Go to the PLINK website http://zzz.bwh.harvard.edu/plink/download.shtml and investigate the format of the MAP/PED files (Look in the blue column on the left side) What do you observe? - What are the 4 columns in the map file? - What are the first 6 columns in a ped file? - What information is in the remaining columns of the ped file? Create 'binary' format PLINK files using the recode command: plink --file D1D --make-bed --out D1D List files ( ls ) and check which new files have appeared Open and examine files ending .bim and .fam. Do not open the .bed file. Open and skim the '.log' file. What do you observe? How is the fam file similar to the ped file? How is it different? How is the bim file similar to the map file? How is it different? (Use the PLINK website if necessary)","title":"Exploring Data Sets"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#recoding-alleles-as-counts","text":"Genotype data in allele count format is very useful, for example to use in regression modelling in statistical software such as R. Generate the D1D data in allele count format: plink --bfile D1D --recodeA --out D1D_AC \ud83d\udcdd There are several options for recoding SNPs in different ways - more information on the PLINK website (see next section). Again note that a log file was created - skim the log file or screen output Look inside the .raw file. What do you think the 0/1/2 represent? Do there appear to be more 0s or 2s? Why might this be?","title":"Recoding alleles as counts"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#plink-website","text":"Go to http://zzz.bwh.harvard.edu/plink/download.shtml and skim through the front page to get an idea of PLINK's functionality. Note the list of clickable links on the left side of the website. Under 'Data Management' (click the heading on the left) and read the list of the di\ufb00erent ways you may want to recode and reorder data sets. Don't attempt to read much further as this is a very large and detailed section - a useful future resource but too much for today. Under 'Data Management', click 'Write SNP list' and read the instructions there to write SNP lists.","title":"PLINK website"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#write-snp-list-and-extract-snps","text":"You will now use the information that you found on the PLINK website to create a command to extract a list of SNPs. Below is a list of requirements - try to do this before you go to the end of this section, where the full command is given and explained. Set the D1D binary file as input Set MAF threshold to 0.05 Set SNP missingness threshold to 0.05 Add the appropriate command to write out a snp list containing only those SNPs with MAF above 0.05 and missingness below 0.05 Use 'D1D_snps' as the output file name After the command has run, check the output for your SNP list and look at it with the default viewer. You will now use the SNP list that you have created to extract those SNPs and create a new set of data files in a single command. Use the D1D binary file set as input Find the command for extracting a set of SNPs listed in a file (hint: Data Management section) and combine it with a command that you learned above to create binary files Use the output file name 'D1D_MAF_MISS' \ud83d\udcdd Log files are uselful to check that the number of SNPs and samples is as expected. Always check your your log files to ensure that they are sensible. SNP lists can also be used to EXCLUDE SNPs - select 'exclude' above instead of 'extract'. Sample ID lists can also be used to 'keep' or 'remove' individuals in the same 'filter' window. Note that both sample IDs (FID IID,separated by a space are required in the sample file list. Solution 1: TO BE REVEALED LATER!! Solution 2: TO BE REVEALED LATER!!","title":"Write SNP list and extract SNPs"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#practical-2","text":"","title":"Practical 2"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#introduction-to-plink-ii-performing-qc-gwas","text":"","title":"Introduction to PLINK II: Performing QC &amp; GWAS"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#key-learning-outcomes_1","text":"After completing this practical, you should be able to: Generate summaries of the data needed for QC Apply QC thresholds Perform GWAS","title":"Key Learning Outcomes"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#generate-summaries-to-perform-qc","text":"There are many kinds of summaries of the data that can generated in PLINK in order to perform particular quality control (QC) steps, which help to make our data more reliable. Some of these involve summaries in relation to the individuals (e.g. individual missingness, sex-check) and some relate to summaries of SNP data (e.g. MAF, Hardy-Weinburg Equilibrium). Over the next few sub-sections you will go through some examples of generating summary statistics that can be used to perform QC.","title":"Generate summaries to perform QC"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#individual-missingness","text":"Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Open the 2 files that were generated (lmiss & imiss). What do the two output files contain? In the imiss file, what is the meaning of the data in the column headed \"F_MISS\"?","title":"Individual missingness"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#snp-missingness","text":"Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Look inside the file containing SNP missingness information: D1D_miss.lmiss. What is the meaning of the value under F_MISS? What does the command --test-missing do and why might it be useful?","title":"SNP Missingness"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#hardy-weinberg-equilibrium","text":"Generate HWE statistics using the --hardy option. Use output file name D1D_hardy. Open and examine results. Why are there multiple rows for each SNP and what does each mean? Which of the rows do you think should be used to exclude SNPs from the subsequent analysis (if any) for failing the HWE test? Why?","title":"Hardy-Weinberg Equilibrium"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#allele-frequencies","text":"Generate allele frequencies using the command *--*freq. Use D1D_freq as the output name. Examine the output. What is the heading of the column that tells you which nucleotide is the minor allele? \ud83d\udcdd This information is important to remember as many PLINK files use this notation. The minor allele is always labeled the same way","title":"Allele frequencies"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#apply-qc-filters","text":"","title":"Apply QC filters"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#there-are-different-strategies-for-performing-qc-on-your-data","text":"(a) Create lists of SNPs and individuals and use --remove, --extract, --exclude, --include to create new file sets (good for documentation, collaboration) (b) Apply thresholds one at a time and generate new bed/bim/fam file (good for applying sequential filters) (c) Use options (e.g. --maf ) in other commands (e.g. --assoc) to remove SNPs or samples at required QC thresholds during analysis. \ud83d\udcdd We have already seen how to select or exclude individuals or SNPs by first creating lists (a), so in this section we will set thresholds to generate new files sets in a single command. However, it is useful to have lists of all SNPs and individuals excluded pre-analysis, according to the reason for exclusion, so generating and retaining such files using the techniques that we used before for good practice.","title":"There are di\ufb00erent strategies for performing QC on your data:"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#apply-individual-missingness-thresholds","text":"Generate new binary file sets (--make-bed) from the 'D1D' binary file set, removing individuals with missingness greater than 3% using a single command (hint: In the 'Inclusion thresholds' section, see the 'Missing/person' sub-section). Use the output file name 'D1D_imiss3pc' Examine the output files (no need to open, and remember the bed file cannot be read) and the log file How many individuals were in the original file? How many individuals were removed? How many males and females were left after screening?","title":"Apply individual missingness thresholds"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#apply-snp-missingness-and-maf-thresholds","text":"Create new binary file sets from the 'D1D_imiss3pc' binary file set (NOT the original D1D files) by setting MAF threshold to 0.05 and SNP missingness threshold to 0.02 (See 'Inclusion thresholds' to obtain the correct threshold flags). Use the output file name'D1D_imiss3pc_lmiss2pc_maf5pc Examine the output files and the log file How many SNPs were in the original files? How many SNPs were removed for low minor allele frequency? How many SNPs were removed for missingness?","title":"Apply SNP missingness and MAF thresholds"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#apply-hardy-weinberg-thresholds","text":"Generate a new binary file set called 'D1D_QC' from the D1D_imiss3pc_lmiss2pc_maf5pc file, applying a HWE threshold of 0.0001. This is our final, QC'ed file set. Examine log and output files. -How many SNPs were removed for HWE p-values below the threshold? \ud83d\udcdd It is useful to know how to do this, but be careful about setting this threshold - strong association signals can cause departure from HWE and you may remove great results! Use a lenient threshold and apply to controls only to avoid this problem. HWE can also be checked post-hoc for each SNP.","title":"Apply Hardy-Weinberg thresholds"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#perform-gwas","text":"","title":"Perform GWAS"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#casecontrol-gwas-no-covariates","text":"Run the following code, which performs a genetic association study using logistic regression on some case/control data: plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --out D1D_CC What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Are there any other significant associations?","title":"Case/Control GWAS - no covariates"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#casecontrol-gwas-with-covariates","text":"Here we repeat the previous analysis but this time including some covariates. The file D1D.pcs1234 contains the first 4 principal components from a PCA on the genetic data. Run the analysis specifying the covariates file: plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --covar D1D.pcs.1234 --out D1D_CC_PCadj What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Suggest a reason for the different results when adjusting for the 4 PCs?","title":"Case/Control GWAS - with covariates"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#license","text":"This work is licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License and the below text is a summary of the main terms of the full Legal Code (the full licence) available at https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode","title":"License"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#you-are-free-to","text":"Share --- copy and redistribute the material in any medium or format Adapt --- remix, transform, and build upon the material The licensor cannot revoke these freedoms as long as you follow the license terms.","title":"You are free to:"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#under-the-following-terms","text":"Attribution --- You must give appropriate credit, providea link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. NonCommercial --- You may not use the material for commercial purposes. ShareAlike --- If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictions --- You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.","title":"Under the following terms:"},{"location":"tmp/prs_2023-main/modules/Day1b.docx/#notices","text":"You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation. No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.","title":"Notices:"},{"location":"tmp/prs_2023-main/modules/Day2.docx/","text":"Introduction to Polygenic Risk Scores Table of Contents Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Data Structure You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2),the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice/PRSice_linux -h Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary. Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres \u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status. Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis. Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#introduction-to-polygenic-risk-scores","text":"","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#table-of-contents","text":"Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents","title":"Table of Contents"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#data-structure","text":"You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents","title":"Data Structure"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents","title":"Understanding GWAS Summary Statistics"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents","title":"Matching the Base and Target Data sets"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents","title":"Performing Clumping"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds.","title":"P-Value Thresholding"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2),the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice/PRSice_linux -h Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents","title":"High Resolution Scoring"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents","title":"Stratifying Samples by PRS"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary.","title":"Case Control Studies"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#rscript-prsiceprsicer-prsice-prsiceprsice_linux-base-base_datacadaddtxt-target-target_datatar-snp-markername-a1-effect_allele-a2-noneffect_allele-chr-chr-bp-bp_hg19-stat-beta-beta-pvalue-p_dgc-pheno-target_datacadpheno-binary-target-t-out-resultscadhighres","text":"\u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status.","title":"Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres\n"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis.","title":"Cross-Trait Analysis"},{"location":"tmp/prs_2023-main/modules/Day2.docx/#rscript-prsiceprsicer-prsice-prsiceprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datacadpheno-binary-target-t-out-resultscrosshighres","text":"Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres\n"},{"location":"tmp/prs_2023-main/modules/Day3.docx/","text":"Advanced Polygenic Risk Score Analyses Day 3 - Polygenic Risk Score Analyses Workshop 2023 Table of Contents Key Learning Outcomes Resources you will be using Datasets Exercise 1 Estimating R 2 in case and control studies Exercise 2 Overfitting caused by model optimisation Out of Sample Validation Exercise 3 Distribution of PRS Gene Set Analysis Molecular Signatures Database MSigDB General Transfer Format file Browser Extensible Data BED Gene Set Enrichment Analysis Exercise 4 Gene Set Based PRS Analysis Key Learning Outcomes After completing this practical, you should be able to: 1. know how to adjust for ascertainment bias in case-control analysis 2. Know how over-fitting a\ufb00ects PRS results and how to handle it 3. understand distribution of PRS 4. understand di\ufb00erent file formats involved in gene-set analysis 5. understand di\ufb00erence between self-contained and competitive gene-set analyses 6. Calculate pathway based PRS Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Additional Resources In this practical, we will explore how to perform gene-set based PRS analyses. To perform this analysis, gene-set information and coordinates for the genic regions are required. These information can be obtained from the following database: Data Set Description Download Link Ensembl Human Genome GTF file A file containing the coordinates for genes in the human genome. Used by PRSice to map the SNPs onto genic regions Link MSigDB Gene Sets File containing the gene-set information. Free registration required. Download here after registration Data Sets You will need to download the required files for this tutorial. Download Backup WeTransfer The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following commands. cd data mv ~/Downloads/Day_3.zip . unzip Day_3.zip cd Day_3 You will find all practical materials in the data/Day_3 directory. Relevant materials that you should see there at the start of the practical are as follows: \ud83d\udcc2: Base_Data - GIANT_Height.txt, - cad.add.txt, - cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udcc1: Reference files - Homo_sapiens.GRCh38.86.gt - Sets.gmt \ud83d\udee0\ufe0f: Software - PRSice.R - PRSice_linux - nagelkerke.R - Quantile.R \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Top Exercise 1 Estimating R 2 in case and control studies Bias in R 2 estimation caused by ascertained case/control samples can be adjusted using the equation proposed by Lee et al (2011) , which requires the sample prevalence (case/control ratio) and population prevalence as parameters. This function is implemented in PRSice and the adjustment can be performed by providing the population prevalence to the command --prevalence . Residuals of logistic regression is not well defined, and in PRS analyses, Nagelkerke R 2 is usually used to represent the model R 2 (this is the default of PRSice). However, this R 2 does not account for the di\ufb00erence between sample prevalence (i.e. case-control ratio) and population prevalence, which can lead to bias in the reported R 2 (Figure 1.1a). Figure 1.1: Performance of di\ufb00erent R 2 when the study contains equal portion of cases and controls (a) Nagelkerke R 2 Bias in R 2 estimation caused by ascertained case/control samples can be adjusted using the equation proposed by Lee et al. 2011 (Figure 1.1b) , which requires the sample prevalence (case/control ratio) and population prevalence as parameters. This function is implemented in PRSice and the adjustment can be performed by providing the population prevalence to the command --prevalence . Figure 1.1: Performance of di\ufb00erent R 2 when the study contains equal portion of cases and controls (b) Lee adjusted R 2 Now, account for the ascertainment of the case/control sample by including the population prevalence (let\u2019s assume e.g. 5% here) in the PRSice command to obtain the adjusted (Lee) R 2 : Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/cad.add.txt \\ --target Target_Data/TAR \\ --snp markername \\ --A1 effect_allele \\ --A2 noneffect_allele \\ --chr chr \\ --bp bp_hg19 \\ --stat beta \\ --beta \\ --pvalue p_dgc \\ --pheno Target_Data/TAR.cad \\ --prevalence 0.05 \\ --binary-target T \\ --out Results/CAD.highres.LEER2 The results are written to the \"Results\" directory. Examine the results folder and each file that was generated. For more information about each file type, see here . \u2b50 Check the *.summary file in the Results folder where you will find the usual (Nagelkerke) R 2 and the adjusted (Lee) R 2 . Figure 1.2: Barplot of CAD Lee R 2 \ud83d\udccc To speed up the practical, we have generated a smaller gene-set file. If you want the full gene-set file, you can download it from the link above. \ud83d\udccc All target phenotype data in this workshop are simulated. While they reflect the corresponding trait data, they have no specific biological meaning and are for demonstration purposes only. \u2753Has accounting for the population prevalence a\ufb00ected the R 2 ? Solution Yes, the adjusted R 2 = 0.0521524 and default R 2 = 0.0442664 \u2753Would you expect a di\ufb00erence between the Nagelkerke R 2 and the Lee adjusted R 2 if the case/control ratio in the target sample reflects the disease prevalence in the population? Solution No, the R 2 will be the same because the prevalence of the target is a true representation of the population prevalence. Back to Top Exercise 2 Overfitting caused by model optimisation In PRS analyses, the shrinkage or tuning parameter is usually optimized across a wide range of parametric space (e.g. P -value threshold, proportion of causal SNPs). When both optimisation and association testing are performed on the target data, over-fitted results will be obtained. The accuracy and predictive power of over-fitted results are likely to diminish when replicated in an independent data set. A simple solution is to perform permutation to obtain an empirical P -value for the association model, which is implemented in PRSice. Briefly, permutation is performed as follows: 1) Compute the P -value in your original data, denoted as obs.p, at the \"best\" threshold. 2) Then shu\ufb04e the phenotype and obtain the P -value of the \"best\" threshold for this null phenotype, denoted as null.p 3) Repeat 2) N times 4) Calculate the empirical P-value as: \\( Pemp = (\\sum(obs.p > null.pi + 1) / (N + 1) \\) You will have to specify the number of permutation (N ) to perform by providing --perm N as a parameter to PRSice. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --snp MarkerName \\ --A1 Allele1 \\ --A2 Allele2 \\ --stat b \\ --beta \\ --pvalue p \\ --pheno Target_Data/TAR.height \\ --binary-target F \\ --cov Target_Data/TAR.covariate \\ --cov-col Sex \\ --perm 1000 \\ --out Results/Height.perm Figure 1.3: Barplot of Height using 1000 permutations \ud83d\udcdd 10000 permutations typically provide empirical P-values with high accuracy to the second decimal place (eg. 0.05), but smaller empirical P-values should be considered approximate. \u2753 What is the smallest possible empirical P-value when 10000 permutation are performed? Solution 1.5 X 10 -34 . \u2753 Is the height PRS significantly associated with height after accounting for the over-fitting implicit in identifying the best-fit PRS? How about CAD? Solution Yes, the height PRS is significantly associated with height. After accounting for the over-fitting implicit in identifying the best-fit PRS, the emprical p-value is 0.000999001. Out of Sample Validation The best way to avoid having results that are over-fit is to perform validation on an independent validation data set. We can perform validation of the previous height + covariate analysis with PRSice, using the independent VAL target sample as validation data and the \"best\" P-value threshold predicted in the VAL samples: Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/GIANT_Height.txt \\ --target Target_Data/VAL \\ --snp MarkerName \\ --A1 Allele1 \\ --A2 Allele2 \\ --stat b \\ --beta \\ --pvalue p \\ --pheno Target_Data/VAL.height \\ --binary-target F \\ --no-full \\ --bar-levels 0.0680001 \\ --fastscore \\ --cov Target_Data/VAL.covariate \\ --cov-col Sex \\ --out Results/Height.val Figure 1.4: Barplot of Height validation dataset \u2753 Why do we use --bar-levels 0.0680001 --no-full and --fastscore in this script? \u2753 How does the PRS R2 and P -value for the validation data set compare to the analysis on the TAR target data? Is this what you would expect? Why? Back to Top Exercise 3 Distribution of PRS Many PRS study publications include quantile plots that show an exponential increase in phenotypic value or / Odd Ratios (OR) among the top quantiles (e.g. an S-shaped quantile plot, e.g. Figure 1.6). Figure 1.5: An example of density plot for PRS Figure 1.6: An example of a S-shaped quantile plot This might lead us to believe that individuals with PRS values in the top quantiles have a distinctly di\ufb00erent genetic aetiology compared to the rest of the sample, or that there is epistasis/interactions causing there substantially higher risk. However, when we plot a normally distributed variable (e.g. a PRS) as quantiles on the X-axis then we expect to observe this exponential pattern even when the X variable only has a linear e\ufb00ect on the Y variable. This is because the top (and bottom) quantiles are further away from each other on the absolute scale of the variable and so the di\ufb00erences in their e\ufb00ects are larger than between quantiles in the middle of the distribution. To understand this more, we will perform a simple simulation using R: R # First, we define some simulation parameters n.sample <- 10000 PRS.r2 <- 0.01 # Then, we simulate PRS that follow a random normal distribution prs <- rnorm(n.sample) # We can then simulate the phenotype using the following script pheno <- prs + rnorm(n.sample,mean=0, sd=sqrt(var(prs)*(1-PRS.r2)/(PRS.r2))) # We can examine the relationship between the phenotype and prs # using linear regression summary(lm(pheno~prs)) # Which shows that we have the expected PRS R2 # Group the phenotype and PRS into a data.frame info <- data.frame(SampleID=1:n.sample, PRS=prs, Phenotype=pheno) # Then we can generate the quantile plot. # To save time, we will load in the quantile plot script from Software source(\"./Software/Quantile.R\") # Then we can plot the quantile plot using quantile_plot function quantile_plot(info, \"Results/Height\", 100) Figure 1.7: The resulting quantile plot \u2753 What is the shape of the resulting quantile plot? \u2753 Try plotting the densities of the height or CAD PRS in R * - do they look normally distributed? Why? (*Hint: You can generate a density plot for the PRS in R using plot(density(x)) where x is a vector of the PRS values in the sample). Back to Top Gene Set Analysis Currently, most PRS analyses have been performed on a genome-wide scale, disregarding the underlying biological pathways. Udler et al. 2018 suggest that grouping Single Nucleotide Polymorphisms (SNPs) into biological functional groups can lead to PRS that are more relevant to clinical risk. In this practical, we will go through some common file formats for gene-set analysis and will then calculate some gene-set (or pathway) based PRS. Molecular Signatures Database MSigDB The Molecular Signatures Database (MSigDB) o\ufb00ers an excellent source of gene-sets, including the hallmark genes, gene-sets of di\ufb00erent biological processes, gene-sets of di\ufb00erent oncogenic signatures etc. All gene-sets from MSigDB follows the Gene Matrix Transposed file format (GMT), which consists of one line per gene-set, each containing at least 3 column of data: Set A Description Gene 1 Gene 2 ... Set A Description Gene 1 Gene 2 ... ** Have a look at the Reference/Sets.gmt file. ** \u2753 How many gene-sets are there in the Reference/Sets.gmt file? \u2753 How many genes does the largest gene-set contain? \ud83d\udcac While you can read the GMT file using Excel. You should be aware that Excel has a tendency to convert gene names into dates (e.g. SEPT9 to Sep-9) As GMT format does not contain the chromosomal location for each individual gene, an additional file is required to provide the chromosoaml location such that SNPs can be map to genes. General Transfer Format file The General Transfer Format (GTF) file contains the chromosomal coordinates for each gene. It is a tab separated file and all but the final field in each feature line must contain a value. \"Empty\" columns should be denoted with a \u2018.\u2019. You can read the full format specification here. One column that might be of particular interest is column 3: feature , which indicates what feature that line of GTF represents. This allows us to select or ignore features that are of interest. You can find the description of each feature here . Browser Extensible Data BED Browser Extensible Data (BED) file (di\ufb00erent to the binary ped file from PLINK) is a file format to define genetic regions. It contains 3 required fields per line (chromosome, start coordinate and end coordinate) together with 9 additional optional field. A special property of BED is that it is a 0-based format, i.e. chromosome starts at 0, as opposed to the usual 1-based format such as the PLINK format. For example, a SNP on chr1:10000 will be represented as: 1 9999 10000 \u2753 How should we represent the coordinate of rs2980300 (chr1:785989) in BED format? Back to Top Gene Set Enrichment Analysis Now we have gone through all the files involved in gene-set analysis, we should consider one of the most important aspects of gene-set (or pathway) enrichment analyses, which is the di\ufb00erent types of testing that we can perform when doing them: Self-Contained vs Competitive Testing The null-hypothesis of self-contained and competitive test statistics is di\ufb00erent: \u2013 Self-Contained - None of the genes within the gene-set are associated with the phenotype \u2013 Competitive - Genes within the gene-set are no more associated with the phenotype than genes outside the gene-set Therefore, a bigger gene-set will have a higher likelihood of having a significant P -value from self-contained test, which is not desirable. Exercise 4 Gene Set Based PRS Analysis Having learnt about the basics of gene-set analyses, we are now ready to perform gene-set association analyses using PRSet. To perform the PRSet analysis and obtain the set based PRS and competitive P-value, simply provide the GTF file and the GMT file to PRSice and specify the number of permutation for competitive P-value calculation using the --set-perm option. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --A1 Allele1 \\ --A2 Allele2 \\ --snp MarkerName \\ --pvalue p \\ --stat b \\ --beta \\ --binary-target F \\ --pheno Target_Data/TAR.height \\ --cov Target_Data/TAR.covariate \\ --out Results/Height.set \\ --gtf Reference/Homo_sapiens.GRCh38.86.gtf \\ --wind-5 5kb \\ --wind-3 1kb \\ --msigdb Reference/Sets.gmt \\ --multi-plot 10 \\ --set-perm 1000 Figure 1.8: An example of the multi-set plot. Sets are sorted based on their self-contained R2 . Base is the genome wide PRS \ud83d\udccc If the --wind-5 and --wind-3 flag is not specified, PRSet will use the exact coordinates of each gene as the boundary. By specifying eg. --wind-5 5kb and --wind-3 1kb then the boundary of each gene will be extended 5 kb towards the 5\u2019 end and 1 kb towards the 3\u2019 end so that regulatory elements of the gene can be included. \ud83d\udccd By default, when calculating set based PRS, PRSet will not perform P -value thresholding. This is because the aim in gene-set analyses is to assess the overall signal in each gene-set, and compare which is most enriched for signal, rather than optimise predictive power as typically desirable for genome-wide PRS. Providing any of the following commands will activate P -value thresholding for set based PRS calculation: --lower, --upper, --inter, --bar-levels, --fastscore \u2753 Can you plot the relationship between the gene-set R2 and the number of SNPs in each gene-set? What general trend can be seen? \u2753 Considering the plot, what gene-sets do you think are most interesting and why? \u2753 Why is it useful to have polygenic scores measured across gene-sets (or pathways) for individuals? Isn\u2019t it su\ufb03cient to just obtain a ranking of gene-sets according to GWAS-signal enrichment?","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#advanced-polygenic-risk-score-analyses","text":"","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#day-3-polygenic-risk-score-analyses-workshop-2023","text":"","title":"Day 3 - Polygenic Risk Score Analyses Workshop 2023"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#table-of-contents","text":"Key Learning Outcomes Resources you will be using Datasets Exercise 1 Estimating R 2 in case and control studies Exercise 2 Overfitting caused by model optimisation Out of Sample Validation Exercise 3 Distribution of PRS Gene Set Analysis Molecular Signatures Database MSigDB General Transfer Format file Browser Extensible Data BED Gene Set Enrichment Analysis Exercise 4 Gene Set Based PRS Analysis","title":"Table of Contents"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: 1. know how to adjust for ascertainment bias in case-control analysis 2. Know how over-fitting a\ufb00ects PRS results and how to handle it 3. understand distribution of PRS 4. understand di\ufb00erent file formats involved in gene-set analysis 5. understand di\ufb00erence between self-contained and competitive gene-set analyses 6. Calculate pathway based PRS","title":"Key Learning Outcomes"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#additional-resources","text":"In this practical, we will explore how to perform gene-set based PRS analyses. To perform this analysis, gene-set information and coordinates for the genic regions are required. These information can be obtained from the following database: Data Set Description Download Link Ensembl Human Genome GTF file A file containing the coordinates for genes in the human genome. Used by PRSice to map the SNPs onto genic regions Link MSigDB Gene Sets File containing the gene-set information. Free registration required. Download here after registration","title":"Additional Resources"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#data-sets","text":"You will need to download the required files for this tutorial. Download Backup WeTransfer The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following commands. cd data mv ~/Downloads/Day_3.zip . unzip Day_3.zip cd Day_3 You will find all practical materials in the data/Day_3 directory. Relevant materials that you should see there at the start of the practical are as follows: \ud83d\udcc2: Base_Data - GIANT_Height.txt, - cad.add.txt, - cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udcc1: Reference files - Homo_sapiens.GRCh38.86.gt - Sets.gmt \ud83d\udee0\ufe0f: Software - PRSice.R - PRSice_linux - nagelkerke.R - Quantile.R \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Top","title":"Data Sets"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#exercise-1-estimating-r2-in-case-and-control-studies","text":"Bias in R 2 estimation caused by ascertained case/control samples can be adjusted using the equation proposed by Lee et al (2011) , which requires the sample prevalence (case/control ratio) and population prevalence as parameters. This function is implemented in PRSice and the adjustment can be performed by providing the population prevalence to the command --prevalence . Residuals of logistic regression is not well defined, and in PRS analyses, Nagelkerke R 2 is usually used to represent the model R 2 (this is the default of PRSice). However, this R 2 does not account for the di\ufb00erence between sample prevalence (i.e. case-control ratio) and population prevalence, which can lead to bias in the reported R 2 (Figure 1.1a). Figure 1.1: Performance of di\ufb00erent R 2 when the study contains equal portion of cases and controls (a) Nagelkerke R 2 Bias in R 2 estimation caused by ascertained case/control samples can be adjusted using the equation proposed by Lee et al. 2011 (Figure 1.1b) , which requires the sample prevalence (case/control ratio) and population prevalence as parameters. This function is implemented in PRSice and the adjustment can be performed by providing the population prevalence to the command --prevalence . Figure 1.1: Performance of di\ufb00erent R 2 when the study contains equal portion of cases and controls (b) Lee adjusted R 2 Now, account for the ascertainment of the case/control sample by including the population prevalence (let\u2019s assume e.g. 5% here) in the PRSice command to obtain the adjusted (Lee) R 2 : Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/cad.add.txt \\ --target Target_Data/TAR \\ --snp markername \\ --A1 effect_allele \\ --A2 noneffect_allele \\ --chr chr \\ --bp bp_hg19 \\ --stat beta \\ --beta \\ --pvalue p_dgc \\ --pheno Target_Data/TAR.cad \\ --prevalence 0.05 \\ --binary-target T \\ --out Results/CAD.highres.LEER2 The results are written to the \"Results\" directory. Examine the results folder and each file that was generated. For more information about each file type, see here . \u2b50 Check the *.summary file in the Results folder where you will find the usual (Nagelkerke) R 2 and the adjusted (Lee) R 2 . Figure 1.2: Barplot of CAD Lee R 2 \ud83d\udccc To speed up the practical, we have generated a smaller gene-set file. If you want the full gene-set file, you can download it from the link above. \ud83d\udccc All target phenotype data in this workshop are simulated. While they reflect the corresponding trait data, they have no specific biological meaning and are for demonstration purposes only. \u2753Has accounting for the population prevalence a\ufb00ected the R 2 ? Solution Yes, the adjusted R 2 = 0.0521524 and default R 2 = 0.0442664 \u2753Would you expect a di\ufb00erence between the Nagelkerke R 2 and the Lee adjusted R 2 if the case/control ratio in the target sample reflects the disease prevalence in the population? Solution No, the R 2 will be the same because the prevalence of the target is a true representation of the population prevalence. Back to Top","title":"Exercise 1 Estimating R2 in case and control studies"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#exercise-2-overfitting-caused-by-model-optimisation","text":"In PRS analyses, the shrinkage or tuning parameter is usually optimized across a wide range of parametric space (e.g. P -value threshold, proportion of causal SNPs). When both optimisation and association testing are performed on the target data, over-fitted results will be obtained. The accuracy and predictive power of over-fitted results are likely to diminish when replicated in an independent data set. A simple solution is to perform permutation to obtain an empirical P -value for the association model, which is implemented in PRSice. Briefly, permutation is performed as follows: 1) Compute the P -value in your original data, denoted as obs.p, at the \"best\" threshold. 2) Then shu\ufb04e the phenotype and obtain the P -value of the \"best\" threshold for this null phenotype, denoted as null.p 3) Repeat 2) N times 4) Calculate the empirical P-value as:","title":"Exercise 2 Overfitting caused by model optimisation"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#pemp-sumobsp-nullpi-1-n-1","text":"You will have to specify the number of permutation (N ) to perform by providing --perm N as a parameter to PRSice.","title":"\\(Pemp = (\\sum(obs.p &gt; null.pi + 1) / (N + 1)\\)"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#rscript-softwareprsicer-prsice-softwareprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datatarheight-binary-target-f-cov-target_datatarcovariate-cov-col-sex-perm-1000-out-resultsheightperm","text":"Figure 1.3: Barplot of Height using 1000 permutations \ud83d\udcdd 10000 permutations typically provide empirical P-values with high accuracy to the second decimal place (eg. 0.05), but smaller empirical P-values should be considered approximate. \u2753 What is the smallest possible empirical P-value when 10000 permutation are performed? Solution 1.5 X 10 -34 . \u2753 Is the height PRS significantly associated with height after accounting for the over-fitting implicit in identifying the best-fit PRS? How about CAD? Solution Yes, the height PRS is significantly associated with height. After accounting for the over-fitting implicit in identifying the best-fit PRS, the emprical p-value is 0.000999001.","title":"Rscript ./Software/PRSice.R \\\n    --prsice Software/PRSice_linux \\\n    --base  Base_Data/GIANT_Height.txt \\\n    --target Target_Data/TAR \\\n    --snp MarkerName \\\n    --A1 Allele1 \\\n    --A2 Allele2 \\\n    --stat b \\\n    --beta \\\n    --pvalue p \\\n    --pheno Target_Data/TAR.height \\\n    --binary-target F \\\n    --cov Target_Data/TAR.covariate \\\n    --cov-col Sex \\\n    --perm 1000 \\\n    --out Results/Height.perm\n"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#out-of-sample-validation","text":"The best way to avoid having results that are over-fit is to perform validation on an independent validation data set. We can perform validation of the previous height + covariate analysis with PRSice, using the independent VAL target sample as validation data and the \"best\" P-value threshold predicted in the VAL samples:","title":"Out of Sample Validation"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#rscript-softwareprsicer-prsice-softwareprsice_linux-base-base_datagiant_heighttxt-target-target_dataval-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datavalheight-binary-target-f-no-full-bar-levels-00680001-fastscore-cov-target_datavalcovariate-cov-col-sex-out-resultsheightval","text":"Figure 1.4: Barplot of Height validation dataset \u2753 Why do we use --bar-levels 0.0680001 --no-full and --fastscore in this script? \u2753 How does the PRS R2 and P -value for the validation data set compare to the analysis on the TAR target data? Is this what you would expect? Why? Back to Top","title":"Rscript ./Software/PRSice.R \\\n    --prsice Software/PRSice_linux \\\n    --base  Base_Data/GIANT_Height.txt \\\n    --target Target_Data/VAL \\\n    --snp MarkerName \\\n    --A1 Allele1 \\\n    --A2 Allele2 \\\n    --stat b \\\n    --beta \\\n    --pvalue p \\\n    --pheno Target_Data/VAL.height \\\n    --binary-target F \\\n    --no-full \\\n    --bar-levels 0.0680001 \\\n    --fastscore \\\n    --cov Target_Data/VAL.covariate \\\n    --cov-col Sex \\\n    --out Results/Height.val\n"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#exercise-3-distribution-of-prs","text":"Many PRS study publications include quantile plots that show an exponential increase in phenotypic value or / Odd Ratios (OR) among the top quantiles (e.g. an S-shaped quantile plot, e.g. Figure 1.6). Figure 1.5: An example of density plot for PRS Figure 1.6: An example of a S-shaped quantile plot This might lead us to believe that individuals with PRS values in the top quantiles have a distinctly di\ufb00erent genetic aetiology compared to the rest of the sample, or that there is epistasis/interactions causing there substantially higher risk. However, when we plot a normally distributed variable (e.g. a PRS) as quantiles on the X-axis then we expect to observe this exponential pattern even when the X variable only has a linear e\ufb00ect on the Y variable. This is because the top (and bottom) quantiles are further away from each other on the absolute scale of the variable and so the di\ufb00erences in their e\ufb00ects are larger than between quantiles in the middle of the distribution. To understand this more, we will perform a simple simulation using R: R # First, we define some simulation parameters n.sample <- 10000 PRS.r2 <- 0.01 # Then, we simulate PRS that follow a random normal distribution prs <- rnorm(n.sample) # We can then simulate the phenotype using the following script pheno <- prs + rnorm(n.sample,mean=0, sd=sqrt(var(prs)*(1-PRS.r2)/(PRS.r2))) # We can examine the relationship between the phenotype and prs # using linear regression summary(lm(pheno~prs)) # Which shows that we have the expected PRS R2 # Group the phenotype and PRS into a data.frame info <- data.frame(SampleID=1:n.sample, PRS=prs, Phenotype=pheno) # Then we can generate the quantile plot. # To save time, we will load in the quantile plot script from Software source(\"./Software/Quantile.R\") # Then we can plot the quantile plot using quantile_plot function quantile_plot(info, \"Results/Height\", 100) Figure 1.7: The resulting quantile plot \u2753 What is the shape of the resulting quantile plot? \u2753 Try plotting the densities of the height or CAD PRS in R * - do they look normally distributed? Why? (*Hint: You can generate a density plot for the PRS in R using plot(density(x)) where x is a vector of the PRS values in the sample). Back to Top","title":"Exercise 3 Distribution of PRS"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#gene-set-analysis","text":"Currently, most PRS analyses have been performed on a genome-wide scale, disregarding the underlying biological pathways. Udler et al. 2018 suggest that grouping Single Nucleotide Polymorphisms (SNPs) into biological functional groups can lead to PRS that are more relevant to clinical risk. In this practical, we will go through some common file formats for gene-set analysis and will then calculate some gene-set (or pathway) based PRS.","title":"Gene Set Analysis"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#molecular-signatures-database-msigdb","text":"The Molecular Signatures Database (MSigDB) o\ufb00ers an excellent source of gene-sets, including the hallmark genes, gene-sets of di\ufb00erent biological processes, gene-sets of di\ufb00erent oncogenic signatures etc. All gene-sets from MSigDB follows the Gene Matrix Transposed file format (GMT), which consists of one line per gene-set, each containing at least 3 column of data: Set A Description Gene 1 Gene 2 ... Set A Description Gene 1 Gene 2 ... ** Have a look at the Reference/Sets.gmt file. ** \u2753 How many gene-sets are there in the Reference/Sets.gmt file? \u2753 How many genes does the largest gene-set contain? \ud83d\udcac While you can read the GMT file using Excel. You should be aware that Excel has a tendency to convert gene names into dates (e.g. SEPT9 to Sep-9) As GMT format does not contain the chromosomal location for each individual gene, an additional file is required to provide the chromosoaml location such that SNPs can be map to genes.","title":"Molecular Signatures Database MSigDB"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#general-transfer-format-file","text":"The General Transfer Format (GTF) file contains the chromosomal coordinates for each gene. It is a tab separated file and all but the final field in each feature line must contain a value. \"Empty\" columns should be denoted with a \u2018.\u2019. You can read the full format specification here. One column that might be of particular interest is column 3: feature , which indicates what feature that line of GTF represents. This allows us to select or ignore features that are of interest. You can find the description of each feature here .","title":"General Transfer Format file"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#browser-extensible-data-bed","text":"Browser Extensible Data (BED) file (di\ufb00erent to the binary ped file from PLINK) is a file format to define genetic regions. It contains 3 required fields per line (chromosome, start coordinate and end coordinate) together with 9 additional optional field. A special property of BED is that it is a 0-based format, i.e. chromosome starts at 0, as opposed to the usual 1-based format such as the PLINK format. For example, a SNP on chr1:10000 will be represented as: 1 9999 10000 \u2753 How should we represent the coordinate of rs2980300 (chr1:785989) in BED format? Back to Top","title":"Browser Extensible Data BED"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#gene-set-enrichment-analysis","text":"Now we have gone through all the files involved in gene-set analysis, we should consider one of the most important aspects of gene-set (or pathway) enrichment analyses, which is the di\ufb00erent types of testing that we can perform when doing them:","title":"Gene Set Enrichment Analysis"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#self-contained-vs-competitive-testing","text":"The null-hypothesis of self-contained and competitive test statistics is di\ufb00erent: \u2013 Self-Contained - None of the genes within the gene-set are associated with the phenotype \u2013 Competitive - Genes within the gene-set are no more associated with the phenotype than genes outside the gene-set Therefore, a bigger gene-set will have a higher likelihood of having a significant P -value from self-contained test, which is not desirable.","title":"Self-Contained vs Competitive Testing"},{"location":"tmp/prs_2023-main/modules/Day3.docx/#exercise-4-gene-set-based-prs-analysis","text":"Having learnt about the basics of gene-set analyses, we are now ready to perform gene-set association analyses using PRSet. To perform the PRSet analysis and obtain the set based PRS and competitive P-value, simply provide the GTF file and the GMT file to PRSice and specify the number of permutation for competitive P-value calculation using the --set-perm option. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --A1 Allele1 \\ --A2 Allele2 \\ --snp MarkerName \\ --pvalue p \\ --stat b \\ --beta \\ --binary-target F \\ --pheno Target_Data/TAR.height \\ --cov Target_Data/TAR.covariate \\ --out Results/Height.set \\ --gtf Reference/Homo_sapiens.GRCh38.86.gtf \\ --wind-5 5kb \\ --wind-3 1kb \\ --msigdb Reference/Sets.gmt \\ --multi-plot 10 \\ --set-perm 1000 Figure 1.8: An example of the multi-set plot. Sets are sorted based on their self-contained R2 . Base is the genome wide PRS \ud83d\udccc If the --wind-5 and --wind-3 flag is not specified, PRSet will use the exact coordinates of each gene as the boundary. By specifying eg. --wind-5 5kb and --wind-3 1kb then the boundary of each gene will be extended 5 kb towards the 5\u2019 end and 1 kb towards the 3\u2019 end so that regulatory elements of the gene can be included. \ud83d\udccd By default, when calculating set based PRS, PRSet will not perform P -value thresholding. This is because the aim in gene-set analyses is to assess the overall signal in each gene-set, and compare which is most enriched for signal, rather than optimise predictive power as typically desirable for genome-wide PRS. Providing any of the following commands will activate P -value thresholding for set based PRS calculation: --lower, --upper, --inter, --bar-levels, --fastscore \u2753 Can you plot the relationship between the gene-set R2 and the number of SNPs in each gene-set? What general trend can be seen? \u2753 Considering the plot, what gene-sets do you think are most interesting and why? \u2753 Why is it useful to have polygenic scores measured across gene-sets (or pathways) for individuals? Isn\u2019t it su\ufb03cient to just obtain a ranking of gene-sets according to GWAS-signal enrichment?","title":"Exercise 4 Gene Set Based PRS Analysis"},{"location":"tmp/prs_2023-main/modules/Day4.docx/","text":"Introduction to Cross-Ancestry PRS analysis Before starting the practical the following commands will need to be run from within your virtual machine: (1) conda create -n \"PRScsx\" python=3.7 (2) conda activate PRScsx (3) pip install scipy (4) pip install h5py The goal of this practical is to provide you with basic understanding and experience of running the PRS-CSx software. After completing this practical, you should: * Be able to perform cross-population descriptives. * Be familiar with running cross-ancestry PRS analyses using PRS-CSx. * Understand how to evaluate linear models using Akaike\u2019s Information Criterion 1. The 1000 Genomes dataset The data we will be working with are coming from the 1000 Genomes Project reference panel. The data relates to individuals from 26 different source populations around the world. For simplicity, the populations have been collapsed into 5 broader continental super-populations: East Asian, European, South Asian, Amerindian, African ((EAS, EUR, SAS, EUR and AFR)). The scripts used to download and process the 1000Genomes data for the purposes of this course will be provided in the course appendix at the end of this week. 2. Cross-population allele frequency Genetic variation is conveyed using allelic frequencies. Allele frequency is shaped by evolutionary forces and drift. Here we compare profiles of allele frequency across the five ancestral populations. Global differences in allelic frequency has important implications for the portability of PRS across populations. Using plink it is possible to generate allele frequency statistics for each SNP, across populations, using the annotations provided in the file pop_info.pheno. In /home/manager/data/Data_Day4 : ./software/plink_linux --bfile ./data/chr1-22 --freq --within ./data/pop_info.pheno Population-stratified allele frequencies are reported in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: grep -F 'AFR' plink.frq.strat | wc -l From there we can print the number of SNPs with minor allele frequencies greater than 0 (and are hence potentially available for genomic analyes). grep -F 'EAS' plink.frq.strat | awk '$6 >0' | wc -l Recycle the code above to find the number of available SNPs in each of the 4 other global populations (EUR, AFR, SAS, AMR). Questions (i) Which population contains the most SNPs? (ii) What is the significance of the observed population order? 3. Distribution of allele frequencies R library ( dplyr ) library ( ggplot2 ) freq <-read.table ( \"plink.frq.strat\" , header = T ) plotDat <- freq %>% mutate ( AlleleFrequency = cut ( MAF, seq (0 , 1 , 0 .25 ))) %>% group_by ( AlleleFrequency, CLST ) %>% summarise ( FractionOfSNPs = n () /nrow ( freq ) * 100) ggplot ( na.omit ( plotDat ) , aes ( AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST )) + geom_line () + scale_y_continuous ( limits = c (0 , 12)) + ggtitle ( \"Distribution of allele frequency across genome\" ) Questions (i) Which population has the most SNPs? (ii) What is the significance of the observed population ordering? (iii) What is the reason behind these two features? 4. Calculation of Fst Fst is a formal metric which is used to convey the level of genetic divergence between populations (on a scale between 0 and 1), using information derived from a set of genome-wide and mutually independent SNPs. Fst between parwise populations is estimated efficiently in Plink-2. So first we need to download Plink-2 using the command below: sudo apt install plink2 A higher Fst corresponds to greater divergence between populations. Use the following command to calculate Fst: plink2 --bfile ./data/chr1-22 --fst POP --pheno ./data/pop_info.pheno Check the output file plink2.fst.summary Questions (i) Which population pairs have the highest Fst ? (ii) For which populations is Fst smallest?? Introduction to PRS-CSx 5. Background to PRS-CSX PRS-CSx is a Python based command line tool that integrates GWAS summary statistics and external LD reference panels from multiple populations to improve cross-population polygenic prediction. We will be using simulated trait data pertaininng to systolic blood pressure (SBP) to explore PRS performance using 2 target populations that consist of 650 individuals of African ancestry and 500 individuals of European ancestry. Please note when running PRSice that the object of the flag \"--prsice\" will change according to whether plink is being called within the linux-like environment of the virtual machine (PRSice_linux) or a mac (PRSice_mac). Both executables can be found in the /home/manager/data/Data_Day4 directory. 6. Extraction of SNPs PRS-CSx uses only HAPMAP3 SNPs therefore we produce a set of plink files containing this SNP subset. ./software/plink_linux --bfile ./data/1kg.eur.dbSNP153.hg38 --extract ./data/csxsnp --make-bed --out ./data/EUR_1kg.hm3.only.csx ./software/plink_linux --bfile ./data/1kg.afr.dbSNP153.hg38 --extract ./data/csxsnp --make-bed --out ./data/AFR_1kg.hm3.only.csx 7. Running PRS-CSx To model the coupling of effect sizes at individual SNPs across ancestries PRS-CSx uses an MCMC (Bayesian) sampling algorithm to determine values of the global shrinkage parameter (\"phi\") by Maximum likelihood. For samples of mixed or admixed genetic ancestry (which ours are not) the optimal value of the shrinkage parameter is estimated autonomously from the data. Here we use the value of phi (1e-4), which is suggested by the software authors, given that our trait is simulated to have a relatively small number (N=110) causal variants, distributed genome-wide. To save time, we will be running the analyses across chromosome 15, rather than the entire genome. The commands needed to run PRS-CSx are contained in two script files, located in /home/manager/data/Data_Day4/scripts. The file run_prscsx_afr-target.sh is used to estimate optimal SNP weights for predicting into the African target population. NB - move the snp file to the reference folder cp /home/manager/PRScsx/snpinfo_mult_1kg_hm3 /home/manager/data/Data_Day4/reference/csx NB - the ld block files must be moved to /home/manager/data/Data_Day4/reference/csx to /home/manager/PRScsx/ mv /home/manager/PRScsx/*.tar.gz /home/manager/PRScsx/ then extracted with tar tar -xvfz ld...tar.gz be careful of space, your vm has 100GB cap. remove the .gz files once extracted Script contents : python /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir = /home/manager/data/Data_Day4/reference/csx \\ --bim_prefix = /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --sst_file = /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx,/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --n_gwas =25732 ,4855 \\ --pop = EUR,AFR \\ --chrom =15 \\ --phi = 1e-4 \\ --out_dir = /home/manager/data/Data_Day4/out/csx \\ --out_name = afr.target.csx The file run_prscsx_eur-target.sh is used to estimate optimal SNP weights for predicting into the European target population: Script contents : python /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir = /home/manager/data/Data_Day4/reference/csx \\ --bim_prefix = /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --sst_file = /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx,/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --n_gwas =25732 ,4855 \\ --pop = EUR,AFR \\ --chrom =15 \\ --phi = 1e-4 \\ --out_dir = /home/manager/data/Data_Day4/out/csx \\ --out_name = eur.target.csx Prior to running each script you will need to update the first line with a reference (i.e the pathname) to your home directory. From /home/manager/data/Data_Day4 the scripts can then be run as follows: ./scripts/run_prscsx_afr-target.sh ./scripts/run_prscsx_eur-target.sh Questions (i) How many results files do you see in the output directory? (ii) What does each file correspond to? (ii) In which column are the adjusted SNP weights contained? 8. Processing The next step would be to collate adjusted SNP weight information from multiple chromosomes and relabel the consolidated files for clarity. The following code works regardless of whether the preceding PRS-CSx analysis was performed for single or multiple chromosomes. In /home/manager/data/Data_Day4/out/csx for file in afr.target.csx_AFR_*; do cat $file >> posteriors.afr.by.afr done for file in afr.target.csx_EUR_*; do cat $file >> posteriors.afr.by.eur done for file in eur.target.csx_AFR_*; do cat $file >> posteriors.eur.by.afr done for file in eur.target.csx_EUR_*; do cat $file >> posteriors.eur.by.eur done 9. Data processing in R The next stage of data processing, done in R will create a new set of summary statistics files, containing the adjusting SNP weights from PRS-CSx. Staying in /home/manager/data/Data_Day4/out/csx : R # Load posteriors effect sizes from PRS-CSx output afr.afr<-read.table ( \"posteriors.afr.by.afr\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.afr.afr\" )) afr.by.eur<-read.table ( \"posteriors.afr.by.eur\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.afr.by.eur\" )) eur.eur<-read.table ( \"posteriors.eur.by.eur\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.eur.eur\" )) eur.by.afr<-read.table ( \"posteriors.eur.by.afr\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.eur.by.afr\" )) # Load original summary statistics afr.SBP<-read.table ( \"/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx\" , header = T ) eur.SBP<-read.table ( \"/home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx\" , header = T ) # Combine the posterior derived weights and summary statistics eur.SBP.merge1<-merge ( x = eur.SBP, y = eur.eur [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) eur.SBP.merge<-merge ( x = eur.SBP.merge1, y = afr.by.eur [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) afr.SBP.merge1<-merge ( x = afr.SBP, y = afr.afr [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) afr.SBP.merge<-merge ( x = afr.SBP.merge1, y = eur.by.afr [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) # Save files write.table ( afr.SBP.merge, \"/home/manager/data/Data_Day4/afr.SBP.posterior.sumstats\" , quote = F, row.names = F ) write.table ( eur.SBP.merge, \"/home/manager/data/Data_Day4/eur.SBP.posterior.sumstats\" , quote = F, row.names = F ) q () 10. Use PRSice to apply the adjusted SNP effects to target phenotypes We first need to create a list of SNPs to be used as input, based on the previous PRS-CSx analysis. This is done in location /home/manager/data/Data_Day4 . awk 'NR>1 {print $1}' afr.SBP.posterior.sumstats > snps.afr.posterior awk 'NR>1 {print $1}' eur.SBP.posterior.sumstats > snps.eur.posterior The next series of commands implement in-ancestry and cross-ancestry prediction of the systolic blood pressure phenotype using the PRS-CSx optimised SNP weights. Do not forget to exchange PRSice_linux for PRSice_mac if running the commands in a Mac environment. The phenotypic files sbp_afr_1kg.sim_pheno and sbp_eur_1kg.sim_pheno contain data on systolic blood pressure with simulated heritabilities that vary from 10%, 20%, 33%, 50% and 100%. To compensate for the fact that the adjusted weights generated are based on chromosome 15, rather than the entire genome, we will be using the 100% trait version (pheno100) for this analysis. 11. Predicting from African training to African target data Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/afr.sbp.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.afr.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.afr.afr \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.afr 12. Predicting from European training to African target data Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/eur.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.eur.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.afr.by.eur \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.by.eur 13. Predicting from European training to European target data Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/eur.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.eur.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.eur.eur \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.eur 14. Predicting from African training to European target data Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/afr.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.afr.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.eur.by.afr \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.by.afr 15. Create summary files From location /home/manager/data/Data_Day4/out/prscsx_prsice awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.afr.afr.summary > quicksum.afr-afr awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.afr.by.eur.summary > quicksum.afr-by-eur awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.eur.by.afr.summary > quicksum.eur-by-afr awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.eur.eur.summary > quicksum.eur-eur Questions (i) What information is being summarized in the output files?? (ii) For each prediction model what is the R2 and value??? 16. Complete the remaining PRS analysis in R Step 1: Load and prepare data R # Load libraries sudo apt install cmake install.packages ( \"AICcmodavg\" ) install.packages ( \"fmsb\" ) library ( AICcmodavg ) library ( fmsb ) afr.afr<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.afr.best\" , header = T ) afr.eur<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.by.eur.best\" , header = T ) eur.eur<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.eur.best\" , header = T ) eur.afr<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.by.afr.best\" , header = T ) colnames ( afr.afr )[4] <- \"afr.afr\" # african prediction using african PRS colnames ( afr.eur )[4] <- \"afr.eur\" # african prediction using european PRS colnames ( eur.eur )[4] <- \"eur.eur\" # european prediction using european PRS colnames ( eur.afr )[4] <- \"eur.afr\" # european prediction using african PRS # Merge PRSs according to target ancestry and source population combined.afr<-merge ( x = afr.afr, y = afr.eur [ c (2 ,4 )] , by = \"IID\" , all.x = T ) combined.eur<-merge ( x = eur.eur, y = eur.afr [ c (2 ,4 )] , by = \"IID\" , all.x = T ) # Rescale scores to have mean = \u20180\u2019 and standard deviation = \u20181\u2019 combined.afr [4 :5 ] <- as.data.frame ( scale ( combined.afr [4 :5 ])) combined.eur [4 :5 ] <- as.data.frame ( scale ( combined.eur [4 :5 ])) # Load phenotype data sbp.eur<-read.table ( \"/home/manager/data/Data_Day4/data/SBP_eur_1kg.sim_pheno\" , header = T ) sbp.afr<-read.table ( \"/home/manager/data/Data_Day4/data/SBP_afr_1kg.sim_pheno\" , header = T ) # Merge phenotypes and PRS combined.eur.pheno<-merge ( x = combined.eur [ -c (2 ,3 )] , y = sbp.eur [ ,c (2 ,3 )] , by = \"IID\" , all.x = T ) combined.afr.pheno<-merge ( x = combined.afr [ -c (2 ,3 )] , y = sbp.afr [ ,c (2 ,3 )] , by = \"IID\" , all.x = T ) Step 2: Model selection using Akaike\u2019s Information Criterion In the final step we want to determine whether the use of the multi-ancestry PRS formulation generated by PRS-CSx performs better at predicting systolic blood pressure, compared to the single-ancestry PRS formulation. To do this we use (AIC Akaike\u2019s Information Criterion). AIC is used to assess the performance of a competing set of regression models. We use it to compare the performance of models that contain different numbers of predictors, given that R2 is inflated by the inclusion of redundant terms in a model. 16b. Model evaluation # EUROPEAN model1.eur <- glm ( pheno100 ~ eur.eur, data = combined.eur.pheno, family = gaussian ) model2.eur <- glm ( pheno100 ~ eur.afr, data = combined.eur.pheno, family = gaussian ) model3.eur <- glm ( pheno100 ~ eur.eur + eur.afr, data = combined.eur.pheno, family = gaussian ) models.eur <- list ( model1.eur, model2.eur, model3.eur ) # define model set mod.names.eur <- c ( 'eur.eur' , 'eur.afr' , 'eur.combined' ) # add model names aictab ( cand.set = models.eur, modnames = mod.names.eur ) # calculate model AICs model # AFRICAN model1.afr <- glm ( pheno100 ~ afr.afr, data = combined.afr.pheno, family = gaussian ) model2.afr <- glm ( pheno100 ~ afr.eur, data = combined.afr.pheno, family = gaussian ) model3.afr <- glm ( pheno100 ~ afr.afr + afr.eur, data = combined.afr.pheno, family = gaussian ) models.afr <- list ( model1.afr, model2.afr, model3.afr ) # define model set mod.names.afr <- c ( 'afr.afr' , 'afr.eur' , 'afr.combined' ) # add model names aictab ( cand.set = models.afr, modnames = mod.names.afr ) # calculate model AICs # NagelkerkeR2 calculations in R # African target NagelkerkeR2 ( model1.afr ) NagelkerkeR2 ( model2.afr ) NagelkerkeR2 ( model3.afr ) # European target NagelkerkeR2 ( model1.eur ) NagelkerkeR2 ( model2.eur ) NagelkerkeR2 ( model3.eur ) For each ancestry which predictive model performs best and worst? Does combining the two sets of adjusted scores perform consistently better than modelling each one separately? Questions (i) For each ancestry which model performs best and which performs worst? (ii) Does linearly combining adjusted scores (European plus African) always result in better performance compared to single-ancestry prediction?","title":"Day4.docx"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#introduction-to-cross-ancestry-prs-analysis","text":"Before starting the practical the following commands will need to be run from within your virtual machine: (1) conda create -n \"PRScsx\" python=3.7 (2) conda activate PRScsx (3) pip install scipy (4) pip install h5py The goal of this practical is to provide you with basic understanding and experience of running the PRS-CSx software. After completing this practical, you should: * Be able to perform cross-population descriptives. * Be familiar with running cross-ancestry PRS analyses using PRS-CSx. * Understand how to evaluate linear models using Akaike\u2019s Information Criterion","title":"Introduction to Cross-Ancestry PRS analysis"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#1-the-1000-genomes-dataset","text":"The data we will be working with are coming from the 1000 Genomes Project reference panel. The data relates to individuals from 26 different source populations around the world. For simplicity, the populations have been collapsed into 5 broader continental super-populations: East Asian, European, South Asian, Amerindian, African ((EAS, EUR, SAS, EUR and AFR)). The scripts used to download and process the 1000Genomes data for the purposes of this course will be provided in the course appendix at the end of this week.","title":"1. The 1000 Genomes dataset"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#2-cross-population-allele-frequency","text":"Genetic variation is conveyed using allelic frequencies. Allele frequency is shaped by evolutionary forces and drift. Here we compare profiles of allele frequency across the five ancestral populations. Global differences in allelic frequency has important implications for the portability of PRS across populations. Using plink it is possible to generate allele frequency statistics for each SNP, across populations, using the annotations provided in the file pop_info.pheno. In /home/manager/data/Data_Day4 : ./software/plink_linux --bfile ./data/chr1-22 --freq --within ./data/pop_info.pheno Population-stratified allele frequencies are reported in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: grep -F 'AFR' plink.frq.strat | wc -l From there we can print the number of SNPs with minor allele frequencies greater than 0 (and are hence potentially available for genomic analyes). grep -F 'EAS' plink.frq.strat | awk '$6 >0' | wc -l Recycle the code above to find the number of available SNPs in each of the 4 other global populations (EUR, AFR, SAS, AMR).","title":"2. Cross-population allele frequency"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#questions","text":"","title":"Questions"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#i-which-population-contains-the-most-snps","text":"","title":"(i) Which population contains the most SNPs?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#ii-what-is-the-significance-of-the-observed-population-order","text":"","title":"(ii) What  is the significance of the observed population order?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#3-distribution-of-allele-frequencies","text":"R library ( dplyr ) library ( ggplot2 ) freq <-read.table ( \"plink.frq.strat\" , header = T ) plotDat <- freq %>% mutate ( AlleleFrequency = cut ( MAF, seq (0 , 1 , 0 .25 ))) %>% group_by ( AlleleFrequency, CLST ) %>% summarise ( FractionOfSNPs = n () /nrow ( freq ) * 100) ggplot ( na.omit ( plotDat ) , aes ( AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST )) + geom_line () + scale_y_continuous ( limits = c (0 , 12)) + ggtitle ( \"Distribution of allele frequency across genome\" )","title":"3. Distribution of allele frequencies"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#questions_1","text":"","title":"Questions"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#i-which-population-has-the-most-snps","text":"","title":"(i) Which population has the most SNPs?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#ii-what-is-the-significance-of-the-observed-population-ordering","text":"","title":"(ii) What  is the significance of the observed population ordering?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#iii-what-is-the-reason-behind-these-two-features","text":"","title":"(iii) What is the reason behind these two features?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#4-calculation-of-fst","text":"Fst is a formal metric which is used to convey the level of genetic divergence between populations (on a scale between 0 and 1), using information derived from a set of genome-wide and mutually independent SNPs. Fst between parwise populations is estimated efficiently in Plink-2. So first we need to download Plink-2 using the command below: sudo apt install plink2 A higher Fst corresponds to greater divergence between populations. Use the following command to calculate Fst: plink2 --bfile ./data/chr1-22 --fst POP --pheno ./data/pop_info.pheno Check the output file plink2.fst.summary","title":"4. Calculation of Fst"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#questions_2","text":"","title":"Questions"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#i-which-population-pairs-have-the-highest-fst","text":"","title":"(i) Which population pairs have the highest Fst ?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#ii-for-which-populations-is-fst-smallest","text":"","title":"(ii) For which populations is Fst smallest??"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#introduction-to-prs-csx","text":"","title":"Introduction to PRS-CSx"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#5-background-to-prs-csx","text":"PRS-CSx is a Python based command line tool that integrates GWAS summary statistics and external LD reference panels from multiple populations to improve cross-population polygenic prediction. We will be using simulated trait data pertaininng to systolic blood pressure (SBP) to explore PRS performance using 2 target populations that consist of 650 individuals of African ancestry and 500 individuals of European ancestry. Please note when running PRSice that the object of the flag \"--prsice\" will change according to whether plink is being called within the linux-like environment of the virtual machine (PRSice_linux) or a mac (PRSice_mac). Both executables can be found in the /home/manager/data/Data_Day4 directory.","title":"5. Background to PRS-CSX"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#6-extraction-of-snps","text":"PRS-CSx uses only HAPMAP3 SNPs therefore we produce a set of plink files containing this SNP subset. ./software/plink_linux --bfile ./data/1kg.eur.dbSNP153.hg38 --extract ./data/csxsnp --make-bed --out ./data/EUR_1kg.hm3.only.csx ./software/plink_linux --bfile ./data/1kg.afr.dbSNP153.hg38 --extract ./data/csxsnp --make-bed --out ./data/AFR_1kg.hm3.only.csx","title":"6. Extraction of SNPs"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#7-running-prs-csx","text":"To model the coupling of effect sizes at individual SNPs across ancestries PRS-CSx uses an MCMC (Bayesian) sampling algorithm to determine values of the global shrinkage parameter (\"phi\") by Maximum likelihood. For samples of mixed or admixed genetic ancestry (which ours are not) the optimal value of the shrinkage parameter is estimated autonomously from the data. Here we use the value of phi (1e-4), which is suggested by the software authors, given that our trait is simulated to have a relatively small number (N=110) causal variants, distributed genome-wide. To save time, we will be running the analyses across chromosome 15, rather than the entire genome. The commands needed to run PRS-CSx are contained in two script files, located in /home/manager/data/Data_Day4/scripts. The file run_prscsx_afr-target.sh is used to estimate optimal SNP weights for predicting into the African target population. NB - move the snp file to the reference folder cp /home/manager/PRScsx/snpinfo_mult_1kg_hm3 /home/manager/data/Data_Day4/reference/csx NB - the ld block files must be moved to /home/manager/data/Data_Day4/reference/csx to /home/manager/PRScsx/ mv /home/manager/PRScsx/*.tar.gz /home/manager/PRScsx/ then extracted with tar tar -xvfz ld...tar.gz be careful of space, your vm has 100GB cap. remove the .gz files once extracted Script contents : python /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir = /home/manager/data/Data_Day4/reference/csx \\ --bim_prefix = /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --sst_file = /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx,/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --n_gwas =25732 ,4855 \\ --pop = EUR,AFR \\ --chrom =15 \\ --phi = 1e-4 \\ --out_dir = /home/manager/data/Data_Day4/out/csx \\ --out_name = afr.target.csx The file run_prscsx_eur-target.sh is used to estimate optimal SNP weights for predicting into the European target population: Script contents : python /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir = /home/manager/data/Data_Day4/reference/csx \\ --bim_prefix = /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --sst_file = /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx,/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --n_gwas =25732 ,4855 \\ --pop = EUR,AFR \\ --chrom =15 \\ --phi = 1e-4 \\ --out_dir = /home/manager/data/Data_Day4/out/csx \\ --out_name = eur.target.csx Prior to running each script you will need to update the first line with a reference (i.e the pathname) to your home directory. From /home/manager/data/Data_Day4 the scripts can then be run as follows: ./scripts/run_prscsx_afr-target.sh ./scripts/run_prscsx_eur-target.sh","title":"7. Running PRS-CSx"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#questions_3","text":"","title":"Questions"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#i-how-many-results-files-do-you-see-in-the-output-directory","text":"","title":"(i) How many results files do you see in the output directory?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#ii-what-does-each-file-correspond-to","text":"","title":"(ii) What does each file correspond to?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#ii-in-which-column-are-the-adjusted-snp-weights-contained","text":"","title":"(ii) In which column are the adjusted SNP weights contained?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#8-processing","text":"The next step would be to collate adjusted SNP weight information from multiple chromosomes and relabel the consolidated files for clarity. The following code works regardless of whether the preceding PRS-CSx analysis was performed for single or multiple chromosomes. In /home/manager/data/Data_Day4/out/csx for file in afr.target.csx_AFR_*; do cat $file >> posteriors.afr.by.afr done for file in afr.target.csx_EUR_*; do cat $file >> posteriors.afr.by.eur done for file in eur.target.csx_AFR_*; do cat $file >> posteriors.eur.by.afr done for file in eur.target.csx_EUR_*; do cat $file >> posteriors.eur.by.eur done","title":"8. Processing"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#9-data-processing-in-r","text":"The next stage of data processing, done in R will create a new set of summary statistics files, containing the adjusting SNP weights from PRS-CSx. Staying in /home/manager/data/Data_Day4/out/csx : R # Load posteriors effect sizes from PRS-CSx output afr.afr<-read.table ( \"posteriors.afr.by.afr\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.afr.afr\" )) afr.by.eur<-read.table ( \"posteriors.afr.by.eur\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.afr.by.eur\" )) eur.eur<-read.table ( \"posteriors.eur.by.eur\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.eur.eur\" )) eur.by.afr<-read.table ( \"posteriors.eur.by.afr\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.eur.by.afr\" )) # Load original summary statistics afr.SBP<-read.table ( \"/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx\" , header = T ) eur.SBP<-read.table ( \"/home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx\" , header = T ) # Combine the posterior derived weights and summary statistics eur.SBP.merge1<-merge ( x = eur.SBP, y = eur.eur [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) eur.SBP.merge<-merge ( x = eur.SBP.merge1, y = afr.by.eur [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) afr.SBP.merge1<-merge ( x = afr.SBP, y = afr.afr [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) afr.SBP.merge<-merge ( x = afr.SBP.merge1, y = eur.by.afr [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) # Save files write.table ( afr.SBP.merge, \"/home/manager/data/Data_Day4/afr.SBP.posterior.sumstats\" , quote = F, row.names = F ) write.table ( eur.SBP.merge, \"/home/manager/data/Data_Day4/eur.SBP.posterior.sumstats\" , quote = F, row.names = F ) q ()","title":"9. Data processing in R"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#10-use-prsice-to-apply-the-adjusted-snp-effects-to-target-phenotypes","text":"We first need to create a list of SNPs to be used as input, based on the previous PRS-CSx analysis. This is done in location /home/manager/data/Data_Day4 . awk 'NR>1 {print $1}' afr.SBP.posterior.sumstats > snps.afr.posterior awk 'NR>1 {print $1}' eur.SBP.posterior.sumstats > snps.eur.posterior The next series of commands implement in-ancestry and cross-ancestry prediction of the systolic blood pressure phenotype using the PRS-CSx optimised SNP weights. Do not forget to exchange PRSice_linux for PRSice_mac if running the commands in a Mac environment. The phenotypic files sbp_afr_1kg.sim_pheno and sbp_eur_1kg.sim_pheno contain data on systolic blood pressure with simulated heritabilities that vary from 10%, 20%, 33%, 50% and 100%. To compensate for the fact that the adjusted weights generated are based on chromosome 15, rather than the entire genome, we will be using the 100% trait version (pheno100) for this analysis.","title":"10. Use PRSice to apply the adjusted SNP effects to target phenotypes"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#11-predicting-from-african-training-to-african-target-data","text":"Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/afr.sbp.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.afr.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.afr.afr \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.afr","title":"11. Predicting from African training to African target data"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#12-predicting-from-european-training-to-african-target-data","text":"Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/eur.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.eur.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.afr.by.eur \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.by.eur","title":"12. Predicting from European training to African target data"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#13-predicting-from-european-training-to-european-target-data","text":"Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/eur.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.eur.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.eur.eur \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.eur","title":"13. Predicting from European training to European target data"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#14-predicting-from-african-training-to-european-target-data","text":"Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/afr.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.afr.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.eur.by.afr \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.by.afr","title":"14. Predicting from African training to European target data"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#15-create-summary-files","text":"From location /home/manager/data/Data_Day4/out/prscsx_prsice awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.afr.afr.summary > quicksum.afr-afr awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.afr.by.eur.summary > quicksum.afr-by-eur awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.eur.by.afr.summary > quicksum.eur-by-afr awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.eur.eur.summary > quicksum.eur-eur","title":"15. Create summary files"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#questions_4","text":"","title":"Questions"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#i-what-information-is-being-summarized-in-the-output-files","text":"","title":"(i) What information is being summarized in the output files??"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#ii-for-each-prediction-model-what-is-the-r2-and-value","text":"","title":"(ii) For each prediction model what is the R2 and  value???"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#16-complete-the-remaining-prs-analysis-in-r","text":"","title":"16. Complete the remaining PRS analysis in R"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#step-1-load-and-prepare-data","text":"R # Load libraries sudo apt install cmake install.packages ( \"AICcmodavg\" ) install.packages ( \"fmsb\" ) library ( AICcmodavg ) library ( fmsb ) afr.afr<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.afr.best\" , header = T ) afr.eur<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.by.eur.best\" , header = T ) eur.eur<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.eur.best\" , header = T ) eur.afr<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.by.afr.best\" , header = T ) colnames ( afr.afr )[4] <- \"afr.afr\" # african prediction using african PRS colnames ( afr.eur )[4] <- \"afr.eur\" # african prediction using european PRS colnames ( eur.eur )[4] <- \"eur.eur\" # european prediction using european PRS colnames ( eur.afr )[4] <- \"eur.afr\" # european prediction using african PRS # Merge PRSs according to target ancestry and source population combined.afr<-merge ( x = afr.afr, y = afr.eur [ c (2 ,4 )] , by = \"IID\" , all.x = T ) combined.eur<-merge ( x = eur.eur, y = eur.afr [ c (2 ,4 )] , by = \"IID\" , all.x = T ) # Rescale scores to have mean = \u20180\u2019 and standard deviation = \u20181\u2019 combined.afr [4 :5 ] <- as.data.frame ( scale ( combined.afr [4 :5 ])) combined.eur [4 :5 ] <- as.data.frame ( scale ( combined.eur [4 :5 ])) # Load phenotype data sbp.eur<-read.table ( \"/home/manager/data/Data_Day4/data/SBP_eur_1kg.sim_pheno\" , header = T ) sbp.afr<-read.table ( \"/home/manager/data/Data_Day4/data/SBP_afr_1kg.sim_pheno\" , header = T ) # Merge phenotypes and PRS combined.eur.pheno<-merge ( x = combined.eur [ -c (2 ,3 )] , y = sbp.eur [ ,c (2 ,3 )] , by = \"IID\" , all.x = T ) combined.afr.pheno<-merge ( x = combined.afr [ -c (2 ,3 )] , y = sbp.afr [ ,c (2 ,3 )] , by = \"IID\" , all.x = T )","title":"Step 1: Load and prepare data"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#step-2-model-selection-using-akaikes-information-criterion","text":"In the final step we want to determine whether the use of the multi-ancestry PRS formulation generated by PRS-CSx performs better at predicting systolic blood pressure, compared to the single-ancestry PRS formulation. To do this we use (AIC Akaike\u2019s Information Criterion). AIC is used to assess the performance of a competing set of regression models. We use it to compare the performance of models that contain different numbers of predictors, given that R2 is inflated by the inclusion of redundant terms in a model.","title":"Step 2: Model selection using Akaike\u2019s Information Criterion"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#16b-model-evaluation","text":"# EUROPEAN model1.eur <- glm ( pheno100 ~ eur.eur, data = combined.eur.pheno, family = gaussian ) model2.eur <- glm ( pheno100 ~ eur.afr, data = combined.eur.pheno, family = gaussian ) model3.eur <- glm ( pheno100 ~ eur.eur + eur.afr, data = combined.eur.pheno, family = gaussian ) models.eur <- list ( model1.eur, model2.eur, model3.eur ) # define model set mod.names.eur <- c ( 'eur.eur' , 'eur.afr' , 'eur.combined' ) # add model names aictab ( cand.set = models.eur, modnames = mod.names.eur ) # calculate model AICs model # AFRICAN model1.afr <- glm ( pheno100 ~ afr.afr, data = combined.afr.pheno, family = gaussian ) model2.afr <- glm ( pheno100 ~ afr.eur, data = combined.afr.pheno, family = gaussian ) model3.afr <- glm ( pheno100 ~ afr.afr + afr.eur, data = combined.afr.pheno, family = gaussian ) models.afr <- list ( model1.afr, model2.afr, model3.afr ) # define model set mod.names.afr <- c ( 'afr.afr' , 'afr.eur' , 'afr.combined' ) # add model names aictab ( cand.set = models.afr, modnames = mod.names.afr ) # calculate model AICs # NagelkerkeR2 calculations in R # African target NagelkerkeR2 ( model1.afr ) NagelkerkeR2 ( model2.afr ) NagelkerkeR2 ( model3.afr ) # European target NagelkerkeR2 ( model1.eur ) NagelkerkeR2 ( model2.eur ) NagelkerkeR2 ( model3.eur ) For each ancestry which predictive model performs best and worst? Does combining the two sets of adjusted scores perform consistently better than modelling each one separately?","title":"16b. Model evaluation"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#questions_5","text":"","title":"Questions"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#i-for-each-ancestry-which-model-performs-best-and-which-performs-worst","text":"","title":"(i) For each ancestry which model performs best and which performs worst?"},{"location":"tmp/prs_2023-main/modules/Day4.docx/#ii-does-linearly-combining-adjusted-scores-european-plus-african-always-result-in-better-performance-compared-to-single-ancestry-prediction","text":"","title":"(ii) Does linearly combining adjusted scores (European plus African) always result in better performance compared to single-ancestry prediction?"},{"location":"tmp/prs_2023-main/modules/Day5_Projects/","text":"Multi-Ancestry Trait Prediction - an extension of the work on Thursday Task \u2013 PRS calculation in multiple populations [3.5 hrs] Thursday\u2019s practical will focus on getting you up and running with some of the leading software tools for performing PRS calculation across ancestries. * Then we will allow you to adapt the scripts that we will provide you with, in order to complete the practical that we will set for you. * You\u2019ll be doing the practical in the groups that you were assigned to at the beginning of the week and at the end of the practical (on Friday) each group will give a presentation about your work and your findings * For the project there will be a total of 5 populations to choose from, namely East Asian, European, South Asian, Amerindian, African (EAS, EUR, SAS, AMR and AFR). Each group will choose a combination of two populations, which have been simulated to have the same genetic architecture but with a different LD structure and allele frequencies. * Using the methods you will learn during the day 4 practical (and potentially other skills learned throughout this week) you will evaluate the performance of at least one of the multi-ancestry methods you will learn about tomorrow and compare this against the performance of PRSice, (a tool which hasn\u2019t been designed for multi-ancestry purposes).","title":"Multi-Ancestry Trait Prediction -  an extension of the work on Thursday"},{"location":"tmp/prs_2023-main/modules/Day5_Projects/#multi-ancestry-trait-prediction-an-extension-of-the-work-on-thursday","text":"","title":"Multi-Ancestry Trait Prediction -  an extension of the work on Thursday"},{"location":"tmp/prs_2023-main/modules/Day5_Projects/#task-prs-calculation-in-multiple-populations-35-hrs","text":"Thursday\u2019s practical will focus on getting you up and running with some of the leading software tools for performing PRS calculation across ancestries. * Then we will allow you to adapt the scripts that we will provide you with, in order to complete the practical that we will set for you. * You\u2019ll be doing the practical in the groups that you were assigned to at the beginning of the week and at the end of the practical (on Friday) each group will give a presentation about your work and your findings * For the project there will be a total of 5 populations to choose from, namely East Asian, European, South Asian, Amerindian, African (EAS, EUR, SAS, AMR and AFR). Each group will choose a combination of two populations, which have been simulated to have the same genetic architecture but with a different LD structure and allele frequencies. * Using the methods you will learn during the day 4 practical (and potentially other skills learned throughout this week) you will evaluate the performance of at least one of the multi-ancestry methods you will learn about tomorrow and compare this against the performance of PRSice, (a tool which hasn\u2019t been designed for multi-ancestry purposes).","title":"Task \u2013 PRS calculation in multiple populations [3.5 hrs]"},{"location":"tmp/prs_2023-main/modules/READme/","text":"Module directory Directory for placing the course module files - these should be markdown or PDF documents They include the presentations and practical manuals for the module. Converting between markdown to PDF can be performed using pandoc. Here is a tutorial and system for that: Converting with Pandoc There is an example markdown file - module_base.md","title":"Module directory"},{"location":"tmp/prs_2023-main/modules/READme/#module-directory","text":"Directory for placing the course module files - these should be markdown or PDF documents They include the presentations and practical manuals for the module. Converting between markdown to PDF can be performed using pandoc. Here is a tutorial and system for that: Converting with Pandoc There is an example markdown file - module_base.md","title":"Module directory"},{"location":"tmp/prs_2023-main/modules/module_base/","text":"This is a base file to modify with your module content Please rename this md file to suit your module Markdown guide is available https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax Example git https://github.com/WCSCourses/WWPG_2022/blob/main/manuals/module_linux_scripting/module_linux_scripting.md","title":"This is a base file to modify with your module content"},{"location":"tmp/prs_2023-main/modules/module_base/#this-is-a-base-file-to-modify-with-your-module-content","text":"","title":"This is a base file to modify with your module content"},{"location":"tmp/prs_2023-main/modules/module_base/#please-rename-this-md-file-to-suit-your-module","text":"","title":"Please rename this md file to suit your module"},{"location":"tmp/prs_2023-main/modules/module_base/#markdown-guide-is-available","text":"https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax","title":"Markdown guide is available"},{"location":"tmp/prs_2023-main/modules/module_base/#example-git","text":"https://github.com/WCSCourses/WWPG_2022/blob/main/manuals/module_linux_scripting/module_linux_scripting.md","title":"Example git"},{"location":"tmp/prs_2023-main/scripts/base/","text":"scripts base","title":"Base"},{"location":"tmp2/workshop_practical_paul.docx/","text":"Introduction to Polygenic Risk Scores Table of Contents Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Data Structure You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this command - cd ~/Downloads wget https://wcs_data_transfer.cog.sanger.ac.uk/Day2_Base_Data.zip You may also download it via dropbox if the above fails with this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice_linux/PRSice Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary. Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres \u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status. Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis. Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top Introduction to Polygenic Risk Scores Table of Contents Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Data Structure You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2),the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice/PRSice_linux -h Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary. Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres \u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status. Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis. Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp2/workshop_practical_paul.docx/#introduction-to-polygenic-risk-scores","text":"","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp2/workshop_practical_paul.docx/#table-of-contents","text":"Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents","title":"Table of Contents"},{"location":"tmp2/workshop_practical_paul.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp2/workshop_practical_paul.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp2/workshop_practical_paul.docx/#data-structure","text":"You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this command - cd ~/Downloads wget https://wcs_data_transfer.cog.sanger.ac.uk/Day2_Base_Data.zip You may also download it via dropbox if the above fails with this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents","title":"Data Structure"},{"location":"tmp2/workshop_practical_paul.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp2/workshop_practical_paul.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents","title":"Understanding GWAS Summary Statistics"},{"location":"tmp2/workshop_practical_paul.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents","title":"Matching the Base and Target Data sets"},{"location":"tmp2/workshop_practical_paul.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp2/workshop_practical_paul.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents","title":"Performing Clumping"},{"location":"tmp2/workshop_practical_paul.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds.","title":"P-Value Thresholding"},{"location":"tmp2/workshop_practical_paul.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice_linux/PRSice Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp2/workshop_practical_paul.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp2/workshop_practical_paul.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents","title":"High Resolution Scoring"},{"location":"tmp2/workshop_practical_paul.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents","title":"Stratifying Samples by PRS"},{"location":"tmp2/workshop_practical_paul.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary.","title":"Case Control Studies"},{"location":"tmp2/workshop_practical_paul.docx/#rscript-prsice_linuxprsicer-prsice-prsice_linuxprsice_linux-base-base_datacadaddtxt-target-target_datatar-snp-markername-a1-effect_allele-a2-noneffect_allele-chr-chr-bp-bp_hg19-stat-beta-beta-pvalue-p_dgc-pheno-target_datacadpheno-binary-target-t-out-resultscadhighres","text":"\u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status.","title":"Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres\n"},{"location":"tmp2/workshop_practical_paul.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis.","title":"Cross-Trait Analysis"},{"location":"tmp2/workshop_practical_paul.docx/#rscript-prsice_linuxprsicer-prsice-prsice_linuxprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datacadpheno-binary-target-t-out-resultscrosshighres","text":"Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres\n"},{"location":"tmp2/workshop_practical_paul.docx/#introduction-to-polygenic-risk-scores_1","text":"","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp2/workshop_practical_paul.docx/#table-of-contents_1","text":"Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents","title":"Table of Contents"},{"location":"tmp2/workshop_practical_paul.docx/#key-learning-outcomes_1","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp2/workshop_practical_paul.docx/#resources-you-will-be-using_1","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp2/workshop_practical_paul.docx/#data-structure_1","text":"You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents","title":"Data Structure"},{"location":"tmp2/workshop_practical_paul.docx/#introduction_1","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp2/workshop_practical_paul.docx/#understanding-gwas-summary-statistics_1","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents","title":"Understanding GWAS Summary Statistics"},{"location":"tmp2/workshop_practical_paul.docx/#matching-the-base-and-target-data-sets_1","text":"The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents","title":"Matching the Base and Target Data sets"},{"location":"tmp2/workshop_practical_paul.docx/#linkage-disequilibrium-in-prs-analyses_1","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp2/workshop_practical_paul.docx/#performing-clumping_1","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents","title":"Performing Clumping"},{"location":"tmp2/workshop_practical_paul.docx/#p-value-thresholding_1","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds.","title":"P-Value Thresholding"},{"location":"tmp2/workshop_practical_paul.docx/#height-prs-using-gw-significant-snps-only_1","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2),the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice/PRSice_linux -h Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp2/workshop_practical_paul.docx/#height-prs-across-multiple-p-value-thresholds_1","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp2/workshop_practical_paul.docx/#high-resolution-scoring_1","text":"If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents","title":"High Resolution Scoring"},{"location":"tmp2/workshop_practical_paul.docx/#stratifying-samples-by-prs_1","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents","title":"Stratifying Samples by PRS"},{"location":"tmp2/workshop_practical_paul.docx/#case-control-studies_1","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary.","title":"Case Control Studies"},{"location":"tmp2/workshop_practical_paul.docx/#rscript-prsiceprsicer-prsice-prsiceprsice_linux-base-base_datacadaddtxt-target-target_datatar-snp-markername-a1-effect_allele-a2-noneffect_allele-chr-chr-bp-bp_hg19-stat-beta-beta-pvalue-p_dgc-pheno-target_datacadpheno-binary-target-t-out-resultscadhighres","text":"\u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status.","title":"Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres\n"},{"location":"tmp2/workshop_practical_paul.docx/#cross-trait-analysis_1","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis.","title":"Cross-Trait Analysis"},{"location":"tmp2/workshop_practical_paul.docx/#rscript-prsiceprsicer-prsice-prsiceprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datacadpheno-binary-target-t-out-resultscrosshighres","text":"Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres\n"},{"location":"tmp2/workshop_practical_tade/","text":"Population Genetics And Ancestry Analysis Table of Contents Key Learning Outcomes Practical Data A Portability Problem Population Genetics Basics Dimensional Reduction: PCA Key Learning Outcomes After completing this practical, you should be able to: Run mixed ancestry PRS and understand the PRS Portability Problem Understand principle component analysis and dimensional reduction Understand basic population genetics and know how to analyze ancestry groups. Understand the challenges and limitations of applying PRS in populations with diverse genetic backgrounds. Practical Specific Data The multi-ancestry data/software required for this practical can be downloaded here. Please download, unzip the data, and move it into a suitable directory on your laptop. After doing this you should see the following directories: exercise1: Data/Code to run multi-ancestry PRS exercise2: Data/Code for principal component analysis exercise3: Data/Code for population genetics analysis Ex 1: Portability Problem The first exercise of this practical takes place in the folder exercise1 . Once inside the folder you should see code and data directories. Looking in the data directory by typing the following command will reveal: ls data/* \ud83c\uddea\ud83c\uddfa: EURO_GWAS.assoc (European Ancestry GWAS Sumstats) \ud83c\uddec\ud83c\udde7: data/ukTarget (Genotype Phenotype data From a population from the UK.) \ud83c\uddef\ud83c\uddf5: data/japanTarget (Genotype Phenotype data from a population from Japan.) To start, run PRSice using the European GWAS and target data from the UK: ./code/PRSice --base data/EURO_GWAS.assoc --target data/ukTarget/ukTarget --binary-target F --out ukRun Verify that this command produce a file called \"ukRun.best\" that contains individual prs-scores in fourth column. This file can compared to the file data/ukTarget/ukTarget.pheno which contains phenotype-values in the third column. \ud83d\udea8 OPTIONAL-CHALLENGE \ud83d\udea8 Using R, Python, or another program, consider calculating the correlation between the PRS and phenotype data in the two files? First read the pseudocode and see if you can follow the strategy. Then give it a try or read the following solutions and make sure that you understand them. Notice the differences in similarities in the programming languages. Hints #1) Step1: Read Both Files in. prs_data = read('ukRun.best') pheno_data = read(\"data/ukTarget/ukTarget.pheno\") #2) Step2: Extract the correct Column from each file . prs_vals = extract_from(prs_data, column 4) pheno_vals = extract_from(pheno_data, column 3) #3) Step3: Calculate the correlation. R2 = calculate_R2_from_data(prs_vals, pheno_vals) Solution (R) R # read-in prs-file prs <- read.table(\"ukRun.best\", header = TRUE, sep = \"\", stringsAsFactors = FALSE) prs.data <- prs1[,4] # read-in pheno-file pheno <- read.table(\"data/ukTarget/ukTarget.pheno\", header = TRUE, sep = \"\", stringsAsFactors = FALSE) pheno.data <- pheno[,3] # Create DataFrame combined_data <- data.frame( x = prs.data, y = pheno.data) # Fit a linear model to the data model <- lm(y ~ x, data = combined_data) # Calculate the R-squared value r_squared <- summary(model)$r.squared # return R2 print(r_squared) Solution (Python) python3 # read-in prs-file: with open('ukRun.best') as F: prs_vals = [float(line.split()[-1]) for i,line in enumerate(F.readlines()) if i > 0] # read-in pheno-file: with open('data/ukTarget/ukTarget.pheno') as F: pheno_vals = [float(line.split()[-1]) for i,line in enumerate(F.readlines()) if i > 0] # calculate correlation prs_mean, pheno_mean = sum(prs_vals)/len(prs_vals), sum(pheno_vals)/len(pheno_vals) rTop = sum([(x-prs_mean)*(y-pheno_mean) for x,y in zip(prs_vals, pheno_vals)]) rBottom = (sum([(x-prs_mean)*(x-prs_mean) for x in prs_vals])**0.5) * (sum([(x-pheno_mean)*(x-pheno_mean) for x in pheno_vals])**0.5) # Return R2 R2 = (rTop/rBottom)*(rTop/rBottom) print(R2) After you feel confident about the code, please run the Rscript in the code directory to calculate the correlation and create a scatterplot using the UK PRS-result: Rscript --vanilla code/plot_prs_results.R data/ukTarget/ukTarget.pheno ukRun.best This will create a scatterplot file called: ukRunScatterplot.pdf . Verify that you can view it, and then type the commands below to reuse the European GWAS data and PRSice with the genotype-phenotype data from a Japan. After viewing the resulting scatterplot please answer the questions below. ./code/PRSice --base data/EURO_GWAS.assoc --target data/japanTarget/japanTarget --binary-target F --out japanRun Rscript --vanilla code/plot_prs_results.R data/japanTarget/japanTarget.pheno japanRun.best \u2753QUESTIONS: In the UK-result, what percent of variance in phenotype is explained by prs? Approximately 10%. In the Japan-result, what percent of variance in phenotype is explained by prs? Approximately 0%. Besides a difference in variance explained, do you notice any other differences? Less variance in PRS, a shift to the left. What is the name of the problem that refers to this drop in performance? The PRS Portability problem. What are some causes of the problem? 1. Differences in LD. 2. Differences in allele frequency. 3. Differences in environment. 4. Differences in population-structure. Back to Top 1000 Genomes Data Now that you have observed the PRS-portability problem in practice we are going to consider some analysis that can be used to provide a solution. Recall from the lecture that population structure and population assignment is often accomplished using principal components analysis (PCA) and that the primary population differences that drive the portability problem are difference in allele frequency and linkage disequilibrium. In the next exercise we will learn how to analyze and compare data from different populations and quantify linkage disequilibrium. In the final exercise we what PCA is and learn how it can be used to separate population data by recent ancestry. Both of these exercises use the 1000Genomes dataset which contains individuals from 26 different source populations from all five continents. Back to Top Ex 2: Population Genetics This exercise of this practical takes place in the folder exercise2 . Once inside the folder you should see code and data directories. Looking in the data directory by typing the following command will reveal: ls data/* \ud83c\udf0e: chr1-22.bed/bim/fam (Global Genotype Data) \ud83c\udff7\ufe0f: data/pop_info.pheno (Population specific annotation data) \ud83d\udcab: data/all_phase3.king.psam (Axillary Phase Data) Sample Sizes The first thing we would like to find out about this data is the number of individuals within each global superpopulation. Type the following command to query the number of European ancestry individuals in the downloaded dataset: grep -F \"EUR\" data/all_phase3.king.psam | wc -l Next, repeat the same command for East Asian, African, South Asian and Amerindian superpopulations, by inserting the relevant ancestry codes (EAS, AFR, SAS, AMR). \ud83d\uddd2\ufe0f Make note of how many individuals from each ancestry group are available. Number of Genetic Variants We do not need to use the full genome-wide data for this tutorial, only a small fraction of the 80 million total available variants. This provides a reliable approximation for the genomic analyses in this tutorial and importantly, reduces the computation time required to complete the tutorial. The following command derives the number of genetic variants on chromosomes 1 to chromosome 22 by counting the number of lines in the relevant (.bim) file, which contains a single variant per line. wc data/chr1-22.bim -l To quantify the number of single nucleotide polymorphisms (SNPs) we can ask plink to write a list of SNPs: ./code/plink --bfile data/chr1-22 --snps-only --write-snplist See the output file plink.snplist, which contains a list of all the SNPs in the dataset. Quantification of variable SNPs The rate at which a genetic variant occurs in a population is also known as its allelic frequency. Allele frequencies are shaped by evolutionary forces over a long period of time and hence can vary. This has implications for PRS research as the allelic frequency distribution of a disease or trait may vary between populations. It is possible to generate allele frequency statistics for each SNP in a given population, using the population information in the file pop_info.pheno. ./code/plink --bfile data/chr1-22 --snps-only --freq --within data/pop_info.pheno Population-stratified allele frequency results can be found in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: grep -F \"AFR\" plink.frq.strat | wc -l Compare the totals against number of SNPs which have minor allele frequencies greater than 0 (and hence are useful for statistical analysis). Do this for all 5 populations (EAS, EUR, SAS, EUR and AFR), using the code given below: grep -F \"AFR\" plink.frq.strat > freq_report.afr grep -F \"AMR\" plink.frq.strat > freq_report.amr grep -F \"EUR\" plink.frq.strat > freq_report.eur grep -F \"EAS\" plink.frq.strat > freq_report.eas grep -F \"SAS\" plink.frq.strat > freq_report.sas grep -F \"AFR\" plink.frq.strat | awk '$6 >0' freq_report.afr | wc -l grep -F \"EUR\" plink.frq.strat | awk '$6 >0' freq_report.eur | wc -l grep -F \"EAS\" plink.frq.strat | awk '$6 >0' freq_report.eas | wc -l grep -F \"AMR\" plink.frq.strat | awk '$6 >0' freq_report.amr | wc -l grep -F \"SAS\" plink.frq.strat | awk '$6 >0' freq_report.sas | wc -l Having compared the number of SNPs that show variation in each population, answer the following questions: \u2753QUESTIONS: Which populations have the largest number (density) of SNPs that can be considered polymorphic? AFR and AMR. What do you think is the significance of the observed population order? Human evolution and migration. Investigation Missingness Genotype missingness, caused by genotyping failure can potentially lead to biased allele frequency estimation. Therefore missingness needs to be excluded as a possible source of bias when calculating allele frequency differences. ./code/plink --bfile data/chr1-22 --missing --within data/pop_info.pheno The output file plink.lmiss provides a variant-based missing data report). Use the following code to query the number of genotyping failures based on the missingness information in the NMISS column: awk '$4 > 0' plink.lmiss | wc -l Cross Population Allele Frequency Comparisons Here we compare profiles of allele frequency across the five ancestral populations. To do this we will use the previously-generated output on minor allele frequencies per ancestry group (the file \"plink.frq.strat\"), using R: R-Code: Compare Allele Frequencies library(dplyr) library(ggplot2) freq <-read.table(\"plink.frq.strat\", header =T) plotDat <- freq %>% mutate(AlleleFrequency = cut(MAF, seq(0, 1, 0.25))) %>% group_by(AlleleFrequency, CLST) %>% summarise(FractionOfSNPs = n()/nrow(freq) * 100) ggplot(na.omit(plotDat),aes(AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST)) + geom_line() + scale_y_continuous(limits = c(0, 12)) + ggtitle(\"Distribution of allele frequency across genome\") \u2753QUESTIONS: How are the allele frequencies in AFR distinguishable from the other global reference groups? Greater diversity. Linkage disequilibrium versus genomic distance, across populations We will now perform pairwise LD comparisons between genome-wide snps in order to show cross-populations relationships between genomic distance and LD strength. We derive information on pairwise R2 between all SNPs: ./code/plink --bfile data/chr1-22 --keep-cluster-names AFR --within data/pop_info.pheno --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 2500 --threads 30 --out chr1-22.AFR Repeat this step for all five 1000Genomes populations. Output files containing LD info for all pairwise SNPs, have a \u2018.ld\u2019 su\ufb03x Next, create a summary file containing the base-pair distance between each pair and the corresponding r2 value. The following example shows this for AFR and EUR populations only, as just these populations will be used in the plot. cat chr1-22.AFR.ld | sed 1,1d | awk -F \" \" 'function abs(v) {return v < 0 ? -v : v}BEGIN{OFS=\"\\t\"}{print abs($5-$2),$7}' | sort -k1,1n > chr1-22.AFR.ld.summary cat chr1-22.EUR.ld | sed 1,1d | awk -F \" \" 'function abs(v) {return v < 0 ? -v : v}BEGIN{OFS=\"\\t\"}{print abs($5-$2),$7}' | sort -k1,1n > chr1-22.EUR.ld.summary LD decay versus chromosomal distance To visualise LD behaviour as a function of chromosomal distance we can carry out the following commands from within an R terminal: R-Code: Visualize LD Behavior # need to add additional functionality to be able to # carry out the necessary data transformation (dplyr) # and manipulation of character strings (stringr ) install.packages(\"dplyr\") install.packages(\"stringr\") install.packages(\"ggplot2\") library(dplyr) library(stringr) library(ggplot2) # Next we will (1) load the previously generated information on pairwise LD, # Categorize distances into intervals of fixed length (100KB), # Compute mean and median r2 within blocks # Obrain mid-points for each distance interval dfr<-read.delim(\"chr1-22.AFR.ld.summary\",sep=\"\",header=F,check.names=F, stringsAsFactors=F) colnames(dfr)<-c(\"dist\",\"rsq\") dfr$distc<-cut(dfr$dist,breaks=seq(from=min(dfr$dist)-1,to=max(dfr$dist)+1,by=100000)) dfr1<-dfr %>% group_by(distc) %>% summarise(mean=mean(rsq),median=median(rsq)) dfr1 <- dfr1 %>% mutate(start=as.integer(str_extract(str_replace_all(distc,\"[\\\\(\\\\)\\\\[\\\\]]\",\"\"),\"^[0-9-e+.]+\")), end=as.integer(str_extract(str_replace_all(distc,\"[\\\\(\\\\)\\\\[\\\\]]\",\"\"),\"[0-9-e+.]+$\")), mid=start+((end-start)/2)) # The preceding code block should be repeated for the file chr1-22._EUR.ld.summary. # When doing so, the output object dfr1 on lines 4 and 5 should be renamed dfr2 to prevent the object df1 being over-written. # Finally, we can plot LD decay for AFR and EUR reference populations in a single graph: ggplot()+ geom_point(data=dfr1,aes(x=start,y=mean),size=0.4,colour=\"grey20\")+ geom_line(data=dfr1,aes(x=start,y=mean),size=0.3,alpha=0.5,colour=\"grey40\")+ labs(x=\"Distance (Megabases)\",y=expression(LD~(r^{2})))+ scale_x_continuous(breaks=c(0,2*10^6,4*10^6,6*10^6,8*10^6),labels=c(\"0\",\"2\",\"4\",\"6\",\"8\"))+ theme_bw() \u2753QUESTIONS: What differences do you observe in terms of LD decay between AFR and EUR genomes? Greater decay in AFR How is this likely to impact the transferability of PRS performance between the two populations? Negatively. Distribution of LD-block length The next set of scripts will allow us to visualise the distribution of LD block length across different 1000Genomes populations. ./code/plink --bfile chr1-22 --keep-cluster-names AFR --blocks no-pheno-req no-small-max-span --blocks-max-kb 250 --within data/pop_info.pheno --threads 30 --out AFR The \u201c\u2013block\" flag estimates haplotype blocks using the same block definition implemented by the software Haploview. The default setting for the flag --blocks-max-kb only considers pairs of variants that are within 200 kilobases of each other. The output file from the above command is a .blocks file. Use the same code to generate output for EUR, EAS, SAS and AMR populations (as it is not possible to generate population-specific information using the --within flag). Then, in R: R-Code: Load each of the 5 datasets and set column names to lower case. dfr.afr <- read.delim(\"AFR.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.afr) <- tolower(colnames(dfr.afr)) dfr.eur <- read.delim(\"EUR.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.eur) <- tolower(colnames(dfr.eur)) dfr.amr <- read.delim(\"AMR.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.amr) <- tolower(colnames(dfr.amr)) dfr.sas <- read.delim(\"SAS.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.sas) <- tolower(colnames(dfr.sas)) dfr.eas <- read.delim(\"EAS.blocks.det\",sep=\"\",header=T,check.names=F,stringsAsFactors=F) colnames(dfr.eas) <- tolower(colnames(dfr.eas)) Then plot the data: plot (density(dfr.afr$kb), main=\"LD block length distribution\", ylab=\"Density\",xlab=\"LD block length (Kb)\" ) lines (density(dfr.eur$kb), col=\"blue\") lines (density(dfr.eas$kb), col=\"red\") lines (density(dfr.amr$kb), col=\"purple\") lines (density(dfr.sas$kb), col=\"green\") legend(\"topright\",c(\"AFR\",\"EAS\",\"EUR\",\"SAS\",\"AMR\"), fill=c(\"black\",\"red\",\"blue\",\"green\",\"purple\")) \u2753QUESTIONS: What are the main features of this plot? How do you interpret them? Open ended Back to Top Ex 3: PCA Principle Component Analysis is a useful technique that allows researchers to visualize high dimensional data in lower space by rotating the axes in such a way that the lower dimensions (or components) maximize the total variance explained. In statistical genetics this involves \"rotating\" million-dimensional data - something that is very hard to visualize! For this reason, we begin with a simpler exercise. For the following three two dimensional shapes, spend some time identifying the principle components or sketching the line across for which variance is maximized. Check your answers below: \u2753QUESTIONS: What line represents the principle component for the first shape? The line 4/3(x) + y What line represents the principle component for the second shape? The line x+y. What line represents the principle component for the third shape? The X and Y axis already maximize the variance. Below you can view the shapes in principal component space. Now that we understand how PCA works in two dimensions we will consider a higher dimensional example. In the three dimensional space below, see if you can visualize a plane that maximizes the variance across two dimensions: Did you get it right? If so, realize that this is equivalent to what we do in genetics - we find rotate the data through millions of dimensions of space to find the plane that maximizes the variance in two dimensions: To run PCA with real data please enter the exercise2 directory, and type the following command to run PCA on the 1000 Genome data: plink --bfile data/chr1-22 --indep-pairwise 250 25 0.1 --maf 0.1 --threads 30 --out chr1-22.ldpruned_all_1kgv2 plink --bfile data/chr1-22 --extract chr1-22.ldpruned_all_1kgv2.prune.in --pca --threads 30 This will generate the principal components that maximize the variance in the data. To plot the result run the following commands from with an R-terminal: R-Code: Generate a PCA Plot require('RColorBrewer') options(scipen=100, digits=3) eigenvec <- read.table('plink.eigenvec', header = F, skip=0, sep = ' ') rownames(eigenvec) <- eigenvec[,2] eigenvec <- eigenvec[,3:ncol(eigenvec)] colnames(eigenvec) <- paste('Principal Component ', c(1:20), sep = '') PED <- read.table(\"data/all_phase3.king.psam\", header = TRUE, skip = 0, sep = '\\t') PED <- PED[which(PED$IID %in% rownames(eigenvec)), ] PED <- PED[match(rownames(eigenvec), PED$IID),] PED$Population <- factor(PED$Population, levels=c(\"ACB\",\"ASW\",\"ESN\",\"GWD\",\"LWK\",\"MSL\",\"YRI\",\"CLM\",\"MXL\",\"PEL\",\"PUR\",\"CDX\",\"CHB\",\"CHS\",\"JPT\",\"KHV\",\"CEU\",\"FIN\",\"GBR\",\"IBS\",\"TSI\",\"BEB\",\"GIH\",\"ITU\",\"PJL\",\"STU\")) col <- colorRampPalette(c(\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"forestgreen\",\"forestgreen\",\"forestgreen\",\"forestgreen\",\"grey\",\"grey\",\"grey\",\"grey\",\"grey\", \"royalblue\",\"royalblue\",\"royalblue\",\"royalblue\",\"royalblue\",\"black\",\"black\",\"black\",\"black\",\"black\"))(length(unique(PED$Population)))[factor(PED$Population)] project.pca <- eigenvec par(mar = c(5,5,5,5), cex = 2.0,cex.main = 7, cex.axis = 2.75, cex.lab = 2.75, mfrow = c(1,2)) plot(project.pca[,1], project.pca[,2], type = 'n', main = 'A', adj = 0.5, xlab = 'First component', ylab = 'Second component', font = 2, font.lab = 2) points(project.pca[,1], project.pca[,2], col = col, pch = 20, cex = 2.25) legend('bottomright', bty = 'n', cex = 3.0, title = '', c('AFR', 'AMR', 'EAS', 'EUR', 'SAS'), fill = c('yellow', 'forestgreen', 'grey', 'royalblue', 'black')) plot(project.pca[,1], project.pca[,3], type=\"n\", main=\"B\", adj=0.5, xlab=\"First component\", ylab=\"Third component\", font=2, font.lab=2) points(project.pca[,1], project.pca[,3], col=col, pch=20, cex=2.25) \u2753QUESTIONS: What is distinct about the PC projects of the AMR group relative to other populations? Greater Distance, Overlap. Why does this occur? What does it tell us about ancestry of this group? Suggest recent admixture?","title":"Population Genetics And Ancestry Analysis"},{"location":"tmp2/workshop_practical_tade/#population-genetics-and-ancestry-analysis","text":"","title":"Population Genetics And Ancestry Analysis"},{"location":"tmp2/workshop_practical_tade/#table-of-contents","text":"Key Learning Outcomes Practical Data A Portability Problem Population Genetics Basics Dimensional Reduction: PCA","title":"Table of Contents"},{"location":"tmp2/workshop_practical_tade/#key-learning-outcomes","text":"After completing this practical, you should be able to: Run mixed ancestry PRS and understand the PRS Portability Problem Understand principle component analysis and dimensional reduction Understand basic population genetics and know how to analyze ancestry groups. Understand the challenges and limitations of applying PRS in populations with diverse genetic backgrounds.","title":"Key Learning Outcomes"},{"location":"tmp2/workshop_practical_tade/#ex-1-portability-problem","text":"The first exercise of this practical takes place in the folder exercise1 . Once inside the folder you should see code and data directories. Looking in the data directory by typing the following command will reveal: ls data/* \ud83c\uddea\ud83c\uddfa: EURO_GWAS.assoc (European Ancestry GWAS Sumstats) \ud83c\uddec\ud83c\udde7: data/ukTarget (Genotype Phenotype data From a population from the UK.) \ud83c\uddef\ud83c\uddf5: data/japanTarget (Genotype Phenotype data from a population from Japan.) To start, run PRSice using the European GWAS and target data from the UK: ./code/PRSice --base data/EURO_GWAS.assoc --target data/ukTarget/ukTarget --binary-target F --out ukRun Verify that this command produce a file called \"ukRun.best\" that contains individual prs-scores in fourth column. This file can compared to the file data/ukTarget/ukTarget.pheno which contains phenotype-values in the third column. \ud83d\udea8 OPTIONAL-CHALLENGE \ud83d\udea8 Using R, Python, or another program, consider calculating the correlation between the PRS and phenotype data in the two files? First read the pseudocode and see if you can follow the strategy. Then give it a try or read the following solutions and make sure that you understand them. Notice the differences in similarities in the programming languages. Hints #1) Step1: Read Both Files in. prs_data = read('ukRun.best') pheno_data = read(\"data/ukTarget/ukTarget.pheno\") #2) Step2: Extract the correct Column from each file . prs_vals = extract_from(prs_data, column 4) pheno_vals = extract_from(pheno_data, column 3) #3) Step3: Calculate the correlation. R2 = calculate_R2_from_data(prs_vals, pheno_vals) Solution (R) R # read-in prs-file prs <- read.table(\"ukRun.best\", header = TRUE, sep = \"\", stringsAsFactors = FALSE) prs.data <- prs1[,4] # read-in pheno-file pheno <- read.table(\"data/ukTarget/ukTarget.pheno\", header = TRUE, sep = \"\", stringsAsFactors = FALSE) pheno.data <- pheno[,3] # Create DataFrame combined_data <- data.frame( x = prs.data, y = pheno.data) # Fit a linear model to the data model <- lm(y ~ x, data = combined_data) # Calculate the R-squared value r_squared <- summary(model)$r.squared # return R2 print(r_squared) Solution (Python) python3 # read-in prs-file: with open('ukRun.best') as F: prs_vals = [float(line.split()[-1]) for i,line in enumerate(F.readlines()) if i > 0] # read-in pheno-file: with open('data/ukTarget/ukTarget.pheno') as F: pheno_vals = [float(line.split()[-1]) for i,line in enumerate(F.readlines()) if i > 0] # calculate correlation prs_mean, pheno_mean = sum(prs_vals)/len(prs_vals), sum(pheno_vals)/len(pheno_vals) rTop = sum([(x-prs_mean)*(y-pheno_mean) for x,y in zip(prs_vals, pheno_vals)]) rBottom = (sum([(x-prs_mean)*(x-prs_mean) for x in prs_vals])**0.5) * (sum([(x-pheno_mean)*(x-pheno_mean) for x in pheno_vals])**0.5) # Return R2 R2 = (rTop/rBottom)*(rTop/rBottom) print(R2) After you feel confident about the code, please run the Rscript in the code directory to calculate the correlation and create a scatterplot using the UK PRS-result: Rscript --vanilla code/plot_prs_results.R data/ukTarget/ukTarget.pheno ukRun.best This will create a scatterplot file called: ukRunScatterplot.pdf . Verify that you can view it, and then type the commands below to reuse the European GWAS data and PRSice with the genotype-phenotype data from a Japan. After viewing the resulting scatterplot please answer the questions below. ./code/PRSice --base data/EURO_GWAS.assoc --target data/japanTarget/japanTarget --binary-target F --out japanRun Rscript --vanilla code/plot_prs_results.R data/japanTarget/japanTarget.pheno japanRun.best \u2753QUESTIONS: In the UK-result, what percent of variance in phenotype is explained by prs? Approximately 10%. In the Japan-result, what percent of variance in phenotype is explained by prs? Approximately 0%. Besides a difference in variance explained, do you notice any other differences? Less variance in PRS, a shift to the left. What is the name of the problem that refers to this drop in performance? The PRS Portability problem. What are some causes of the problem? 1. Differences in LD. 2. Differences in allele frequency. 3. Differences in environment. 4. Differences in population-structure. Back to Top","title":"Ex 1: Portability Problem"},{"location":"tmp2/workshop_practical_tade/#ex-2-population-genetics","text":"This exercise of this practical takes place in the folder exercise2 . Once inside the folder you should see code and data directories. Looking in the data directory by typing the following command will reveal: ls data/* \ud83c\udf0e: chr1-22.bed/bim/fam (Global Genotype Data) \ud83c\udff7\ufe0f: data/pop_info.pheno (Population specific annotation data) \ud83d\udcab: data/all_phase3.king.psam (Axillary Phase Data)","title":"Ex 2: Population Genetics"},{"location":"tmp2/workshop_practical_tade/#ex-3-pca","text":"Principle Component Analysis is a useful technique that allows researchers to visualize high dimensional data in lower space by rotating the axes in such a way that the lower dimensions (or components) maximize the total variance explained. In statistical genetics this involves \"rotating\" million-dimensional data - something that is very hard to visualize! For this reason, we begin with a simpler exercise. For the following three two dimensional shapes, spend some time identifying the principle components or sketching the line across for which variance is maximized. Check your answers below: \u2753QUESTIONS: What line represents the principle component for the first shape? The line 4/3(x) + y What line represents the principle component for the second shape? The line x+y. What line represents the principle component for the third shape? The X and Y axis already maximize the variance. Below you can view the shapes in principal component space. Now that we understand how PCA works in two dimensions we will consider a higher dimensional example. In the three dimensional space below, see if you can visualize a plane that maximizes the variance across two dimensions: Did you get it right? If so, realize that this is equivalent to what we do in genetics - we find rotate the data through millions of dimensions of space to find the plane that maximizes the variance in two dimensions: To run PCA with real data please enter the exercise2 directory, and type the following command to run PCA on the 1000 Genome data: plink --bfile data/chr1-22 --indep-pairwise 250 25 0.1 --maf 0.1 --threads 30 --out chr1-22.ldpruned_all_1kgv2 plink --bfile data/chr1-22 --extract chr1-22.ldpruned_all_1kgv2.prune.in --pca --threads 30 This will generate the principal components that maximize the variance in the data. To plot the result run the following commands from with an R-terminal: R-Code: Generate a PCA Plot require('RColorBrewer') options(scipen=100, digits=3) eigenvec <- read.table('plink.eigenvec', header = F, skip=0, sep = ' ') rownames(eigenvec) <- eigenvec[,2] eigenvec <- eigenvec[,3:ncol(eigenvec)] colnames(eigenvec) <- paste('Principal Component ', c(1:20), sep = '') PED <- read.table(\"data/all_phase3.king.psam\", header = TRUE, skip = 0, sep = '\\t') PED <- PED[which(PED$IID %in% rownames(eigenvec)), ] PED <- PED[match(rownames(eigenvec), PED$IID),] PED$Population <- factor(PED$Population, levels=c(\"ACB\",\"ASW\",\"ESN\",\"GWD\",\"LWK\",\"MSL\",\"YRI\",\"CLM\",\"MXL\",\"PEL\",\"PUR\",\"CDX\",\"CHB\",\"CHS\",\"JPT\",\"KHV\",\"CEU\",\"FIN\",\"GBR\",\"IBS\",\"TSI\",\"BEB\",\"GIH\",\"ITU\",\"PJL\",\"STU\")) col <- colorRampPalette(c(\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"forestgreen\",\"forestgreen\",\"forestgreen\",\"forestgreen\",\"grey\",\"grey\",\"grey\",\"grey\",\"grey\", \"royalblue\",\"royalblue\",\"royalblue\",\"royalblue\",\"royalblue\",\"black\",\"black\",\"black\",\"black\",\"black\"))(length(unique(PED$Population)))[factor(PED$Population)] project.pca <- eigenvec par(mar = c(5,5,5,5), cex = 2.0,cex.main = 7, cex.axis = 2.75, cex.lab = 2.75, mfrow = c(1,2)) plot(project.pca[,1], project.pca[,2], type = 'n', main = 'A', adj = 0.5, xlab = 'First component', ylab = 'Second component', font = 2, font.lab = 2) points(project.pca[,1], project.pca[,2], col = col, pch = 20, cex = 2.25) legend('bottomright', bty = 'n', cex = 3.0, title = '', c('AFR', 'AMR', 'EAS', 'EUR', 'SAS'), fill = c('yellow', 'forestgreen', 'grey', 'royalblue', 'black')) plot(project.pca[,1], project.pca[,3], type=\"n\", main=\"B\", adj=0.5, xlab=\"First component\", ylab=\"Third component\", font=2, font.lab=2) points(project.pca[,1], project.pca[,3], col=col, pch=20, cex=2.25) \u2753QUESTIONS: What is distinct about the PC projects of the AMR group relative to other populations? Greater Distance, Overlap. Why does this occur? What does it tell us about ancestry of this group? Suggest recent admixture?","title":"Ex 3: PCA"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/","text":"Polygenic Risk Score Analyses Workshop 2024 Day 1a: GWAS & relevant Statistics Introduction to Bash Most software in Bioinformatics and Statistical Genetics need to be run in a Unix environment (e.g. Linux or Mac OS) and most high-performance computer clusters run Unix systems. Therefore, although there are alternatives available on Windows (command line, Linux subsystems or Virtual Machines), it will be highly beneficial to become familiar with performing research in a Unix-only environment. Moving around the File System To begin our practical, please open up a \\\"terminal\\\" on your computer (on a Mac this is stored in Applications/Utilities/). We can change our directory using the following command: cd \\<Path>\\ where *\\ * is the path to the target directory. Some common usage of cd includes cd ~/ # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd XXX # will bring you to the XXX directory, so long as it is in the current directory As an example, we can move to the data directory by typing: cd data/ Looking at the Current Directory Next we can move into the ~/data/Day1a_Data/Day1a_Data folder (from the data/ folder type: cd Day1a_Data/Day1a_Data). We can list out the folder content by typing: ls For ls, there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size Counting Number of Lines in File We can also count the number of lines in a file with the following command (where *\\ * is the file of interest): wc -l <file> Often we would like to store the output of a command, which we can do by redirecting the output of the command to a file. For example, we can redirect the count of the GIANT_Height.txt to giant_count using the following command: wc -l GIANT_Height.txt > giant_count.txt Search File Content Another common task is to search for specific words or characters in a file (e.g. does this file contain our gene of interest?). This can be performed using the \"grep\" command as follows: grep <string> file For example, to check if the Single Nucleotide Polymorphism (SNP) rs10786427 is present in GIANT_Height.txt , we can do: grep rs10786427 GIANT_Height.txt In addition, grep allows us to check if patterns contained in one file can be found in another file. For example, if we want to extract a subset of samples from the phenotype file (e.g. extract the list of samples in Data/Day_1a/TAR.height ), we can do: grep -f Select.sample TAR.height An extremely useful feature of the terminal is chaining multiple commands into one command, which we call piping . For example, we can use piping to count the number of samples in Select.sample that were found in TAR.height in a single command, as follows: bash grep -f Select.sample TAR.height | wc -l Filtering and Reshu\ufb04ing Files A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new results file that only contains SNP rsIDs (column 1), allele frequencies (column 4) and P -values (column 7) as follows: awk '{ print $1,$4,$7}' GIANT_Height.txt > GIANT_Height_3cols.txt We can also use a \\\"conditional statement\\\" in awk to extract all significant [SNPs] from the results file, using the following command: awk '{if($7 < 5e-8) { print } }' GIANT_Height.txt > Significant_SNPs.txt Or the short form: awk '$7 < 5e-8{ print}' GIANT_Height.txt > Significant_SNPs.txt \"if( \\(7<5e-8)\" and \"\\) 7 < 5e-8\" tell awk to extract any rows with column 7 (the column containing P -value) with a value of smaller than 5e-8 and {print} means that we would like to print the entire row when this criterion is met. Introduction to R R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop. Basics If you are not using R Studio then you can type R in your terminal to run R in the terminal. ## Adding script to working dir cd ~/data/Day1a_Data/Day1a_Data wget https://raw.githubusercontent.com/WCSCourses/prs_2023/main/scripts/nagelkerke.R Working Directory When we start R , we will be working in a specific folder called the working directory . We can check the current/working directory we are in by typing: getwd() And we can change our working directory to the Practical folder by setwd(\"~/data/Day1a_Data/Day1a_Data\") Libraries Most functionality of R is organised in \\\"packages\\\" or \\\"libraries\\\". To access these functions, we will have to install and \\\"load\\\" these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Alternatively, we can import functions (e.g. that we have written) from an R script file on our computer. For example, you can load the Nagelkerke R2 function by typing source(\"nagelkerke.R\") And you are now able to use the Nagelkerke R2 function (we will use this function at the end of this worksheet). Variables in R You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\") Functions You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2) Plotting While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point() Regression Models In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial)) We will need the NagelkerkeR2 function to calculate the pseudo R2 for logistic model source(\"nagelkerke.R\") reg <- glm(y~x, family=binomial) Calculate the Nagelkerke R2 using the NagelkerkeR2 function NagelkerkeR2(reg)","title":"Polygenic Risk Score Analyses Workshop 2024"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#polygenic-risk-score-analyses-workshop-2024","text":"","title":"Polygenic Risk Score Analyses Workshop 2024"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#day-1a-gwas-relevant-statistics","text":"","title":"Day 1a: GWAS &amp; relevant Statistics"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#introduction-to-bash","text":"Most software in Bioinformatics and Statistical Genetics need to be run in a Unix environment (e.g. Linux or Mac OS) and most high-performance computer clusters run Unix systems. Therefore, although there are alternatives available on Windows (command line, Linux subsystems or Virtual Machines), it will be highly beneficial to become familiar with performing research in a Unix-only environment.","title":"Introduction to Bash"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#moving-around-the-file-system","text":"To begin our practical, please open up a \\\"terminal\\\" on your computer (on a Mac this is stored in Applications/Utilities/). We can change our directory using the following command: cd \\<Path>\\ where *\\ * is the path to the target directory. Some common usage of cd includes cd ~/ # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd XXX # will bring you to the XXX directory, so long as it is in the current directory As an example, we can move to the data directory by typing: cd data/","title":"Moving around the File System"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#looking-at-the-current-directory","text":"Next we can move into the ~/data/Day1a_Data/Day1a_Data folder (from the data/ folder type: cd Day1a_Data/Day1a_Data). We can list out the folder content by typing: ls For ls, there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size","title":"Looking at the Current Directory"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#counting-number-of-lines-in-file","text":"We can also count the number of lines in a file with the following command (where *\\ * is the file of interest): wc -l <file> Often we would like to store the output of a command, which we can do by redirecting the output of the command to a file. For example, we can redirect the count of the GIANT_Height.txt to giant_count using the following command: wc -l GIANT_Height.txt > giant_count.txt","title":"Counting Number of Lines in File"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#search-file-content","text":"Another common task is to search for specific words or characters in a file (e.g. does this file contain our gene of interest?). This can be performed using the \"grep\" command as follows: grep <string> file For example, to check if the Single Nucleotide Polymorphism (SNP) rs10786427 is present in GIANT_Height.txt , we can do: grep rs10786427 GIANT_Height.txt In addition, grep allows us to check if patterns contained in one file can be found in another file. For example, if we want to extract a subset of samples from the phenotype file (e.g. extract the list of samples in Data/Day_1a/TAR.height ), we can do: grep -f Select.sample TAR.height An extremely useful feature of the terminal is chaining multiple commands into one command, which we call piping . For example, we can use piping to count the number of samples in Select.sample that were found in TAR.height in a single command, as follows: bash grep -f Select.sample TAR.height | wc -l","title":"Search File Content"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#filtering-and-reshuffling-files","text":"A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new results file that only contains SNP rsIDs (column 1), allele frequencies (column 4) and P -values (column 7) as follows: awk '{ print $1,$4,$7}' GIANT_Height.txt > GIANT_Height_3cols.txt We can also use a \\\"conditional statement\\\" in awk to extract all significant [SNPs] from the results file, using the following command: awk '{if($7 < 5e-8) { print } }' GIANT_Height.txt > Significant_SNPs.txt Or the short form: awk '$7 < 5e-8{ print}' GIANT_Height.txt > Significant_SNPs.txt \"if( \\(7<5e-8)\" and \"\\) 7 < 5e-8\" tell awk to extract any rows with column 7 (the column containing P -value) with a value of smaller than 5e-8 and {print} means that we would like to print the entire row when this criterion is met.","title":"Filtering and Reshu\ufb04ing Files"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#introduction-to-r","text":"R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop.","title":"Introduction to R"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#basics","text":"If you are not using R Studio then you can type R in your terminal to run R in the terminal. ## Adding script to working dir cd ~/data/Day1a_Data/Day1a_Data wget https://raw.githubusercontent.com/WCSCourses/prs_2023/main/scripts/nagelkerke.R","title":"Basics"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#working-directory","text":"When we start R , we will be working in a specific folder called the working directory . We can check the current/working directory we are in by typing: getwd() And we can change our working directory to the Practical folder by setwd(\"~/data/Day1a_Data/Day1a_Data\")","title":"Working Directory"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#libraries","text":"Most functionality of R is organised in \\\"packages\\\" or \\\"libraries\\\". To access these functions, we will have to install and \\\"load\\\" these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Alternatively, we can import functions (e.g. that we have written) from an R script file on our computer. For example, you can load the Nagelkerke R2 function by typing source(\"nagelkerke.R\") And you are now able to use the Nagelkerke R2 function (we will use this function at the end of this worksheet).","title":"Libraries"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#variables-in-r","text":"You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\")","title":"Variables in R"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#functions","text":"You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2)","title":"Functions"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#plotting","text":"While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point()","title":"Plotting"},{"location":"tmp2/practical_docs_hidden/Day1a.docx/#regression-models","text":"In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial)) We will need the NagelkerkeR2 function to calculate the pseudo R2 for logistic model source(\"nagelkerke.R\") reg <- glm(y~x, family=binomial) Calculate the Nagelkerke R2 using the NagelkerkeR2 function NagelkerkeR2(reg)","title":"Regression Models"},{"location":"tmp2/practical_docs_hidden/Day2.docx/","text":"Introduction to Polygenic Risk Scores Table of Contents Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Data Structure You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this command - cd ~/Downloads wget https://wcs_data_transfer.cog.sanger.ac.uk/Day2_Base_Data.zip You may also download it via dropbox if the above fails with this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice_linux/PRSice Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary. Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres \u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status. Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis. Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#introduction-to-polygenic-risk-scores","text":"","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#table-of-contents","text":"Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents","title":"Table of Contents"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#data-structure","text":"You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this command - cd ~/Downloads wget https://wcs_data_transfer.cog.sanger.ac.uk/Day2_Base_Data.zip You may also download it via dropbox if the above fails with this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents","title":"Data Structure"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents","title":"Understanding GWAS Summary Statistics"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents","title":"Matching the Base and Target Data sets"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents","title":"Performing Clumping"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds.","title":"P-Value Thresholding"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice_linux/PRSice Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents","title":"High Resolution Scoring"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents","title":"Stratifying Samples by PRS"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary.","title":"Case Control Studies"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#rscript-prsice_linuxprsicer-prsice-prsice_linuxprsice_linux-base-base_datacadaddtxt-target-target_datatar-snp-markername-a1-effect_allele-a2-noneffect_allele-chr-chr-bp-bp_hg19-stat-beta-beta-pvalue-p_dgc-pheno-target_datacadpheno-binary-target-t-out-resultscadhighres","text":"\u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status.","title":"Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres\n"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis.","title":"Cross-Trait Analysis"},{"location":"tmp2/practical_docs_hidden/Day2.docx/#rscript-prsice_linuxprsicer-prsice-prsice_linuxprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datacadpheno-binary-target-t-out-resultscrosshighres","text":"Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Rscript ~/PRSice_linux/PRSice.R --prsice ~/PRSice_linux/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres\n"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/","text":"Advanced Polygenic Risk Score Analyses Day 2 - Afternoon Practical: Pathway PRS Analyses Table of Contents Introduction to gene set (pathway) PRS analysis Inputs required for gene-set PRS analysis Molecular Signatures Database MSigDB Other inputs that can be used for gene-set PRS using PRSet Exercise: Calculate gene-set PRS analysis Considerations when analysing and interpreting gene set PRSs Clumping for each gene set independently P-value thresholding in gene set PRS analyses Self-contained vs competitive testing Key Learning Outcomes After completing this practical, you should be able to: 1. Understand the motivation and rationale for calculating gene set PRS. 2. Identify the additional inputs required for gene set PRS analysis. 3. Calculate gene set based PRSs using PRSet. 5. Understand and interpret the outcomes of gene set PRSs and how they differ from genome-wide PRS. Data Structure You will find all practical materials in the data/Day_2b directory. Relevant materials that you should find at the start of the practical are: \ud83d\udcc2: Base_Data - GIANT_Height.txt, \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.covariate \ud83d\udcc1: Reference - Homo_sapiens.GRCh38.109.gtf.gz - Sets.gmt Introduction to gene set (pathway) PRS analysis Most PRS methods summarize genetic risk to a single number, based on the aggregation of an individual\u2019s genome-wide risk alleles. This approach does not consider the different contributions of the various biological processes that can influence complex diseases and traits. During this session, you will learn how to run a gene set (or pathway) based PRS analyses. The key difference between genome-wide PRS and gene set or pathway-based PRSs analyses is that, instead of aggregating the estimated effects of risk alleles across the entire genome, gene set PRSs aggregate risk alleles across as many gene sets as the user defines (Figure 1). Figure 1: The pathway polygenic risk score approach. Coloured boxes represent genes, lines link genes that are within the same genomic pathway. See full description here . \ud83d\udccc In this practical, we will go through some of the additional input requirements and considerations for the analysis of gene set PRS analysis, and will then calculate some gene set based PRS using PRSet . By aggregating PRS across multiple gene sets (or pathways), these PRS analyses will allow us to determine the genetic contribution made by each biological process in complex traits and diseases. For more information about the rationale and the software that we are going to use, please see the PRSet publication PRSet: Pathway-based polygenic risk score analyses and software . \u2753 Why is it useful to have polygenic scores measured across gene-sets (or pathways) for individuals? Isn\u2019t it su\ufb03cient to just obtain a ranking of gene-sets according to GWAS-signal enrichment (using gene set enrichment tools such as MAGMA or partitioned LDSC)? Inputs required for gene-set PRS analysis Summary statistics from GWAS, as well as individual level genotype and phenotype data are required to perform gene set PRS analyses. In this session, the following Base and Target data is used. Base data is publicly available. All Target data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Data Set Description Download Link Base from the GIANT Consortium GWAS of height on 253,288 individuals Link Simulated Target Data Individual-level phenotype and genotype files Data folder Additionally, to perform gene set PRS analyses, information about the gene sets for which we want to calculate the PRSs are required. In this tutorial, we will use as input gene-sets from the Molecular Signatures Database . However, PRSet also takes as input BED and SNP files . Data Set Description Download Link Ensembl Human Genome GTF file A file containing the coordinates for genes in the human genome. Used by PRSet to map the SNPs onto genic regions Link to Homo_sapiens.GRCh38.109.gtf.gz MSigDB Gene Sets File containing the gene-set information. Free registration required. Download link after registration Molecular Signatures Database MSigDB + General Transfer Format file MSigDB o\ufb00ers an excellent source of gene sets, including the hallmark genes, gene sets of di\ufb00erent biological processes, gene sets of di\ufb00erent oncogenic signatures etc. All gene sets from MSigDB follows the Gene Matrix Transposed file format (GMT), which consists of one line per gene set, each containing at least 3 column of data: Set A Description Gene 1 Gene 2 ... Set A Description Gene 1 Gene 2 ... \ud83d\udcac While you can read the GMT file using Excel, we recommend exploring these files using bash. You should be aware that Excel has a tendency to convert gene names into dates (e.g. SEPT9 to Sep-9) ** Have a look at the Reference/Sets.gmt file. ** \u2753 How many gene sets are there in the Reference/Sets.gmt file? \u2753 How many genes does the largest gene set contain? As GMT format does not contain the chromosomal location for each individual gene, an additional file (General Transfer Format file) is required to provide the chromosomal location such that SNPs can be mapped to genes. The General Transfer Format (GTF) file contains the chromosomal coordinates for each gene. It is a tab separated file and all fields except the last must contain a value. You can read the full format specification here . Two columns in the GTF file that might be of particular interest are: - Column 3: feature , which indicates what feature that line of GTF represents. This allows us to select or ignore features that are of interest. Column 9: attribute , which contains a semicolon-separated list of tag-value pairs (separated by a space), providing additional information about each feature. A key can be repeated multiple times. > \ud83d\udccc Tip , to parse column 9 and split the additional information in separate columns, you can use the following R code: library(data.table) library(magrittr) # Function to extract attributes from column 9 in GTF files: extract_attribute = function(input, attribute) { strsplit(input, split = \";\") %>% unlist %>% .[grepl(attribute, .)] %>% gsub(\"\\\"\", \"\", .) %>% strsplit(., split = \" \") %>% unlist %>% tail(n = 1) %>% return } gtf38 = fread(\"./Reference/Homo_sapiens.GRCh38.109.gtf.gz\") gtf38_parsed = gtf38 %>% # Select genes only, based on column 3 (feature) .[V3 == \"gene\"] %>% # Select genes located in autosomes .[`#!genebuild-last-updated 2022-11` %in% 1:22] %>% # Create colummns with Gene information .[, c(\"chr\", \"Gene_start\", \"Gene_end\", \"ensemblID\", \"Gene_Name\", \"Gene_biotype\") := data.table( `#!genebuild-last-updated 2022-11`, V4, V5, sapply(V9, extract_attribute, \"gene_id\"), sapply(V9, extract_attribute, \"gene_name\"), sapply(V9, extract_attribute, \"gene_biotype\"))] %>% # Filter the columns of interest .[, c(\"chr\", \"Gene_start\", \"Gene_end\", \"ensemblID\", \"Gene_Name\", \"Gene_biotype\")] ** Have a look at the Reference/Homo_sapiens.GRCh38.109.gtf.gz file. ** \u2753 Based on the column with information about the features, how many instances of feature = \"gene\" can you find ? \u2753 Based on the column with inforamtion about the attributes, how many protein-coding genes are there in the Reference/Homo_sapiens.GRCh38.109.gtf.gz file? Other inputs that can be used for gene set PRS using PRSet Browser Extensible Data BED Browser Extensible Data (BED) file (di\ufb00erent to the binary ped file from PLINK), is a file format to define genetic regions. It contains 3 required fields per line (chromosome, start coordinate and end coordinate) together with 9 additional optional field. A special property of BED is that it is a 0-based format, i.e. chromosome starts at 0, as opposed to the usual 1-based format such as the PLINK format. For example, a SNP on chr1:10000 will be represented as: 1 9999 10000 \u2753 How should we represent the coordinate of rs2980300 (chr1:785989) in BED format? List of SNPs Finally, PRSet also allow SNP sets, where the user have flexibility to decide what SNPs are included. The list of SNPs can have two different formats: - SNP list format, a file containing a single column of SNP ID. Name of the set will be the file name or can be provided using --snp-set File:Name - MSigDB format: Each row represent a single SNP set with the first column containing the name of the SNP set. Back to Top Exercise: Calculate gene set PRS analysis We are now ready to perform gene-set association analyses using PRSet. To perform the PRSet analysis and obtain the set based PRS and competitive P-value, simply provide the GTF file and the GMT file to PRSice and specify the number of permutation for competitive P-value calculation using the --set-perm option. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ ----> ATTENTION, the binary file may be different depending on the operative system (linux, mac, windows) --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --A1 Allele1 \\ --A2 Allele2 \\ --snp MarkerName \\ --pvalue p \\ --stat b \\ --beta \\ --binary-target F \\ --pheno Target_Data/TAR.height \\ --cov Target_Data/TAR.covariate \\ --out Height.set \\ --gtf Reference/Homo_sapiens.GRCh38.109.gtf.gz \\ --wind-5 5kb \\ --wind-3 1kb \\ --msigdb Reference/Sets.gmt \\ --multi-plot 10 \\ --set-perm 1000 > \ud83d\udccc If the --wind-5 and --wind-3 flag is not specified, PRSet will use the exact coordinates of each gene as the boundary. By specifying eg. --wind-5 5kb and --wind-3 1kb then the boundary of each gene will be extended 5 kb towards the 5\u2019 end and 1 kb towards the 3\u2019 end so that regulatory elements of the gene can be included. Results and Plots specific of gene set PRS analyses ** Check the .summary results file, with and without running the PRSet specific options ** \u2753 How does this file change? What extra information is incorporated when including the PRSet specific commands? Apart from the output files, running the PRSet options will provide extra information about the new gene set PRSs calculated. For example, a new figure with the results for each gene set PRS. Figure 2 : An example of the multi-set plot. Sets are sorted based on their self-contained R2. Base is the genome wide PRS. Considerations when analysing and interpreting gene-set PRSs Clumping for each gene set independently In standard clumping and P-value thresholding methods, clumping is performed to account for linkage disequilibrium between SNPs. If genome-wide clumping is performed at the gene set level, we may remove signal as shown in this toy example . To maximize signal within each gene set, clumping is performed for each gene set separately. ** Check the .summary results file. When answering questions, do not count the Base, as this result corresponds to the genome-wide PRS ** \u2753 Check the '.summary' file. How many SNPs are included in the top 10 gene sets? \u2753 Can you plot the relationship between the gene set R2 and the number of SNPs in each gene set? What general trend can be seen? P-value thresholding in gene set PRS analyses PRSet default option is to no not perform p-value thresholding. It will simply calculate the set based PRS at P-value threshold of 1. \u2753 Why do you think that the default option of PRSet is P-value threshold of 1? \u2753 In what cases would you like to apply P-value thresholding? Self-contained vs competitive testing An important aspect when calculating gene set based PRSs is the type of test used for association. Since we are only considering one region of the genome, self-contained and/or competitive tests can be performed. The null-hypothesis of self-contained and competitive test statistics is di\ufb00erent: \u2013 Self-Contained - None of the genes within the gene-set are associated with the phenotype \u2013 Competitive - Genes within the gene-set are no more associated with the phenotype than genes outside the gene-set Therefore, a bigger gene-set will have a higher likelihood of having a significant P -value from self-contained test, which is not desirable. ** Check the .summary results file again ** \u2753 What are the 3 gene-sets with the smallest competitive P-values? \u2753 Why do you think that we check the competitive P-value, instead of the self contained P-value? ** Imagine that you are running an analysis to find the gene sets most associated with height ** \u2753 Considering the competitive P-value results, what gene set do you think is the most interesting and why? Back to Top","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#advanced-polygenic-risk-score-analyses","text":"","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#day-2-afternoon-practical-pathway-prs-analyses","text":"","title":"Day 2 - Afternoon Practical: Pathway PRS Analyses"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#table-of-contents","text":"Introduction to gene set (pathway) PRS analysis Inputs required for gene-set PRS analysis Molecular Signatures Database MSigDB Other inputs that can be used for gene-set PRS using PRSet Exercise: Calculate gene-set PRS analysis Considerations when analysing and interpreting gene set PRSs Clumping for each gene set independently P-value thresholding in gene set PRS analyses Self-contained vs competitive testing","title":"Table of Contents"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: 1. Understand the motivation and rationale for calculating gene set PRS. 2. Identify the additional inputs required for gene set PRS analysis. 3. Calculate gene set based PRSs using PRSet. 5. Understand and interpret the outcomes of gene set PRSs and how they differ from genome-wide PRS.","title":"Key Learning Outcomes"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#data-structure","text":"You will find all practical materials in the data/Day_2b directory. Relevant materials that you should find at the start of the practical are: \ud83d\udcc2: Base_Data - GIANT_Height.txt, \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.covariate \ud83d\udcc1: Reference - Homo_sapiens.GRCh38.109.gtf.gz - Sets.gmt","title":"Data Structure"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#introduction-to-gene-set-pathway-prs-analysis","text":"Most PRS methods summarize genetic risk to a single number, based on the aggregation of an individual\u2019s genome-wide risk alleles. This approach does not consider the different contributions of the various biological processes that can influence complex diseases and traits. During this session, you will learn how to run a gene set (or pathway) based PRS analyses. The key difference between genome-wide PRS and gene set or pathway-based PRSs analyses is that, instead of aggregating the estimated effects of risk alleles across the entire genome, gene set PRSs aggregate risk alleles across as many gene sets as the user defines (Figure 1). Figure 1: The pathway polygenic risk score approach. Coloured boxes represent genes, lines link genes that are within the same genomic pathway. See full description here . \ud83d\udccc In this practical, we will go through some of the additional input requirements and considerations for the analysis of gene set PRS analysis, and will then calculate some gene set based PRS using PRSet . By aggregating PRS across multiple gene sets (or pathways), these PRS analyses will allow us to determine the genetic contribution made by each biological process in complex traits and diseases. For more information about the rationale and the software that we are going to use, please see the PRSet publication PRSet: Pathway-based polygenic risk score analyses and software . \u2753 Why is it useful to have polygenic scores measured across gene-sets (or pathways) for individuals? Isn\u2019t it su\ufb03cient to just obtain a ranking of gene-sets according to GWAS-signal enrichment (using gene set enrichment tools such as MAGMA or partitioned LDSC)?","title":"Introduction to gene set (pathway) PRS analysis"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#inputs-required-for-gene-set-prs-analysis","text":"Summary statistics from GWAS, as well as individual level genotype and phenotype data are required to perform gene set PRS analyses. In this session, the following Base and Target data is used. Base data is publicly available. All Target data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Data Set Description Download Link Base from the GIANT Consortium GWAS of height on 253,288 individuals Link Simulated Target Data Individual-level phenotype and genotype files Data folder Additionally, to perform gene set PRS analyses, information about the gene sets for which we want to calculate the PRSs are required. In this tutorial, we will use as input gene-sets from the Molecular Signatures Database . However, PRSet also takes as input BED and SNP files . Data Set Description Download Link Ensembl Human Genome GTF file A file containing the coordinates for genes in the human genome. Used by PRSet to map the SNPs onto genic regions Link to Homo_sapiens.GRCh38.109.gtf.gz MSigDB Gene Sets File containing the gene-set information. Free registration required. Download link after registration","title":"Inputs required for gene-set PRS analysis"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#molecular-signatures-database-msigdb-general-transfer-format-file","text":"MSigDB o\ufb00ers an excellent source of gene sets, including the hallmark genes, gene sets of di\ufb00erent biological processes, gene sets of di\ufb00erent oncogenic signatures etc. All gene sets from MSigDB follows the Gene Matrix Transposed file format (GMT), which consists of one line per gene set, each containing at least 3 column of data: Set A Description Gene 1 Gene 2 ... Set A Description Gene 1 Gene 2 ... \ud83d\udcac While you can read the GMT file using Excel, we recommend exploring these files using bash. You should be aware that Excel has a tendency to convert gene names into dates (e.g. SEPT9 to Sep-9) ** Have a look at the Reference/Sets.gmt file. ** \u2753 How many gene sets are there in the Reference/Sets.gmt file? \u2753 How many genes does the largest gene set contain? As GMT format does not contain the chromosomal location for each individual gene, an additional file (General Transfer Format file) is required to provide the chromosomal location such that SNPs can be mapped to genes. The General Transfer Format (GTF) file contains the chromosomal coordinates for each gene. It is a tab separated file and all fields except the last must contain a value. You can read the full format specification here . Two columns in the GTF file that might be of particular interest are: - Column 3: feature , which indicates what feature that line of GTF represents. This allows us to select or ignore features that are of interest. Column 9: attribute , which contains a semicolon-separated list of tag-value pairs (separated by a space), providing additional information about each feature. A key can be repeated multiple times.","title":"Molecular Signatures Database MSigDB + General Transfer Format file"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#tip-to-parse-column-9-and-split-the-additional-information-in-separate-columns-you-can-use-the-following-r-code","text":"library(data.table) library(magrittr) # Function to extract attributes from column 9 in GTF files: extract_attribute = function(input, attribute) { strsplit(input, split = \";\") %>% unlist %>% .[grepl(attribute, .)] %>% gsub(\"\\\"\", \"\", .) %>% strsplit(., split = \" \") %>% unlist %>% tail(n = 1) %>% return } gtf38 = fread(\"./Reference/Homo_sapiens.GRCh38.109.gtf.gz\") gtf38_parsed = gtf38 %>% # Select genes only, based on column 3 (feature) .[V3 == \"gene\"] %>% # Select genes located in autosomes .[`#!genebuild-last-updated 2022-11` %in% 1:22] %>% # Create colummns with Gene information .[, c(\"chr\", \"Gene_start\", \"Gene_end\", \"ensemblID\", \"Gene_Name\", \"Gene_biotype\") := data.table( `#!genebuild-last-updated 2022-11`, V4, V5, sapply(V9, extract_attribute, \"gene_id\"), sapply(V9, extract_attribute, \"gene_name\"), sapply(V9, extract_attribute, \"gene_biotype\"))] %>% # Filter the columns of interest .[, c(\"chr\", \"Gene_start\", \"Gene_end\", \"ensemblID\", \"Gene_Name\", \"Gene_biotype\")] ** Have a look at the Reference/Homo_sapiens.GRCh38.109.gtf.gz file. ** \u2753 Based on the column with information about the features, how many instances of feature = \"gene\" can you find ? \u2753 Based on the column with inforamtion about the attributes, how many protein-coding genes are there in the Reference/Homo_sapiens.GRCh38.109.gtf.gz file?","title":"&gt; \ud83d\udccc Tip, to parse column 9 and split the additional information in separate columns, you can use the following R code:"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#other-inputs-that-can-be-used-for-gene-set-prs-using-prset","text":"","title":"Other inputs that can be used for gene set PRS using PRSet"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#browser-extensible-data-bed","text":"Browser Extensible Data (BED) file (di\ufb00erent to the binary ped file from PLINK), is a file format to define genetic regions. It contains 3 required fields per line (chromosome, start coordinate and end coordinate) together with 9 additional optional field. A special property of BED is that it is a 0-based format, i.e. chromosome starts at 0, as opposed to the usual 1-based format such as the PLINK format. For example, a SNP on chr1:10000 will be represented as: 1 9999 10000 \u2753 How should we represent the coordinate of rs2980300 (chr1:785989) in BED format?","title":"Browser Extensible Data BED"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#list-of-snps","text":"Finally, PRSet also allow SNP sets, where the user have flexibility to decide what SNPs are included. The list of SNPs can have two different formats: - SNP list format, a file containing a single column of SNP ID. Name of the set will be the file name or can be provided using --snp-set File:Name - MSigDB format: Each row represent a single SNP set with the first column containing the name of the SNP set. Back to Top","title":"List of SNPs"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#exercise-calculate-gene-set-prs-analysis","text":"We are now ready to perform gene-set association analyses using PRSet. To perform the PRSet analysis and obtain the set based PRS and competitive P-value, simply provide the GTF file and the GMT file to PRSice and specify the number of permutation for competitive P-value calculation using the --set-perm option. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ ----> ATTENTION, the binary file may be different depending on the operative system (linux, mac, windows) --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --A1 Allele1 \\ --A2 Allele2 \\ --snp MarkerName \\ --pvalue p \\ --stat b \\ --beta \\ --binary-target F \\ --pheno Target_Data/TAR.height \\ --cov Target_Data/TAR.covariate \\ --out Height.set \\ --gtf Reference/Homo_sapiens.GRCh38.109.gtf.gz \\ --wind-5 5kb \\ --wind-3 1kb \\ --msigdb Reference/Sets.gmt \\ --multi-plot 10 \\ --set-perm 1000","title":"Exercise: Calculate gene set PRS analysis"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#if-the-wind-5-and-wind-3-flag-is-not-specified-prset-will-use-the-exact-coordinates-of-each-gene-as-the-boundary-by-specifying-eg-wind-5-5kb-and-wind-3-1kb-then-the-boundary-of-each-gene-will-be-extended-5-kb-towards-the-5-end-and-1-kb-towards-the-3-end-so-that-regulatory-elements-of-the-gene-can-be-included","text":"","title":"&gt; \ud83d\udccc If the --wind-5 and --wind-3 flag is not specified, PRSet will use the exact coordinates of each gene as the boundary. By specifying eg. --wind-5 5kb and --wind-3 1kb then the boundary of each gene will be extended 5 kb towards the 5\u2019 end and 1 kb towards the 3\u2019 end so that regulatory elements of the gene can be included."},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#results-and-plots-specific-of-gene-set-prs-analyses","text":"** Check the .summary results file, with and without running the PRSet specific options ** \u2753 How does this file change? What extra information is incorporated when including the PRSet specific commands? Apart from the output files, running the PRSet options will provide extra information about the new gene set PRSs calculated. For example, a new figure with the results for each gene set PRS. Figure 2 : An example of the multi-set plot. Sets are sorted based on their self-contained R2. Base is the genome wide PRS.","title":"Results and Plots specific of gene set PRS analyses"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#considerations-when-analysing-and-interpreting-gene-set-prss","text":"","title":"Considerations when analysing and interpreting gene-set PRSs"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#clumping-for-each-gene-set-independently","text":"In standard clumping and P-value thresholding methods, clumping is performed to account for linkage disequilibrium between SNPs. If genome-wide clumping is performed at the gene set level, we may remove signal as shown in this toy example . To maximize signal within each gene set, clumping is performed for each gene set separately. ** Check the .summary results file. When answering questions, do not count the Base, as this result corresponds to the genome-wide PRS ** \u2753 Check the '.summary' file. How many SNPs are included in the top 10 gene sets? \u2753 Can you plot the relationship between the gene set R2 and the number of SNPs in each gene set? What general trend can be seen?","title":"Clumping for each gene set independently"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#p-value-thresholding-in-gene-set-prs-analyses","text":"PRSet default option is to no not perform p-value thresholding. It will simply calculate the set based PRS at P-value threshold of 1. \u2753 Why do you think that the default option of PRSet is P-value threshold of 1? \u2753 In what cases would you like to apply P-value thresholding?","title":"P-value thresholding in gene set PRS analyses"},{"location":"tmp2/practical_docs_hidden/Day2b.docx/#self-contained-vs-competitive-testing","text":"An important aspect when calculating gene set based PRSs is the type of test used for association. Since we are only considering one region of the genome, self-contained and/or competitive tests can be performed. The null-hypothesis of self-contained and competitive test statistics is di\ufb00erent: \u2013 Self-Contained - None of the genes within the gene-set are associated with the phenotype \u2013 Competitive - Genes within the gene-set are no more associated with the phenotype than genes outside the gene-set Therefore, a bigger gene-set will have a higher likelihood of having a significant P -value from self-contained test, which is not desirable. ** Check the .summary results file again ** \u2753 What are the 3 gene-sets with the smallest competitive P-values? \u2753 Why do you think that we check the competitive P-value, instead of the self contained P-value? ** Imagine that you are running an analysis to find the gene sets most associated with height ** \u2753 Considering the competitive P-value results, what gene set do you think is the most interesting and why? Back to Top","title":"Self-contained vs competitive testing"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/","text":"Advanced Polygenic Risk Score Analyses Day 3 - Polygenic Risk Score Analyses Workshop 2024 Table of Contents Key Learning Outcomes Base and Target datasets Downloading Datasets Method for Calculating PRS Exercise 1 Estimating R 2 Exercise 2 Visualising and comparing R 2 Day 3a practical Key Learning Outcomes After completing this practical, you should be able to: 1. Compute and analyse ancestry-matched and unmatched PRS using PRSice-2. 2. Understand and interpret the results from PRSise-2 derived scores. 3. Understand and identify the impact of ancestry on the predictive utility of PRS. 4. Understand and identify the impact of sample size on the predictive utility of PRS. 5. Understand the challenges and limitations of applying PRS in populations with diverse genetic backgrounds. Base and Target datasets In this practical, we will compute a PRS for systolic blood pressure (SBP) and assess it performance across European and African ancestry datasets to clearly illustrate the portability problem. We will assess the predictive utility of 3 scores : ANCESTRY-MATCHED 1. EUR base - EUR target: Utilise European summary statistics as the training data and individual-level genotyped data from Europeans as the target dataset. 2. AFR base - AFR target: Utilise African summary statistics as the training data and individual-level genotyped data from Africans as the target dataset. ANCESTRY-UNMATCHED EUR base - AFR target: Utilise European summary statistics as the training data and individual-level genotyped data from Africans as the target dataset. Please note that the sample sizes of the individual-level target data are as follows: Europeans (n = ~500) and Africans (n = ~650). Note: This is simulated data with no real-life biological meaning or implication. Dataset Source Description Base dataset (EUR, AFR) simulated GWAS summary stats of SBP Target dataset (EUR, AFR) simulated EUR (n = ~500), AFR (n = ~650) Downloading Datasets All required software for this practical is found in the /home/manager/data/Data_Day4/software directory. \ud83d\udee0\ufe0f: Software - PRSice.R - PRSice_linux - plink_linux All required data for this practical is found in the /home/manager/data/Data_Day4/data directory. The relevant data that you should see there at the start of the practical are as follows: \ud83d\udcc2: Base_Data (summary statistics) - AFR-SBP-simulated.sumstats.prscsx - EUR-SBP-simulated.sumstats.prscsx \ud83d\udcc2: Target_Data - AFR_1kg.hm3.only.csx (.bed, .bim, .fam) - EUR_1kg.hm3.only.csx (.bed, .bim, .fam) - sbp.afr.1kg.sim_pheno - sbp.eur.1kg.sim_pheno \ud83d\udcc1: Reference files - 1kg.afr.dbSNP153.hg38.bed - 1kg.afr.dbSNP153.hg38.bim - 1kg.afr.dbSNP153.hg38.fam - 1kg.eur.dbSNP153.hg38.bed - 1kg.eur.dbSNP153.hg38.bim - 1kg.eur.dbSNP153.hg38.fam Method for calculating PRS For this practical we will use PRSice-2. PRSice-2 is one of the dedicated PRS calculation and analysis programs that makes use of a sequence of PLINK functions. The tools utilises the standard clumping and thresholding (C+T) approach. Exercise 1 Estimating R 2 Code Open the terminal and move to the data directory for this practical: cd /home/manager/data/Data_Day4/data Create the output directory - \"out\": mkdir out Look at the data files within the directory: ls -l Now, calculate PRS using PRSice 2 Scenario 1: Predicting from EUR training to EUR target data: Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.eur.eur Key code parameters The parameters listed in this table remain consistent across various scenarios, but the specific values may change based on the dataset and analysis scenario. For illustrative purposes, this table uses the first scenario, EUR base and EUR target population: Click to view the parameters table Parameter Value Description prsice PRSice_xxx Informs PRSice.R that the location of the PRSice binary, xxx is the operating system (mac or linux) base EUR-SBP-simulated.sumstats.prscsx Specifies the GWAS summary statistics file for input A1 A1 Column name for the effect allele in the GWAS summary statistics p value P Column name for the p-values of SNPs in the GWAS summary statistics no clump - Instructs PRSice to skip the clumping process, which is used to remove SNPs in linkage disequilibrium beta - Indicates that the effect sizes are given in beta coefficients (linear regression coefficients) snp SNP Column name for SNP identifiers in the GWAS summary statistics score sum Specifies that the score calculation should sum the product of SNP effect sizes and their genotype counts target EUR_1kg.hm3.only.csx Specifies the genotype data file for the target sample binary-target F Indicates that the phenotype of interest is not binary (e.g., quantitative trait), F for no pheno sbp_eur_1kg.sim_pheno Specifies the file containing phenotype data pheno-col pheno100 Column name in the phenotype file that contains the phenotype data to be used for PRS calculation cov* EUR.covariate Specifies the file containing covariate data for the analysis base-maf* MAF:0.01 Filter out SNPs with MAF < 0.01 in the GWAS summary statistics, using information in the MAF column base-info* INFO:0.8 Filter out SNPs with INFO < 0.8 in the GWAS summary statistics, using information in the INFO column stat* OR Column name for the odds ratio (effect size) in the GWAS summary statistics or* - Inform PRSice that the effect size is an Odd Ratio thread 8 Specifies the number of computing threads to use for the analysis out SBP_trial.eur.eur Specifies the name for the output files generated by PRSice *Note: These parameters are not used within this exercise but will likely be included when conducting your own analyses. QUESTIONS Move to the out directory you created earlier: cd out Look at the files produced following your first analyis within the directory: ls -l How many files have been generated from this code and what does each file show you? This code generates six files. Each files serves a different purpose in the analysis and interpretation of derived PRS. These are outlined below: 1. **.summary**: Provides a high-level summary of the best-performing PRS analysis result, allowing for a quick assessment of the PRS model's performance. 2. **.prsice**: Provides the PRS analysis results across all p-value thresholds. This file will be the input for the bar plot that assesses the R2 at each p-value threshold. 3. **.log**: Useful for debugging and detailed tracking of the computational steps undertaken during the PRS calculation. 4. **.best**: Provides details of which individuals (IID) are included in the PRS regression analysis that assesses the association between the genotype and phenotype, and provides their individual PRS score 5. **.png (Bar plot)**: Assist in visually assessing the performance of PRS calculated at each p-value threshold, with the most predictive bar being the highest R 2 and thus the tallest bar). The y axis shows the phenotypic variance explained (R 2 ), the x-axis the various p-value thresholds, and the text above each bar is the p-value showing the significance of the association between the PRS and phenotype. The colours of the bars (from red to blue) indicate the strength of the association with red indicating lower p-values (greater significance). 6. **.png (High resolution plot)**: Assist in visually assessing the performance of PRS calculated at each p-value threshold. However, this high-resolution plot uses a negative logarithmic scale on the Y-axis to show the performance of different combinations of SNPS in predicting the trait as measured by their p-values. Lower p-values indicate better performance and appear higher on the Y-axis. Examine the plot indicating the R 2 at each p-value threshold: xdg-open SBP.eur.eur_BARPLOT_2024-06-12.png Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 0.00205005. What does \"best-fit\" mean? \"Best-fit\" refers to the p-value threshold at which the PRS accounts for the highest proportion of variance in the phenotype (R 2 ) compared to other thresholds tested. Why does this matter? Choosing the optimal p-value threshold is crucial because it affects the sensitivity and specificity of the PRS. The optimal threshold balances including informative SNPs and excluding noise from less relevant variants. A threshold that is too lenient (high p-value from GWAS association test) might include too many SNPs, adding noise and possibly diluting the predictive power of the score. Conversely, a threshold that is too stringent (low p-value) might exclude potentially informative SNPs, reducing the ability of the PRS to capture the genetic architecture of the trait. Which file provides a summary of the \"best-fit\" PRS? SBP.eur.eur.summary View this summary output file: cat /home/manager/data/Data_Day4/data/out/SBP.eur.eur.summary How much phenotypic variation does the \"best-fit\" PRS explain? What does this mean in very simple terms? R 2 = 0.0829 (8.2%). This R 2 value means that out of the total variability observed in the trait across the population (under study), 8.2% of the variation can be attributed to the genetic variants included in this PRS. What is the significance of the association (p-value) between the \"best-fit\" PRS and trait? The p-value is 1.72126e-11. A p-value below 0.05 indicates statistically significant evidence that the PRS at this threshold explains phenotypic variance and captures genuine genetic associations with the phenotype (i.e. not by chance). How many SNPs are included in the \"best-fit\" PRS? Number of SNPs = 389. Scenario 2: Predicting from AFR training to AFR target data: Return to the data directory: cd /home/manager/data/Data_Day4/data Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno50 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.afr.afr View the output file: cat /home/manager/data/Data_Day4/data/out/SBP.afr.afr.summary QUESTIONS Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 5e-08. How many SNPs are included in the \"best-fit\" PRS explain? Number of SNPs = 96. How much phenotypic variation does the \"best-fit\" PRS explain? R 2 = 0.0082124 (0.8%). Scenario 3: Predicting from EUR training to AFR target data Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno50 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.eur.afr View the output file: cat /home/manager/data/Data_Day4/data/out/SBP.eur.afr.summary QUESTIONS Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 0.00815005. How many SNPs are included in the \"best-fit\" PRS explain? Number of SNPs = 1192. How much phenotypic variation does the \"best-fit\" PRS explain? R 2 = 0.0160098 (1.6%). Exercise 2 Visualising and comparing R 2 In this exercise, we will analyse and compare the phenotypic variance explained (R 2 ) by PRS across different combinations of base and target ancestries. We will use R for visualisation. Open a new terminal and open R Open a new tab in the terminal ( plus icon in the top left corner ) In this new terminal window, make sure you are in the 'out' directory: cd /home/manager/data/Data_Day4/data/out/ Now open R: R Once in R, combine the summary files and visualise the performance of each PRS: # Load necessary libraries library ( ggplot2 ) library ( RColorBrewer ) # Create a function to read the files and add ancestry information read_and_label <- function ( file, ancestry ) { data <- read.table ( file, header = TRUE, sep = \"\\t\" ) data $Ancestry <- ancestry return ( data ) } # Read each file with the corresponding ancestry information EUR_EUR <- read_and_label ( \"SBP.eur.eur.summary\" , \"EUR_EUR\" ) AFR_AFR <- read_and_label ( \"SBP.afr.afr.summary\" , \"AFR_AFR\" ) EUR_AFR <- read_and_label ( \"SBP.eur.afr.summary\" , \"EUR_AFR\" ) # Combine all data into one dataframe all_data <- rbind ( EUR_EUR, AFR_AFR, EUR_AFR ) # Create a bar graph with different colors for each ancestry png ( '/home/manager/data/Data_Day4/data/out/PRS_ancestry_analysis.png' , unit = 'px' , res =300 , width =3500 , height =4500) ancestry <- ggplot ( all_data, aes ( x = Ancestry, y = PRS.R2, fill = Ancestry )) + geom_bar ( stat = \"identity\" , position = \"dodge\" ) + labs ( title = \"R2 Values by Ancestry\" , x = \"Ancestry\" , y = \"R2 Value\" ) + theme_minimal () + scale_fill_brewer ( palette = \"Set3\" ) + theme ( plot.title = element_text ( hjust = 0 .5, size = 16 , face = \"bold\" ) , axis.title.x = element_text ( size = 14 , face = \"bold\" ) , axis.title.y = element_text ( size = 14 , face = \"bold\" ) , axis.text.x = element_text ( size = 12 , angle = 45 , hjust = 1) , axis.text.y = element_text ( size = 12) , legend.position = \"none\" ) print ( ancestry ) dev.off () Examine the bar plot indicating the R 2 for each base:target ancestry pair: xdg-open PRS_ancestry_analysis.png QUESTIONS Which base:target pair has the highest phenotypic variance explained? EUR:EUR. Which base:target pair has the lowest phenotypic variance explained? AFR:AFR. Explain the results? Are they as expected? THINK - PAIR - SHARE \u203c\ufe0f Note that all target phenotype data in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Top","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#advanced-polygenic-risk-score-analyses","text":"","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#day-3-polygenic-risk-score-analyses-workshop-2024","text":"","title":"Day 3 - Polygenic Risk Score Analyses Workshop 2024"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#table-of-contents","text":"Key Learning Outcomes Base and Target datasets Downloading Datasets Method for Calculating PRS Exercise 1 Estimating R 2 Exercise 2 Visualising and comparing R 2","title":"Table of Contents"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#day-3a-practical","text":"","title":"Day 3a practical"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: 1. Compute and analyse ancestry-matched and unmatched PRS using PRSice-2. 2. Understand and interpret the results from PRSise-2 derived scores. 3. Understand and identify the impact of ancestry on the predictive utility of PRS. 4. Understand and identify the impact of sample size on the predictive utility of PRS. 5. Understand the challenges and limitations of applying PRS in populations with diverse genetic backgrounds.","title":"Key Learning Outcomes"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#base-and-target-datasets","text":"In this practical, we will compute a PRS for systolic blood pressure (SBP) and assess it performance across European and African ancestry datasets to clearly illustrate the portability problem. We will assess the predictive utility of 3 scores : ANCESTRY-MATCHED 1. EUR base - EUR target: Utilise European summary statistics as the training data and individual-level genotyped data from Europeans as the target dataset. 2. AFR base - AFR target: Utilise African summary statistics as the training data and individual-level genotyped data from Africans as the target dataset. ANCESTRY-UNMATCHED EUR base - AFR target: Utilise European summary statistics as the training data and individual-level genotyped data from Africans as the target dataset. Please note that the sample sizes of the individual-level target data are as follows: Europeans (n = ~500) and Africans (n = ~650). Note: This is simulated data with no real-life biological meaning or implication. Dataset Source Description Base dataset (EUR, AFR) simulated GWAS summary stats of SBP Target dataset (EUR, AFR) simulated EUR (n = ~500), AFR (n = ~650)","title":"Base and Target datasets"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#downloading-datasets","text":"All required software for this practical is found in the /home/manager/data/Data_Day4/software directory. \ud83d\udee0\ufe0f: Software - PRSice.R - PRSice_linux - plink_linux All required data for this practical is found in the /home/manager/data/Data_Day4/data directory. The relevant data that you should see there at the start of the practical are as follows: \ud83d\udcc2: Base_Data (summary statistics) - AFR-SBP-simulated.sumstats.prscsx - EUR-SBP-simulated.sumstats.prscsx \ud83d\udcc2: Target_Data - AFR_1kg.hm3.only.csx (.bed, .bim, .fam) - EUR_1kg.hm3.only.csx (.bed, .bim, .fam) - sbp.afr.1kg.sim_pheno - sbp.eur.1kg.sim_pheno \ud83d\udcc1: Reference files - 1kg.afr.dbSNP153.hg38.bed - 1kg.afr.dbSNP153.hg38.bim - 1kg.afr.dbSNP153.hg38.fam - 1kg.eur.dbSNP153.hg38.bed - 1kg.eur.dbSNP153.hg38.bim - 1kg.eur.dbSNP153.hg38.fam","title":"Downloading Datasets"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#method-for-calculating-prs","text":"For this practical we will use PRSice-2. PRSice-2 is one of the dedicated PRS calculation and analysis programs that makes use of a sequence of PLINK functions. The tools utilises the standard clumping and thresholding (C+T) approach.","title":"Method for calculating PRS"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#exercise-1-estimating-r2","text":"","title":"Exercise 1 Estimating R2"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#code","text":"Open the terminal and move to the data directory for this practical: cd /home/manager/data/Data_Day4/data Create the output directory - \"out\": mkdir out Look at the data files within the directory: ls -l Now, calculate PRS using PRSice 2","title":"Code"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#scenario-1-predicting-from-eur-training-to-eur-target-data","text":"Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.eur.eur","title":"Scenario 1: Predicting from EUR training to EUR target data:"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#key-code-parameters","text":"The parameters listed in this table remain consistent across various scenarios, but the specific values may change based on the dataset and analysis scenario. For illustrative purposes, this table uses the first scenario, EUR base and EUR target population: Click to view the parameters table Parameter Value Description prsice PRSice_xxx Informs PRSice.R that the location of the PRSice binary, xxx is the operating system (mac or linux) base EUR-SBP-simulated.sumstats.prscsx Specifies the GWAS summary statistics file for input A1 A1 Column name for the effect allele in the GWAS summary statistics p value P Column name for the p-values of SNPs in the GWAS summary statistics no clump - Instructs PRSice to skip the clumping process, which is used to remove SNPs in linkage disequilibrium beta - Indicates that the effect sizes are given in beta coefficients (linear regression coefficients) snp SNP Column name for SNP identifiers in the GWAS summary statistics score sum Specifies that the score calculation should sum the product of SNP effect sizes and their genotype counts target EUR_1kg.hm3.only.csx Specifies the genotype data file for the target sample binary-target F Indicates that the phenotype of interest is not binary (e.g., quantitative trait), F for no pheno sbp_eur_1kg.sim_pheno Specifies the file containing phenotype data pheno-col pheno100 Column name in the phenotype file that contains the phenotype data to be used for PRS calculation cov* EUR.covariate Specifies the file containing covariate data for the analysis base-maf* MAF:0.01 Filter out SNPs with MAF < 0.01 in the GWAS summary statistics, using information in the MAF column base-info* INFO:0.8 Filter out SNPs with INFO < 0.8 in the GWAS summary statistics, using information in the INFO column stat* OR Column name for the odds ratio (effect size) in the GWAS summary statistics or* - Inform PRSice that the effect size is an Odd Ratio thread 8 Specifies the number of computing threads to use for the analysis out SBP_trial.eur.eur Specifies the name for the output files generated by PRSice *Note: These parameters are not used within this exercise but will likely be included when conducting your own analyses. QUESTIONS Move to the out directory you created earlier: cd out Look at the files produced following your first analyis within the directory: ls -l How many files have been generated from this code and what does each file show you? This code generates six files. Each files serves a different purpose in the analysis and interpretation of derived PRS. These are outlined below: 1. **.summary**: Provides a high-level summary of the best-performing PRS analysis result, allowing for a quick assessment of the PRS model's performance. 2. **.prsice**: Provides the PRS analysis results across all p-value thresholds. This file will be the input for the bar plot that assesses the R2 at each p-value threshold. 3. **.log**: Useful for debugging and detailed tracking of the computational steps undertaken during the PRS calculation. 4. **.best**: Provides details of which individuals (IID) are included in the PRS regression analysis that assesses the association between the genotype and phenotype, and provides their individual PRS score 5. **.png (Bar plot)**: Assist in visually assessing the performance of PRS calculated at each p-value threshold, with the most predictive bar being the highest R 2 and thus the tallest bar). The y axis shows the phenotypic variance explained (R 2 ), the x-axis the various p-value thresholds, and the text above each bar is the p-value showing the significance of the association between the PRS and phenotype. The colours of the bars (from red to blue) indicate the strength of the association with red indicating lower p-values (greater significance). 6. **.png (High resolution plot)**: Assist in visually assessing the performance of PRS calculated at each p-value threshold. However, this high-resolution plot uses a negative logarithmic scale on the Y-axis to show the performance of different combinations of SNPS in predicting the trait as measured by their p-values. Lower p-values indicate better performance and appear higher on the Y-axis. Examine the plot indicating the R 2 at each p-value threshold: xdg-open SBP.eur.eur_BARPLOT_2024-06-12.png Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 0.00205005. What does \"best-fit\" mean? \"Best-fit\" refers to the p-value threshold at which the PRS accounts for the highest proportion of variance in the phenotype (R 2 ) compared to other thresholds tested. Why does this matter? Choosing the optimal p-value threshold is crucial because it affects the sensitivity and specificity of the PRS. The optimal threshold balances including informative SNPs and excluding noise from less relevant variants. A threshold that is too lenient (high p-value from GWAS association test) might include too many SNPs, adding noise and possibly diluting the predictive power of the score. Conversely, a threshold that is too stringent (low p-value) might exclude potentially informative SNPs, reducing the ability of the PRS to capture the genetic architecture of the trait. Which file provides a summary of the \"best-fit\" PRS? SBP.eur.eur.summary View this summary output file: cat /home/manager/data/Data_Day4/data/out/SBP.eur.eur.summary How much phenotypic variation does the \"best-fit\" PRS explain? What does this mean in very simple terms? R 2 = 0.0829 (8.2%). This R 2 value means that out of the total variability observed in the trait across the population (under study), 8.2% of the variation can be attributed to the genetic variants included in this PRS. What is the significance of the association (p-value) between the \"best-fit\" PRS and trait? The p-value is 1.72126e-11. A p-value below 0.05 indicates statistically significant evidence that the PRS at this threshold explains phenotypic variance and captures genuine genetic associations with the phenotype (i.e. not by chance). How many SNPs are included in the \"best-fit\" PRS? Number of SNPs = 389.","title":"Key code parameters"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#scenario-2-predicting-from-afr-training-to-afr-target-data","text":"Return to the data directory: cd /home/manager/data/Data_Day4/data Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno50 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.afr.afr View the output file: cat /home/manager/data/Data_Day4/data/out/SBP.afr.afr.summary QUESTIONS Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 5e-08. How many SNPs are included in the \"best-fit\" PRS explain? Number of SNPs = 96. How much phenotypic variation does the \"best-fit\" PRS explain? R 2 = 0.0082124 (0.8%).","title":"Scenario 2: Predicting from AFR training to AFR target data:"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#scenario-3-predicting-from-eur-training-to-afr-target-data","text":"Rscript /home/manager/PRSice_linux/PRSice.R \\ --prsice /home/manager/PRSice_linux/PRSice \\ --base /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno50 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/data/out/SBP.eur.afr View the output file: cat /home/manager/data/Data_Day4/data/out/SBP.eur.afr.summary QUESTIONS Which p-value threshold generates the \"best-fit\" PRS? P-value threshold of 0.00815005. How many SNPs are included in the \"best-fit\" PRS explain? Number of SNPs = 1192. How much phenotypic variation does the \"best-fit\" PRS explain? R 2 = 0.0160098 (1.6%).","title":"Scenario 3: Predicting from EUR training to AFR target data"},{"location":"tmp2/practical_docs_hidden/Day3a.docx/#exercise-2-visualising-and-comparing-r2","text":"In this exercise, we will analyse and compare the phenotypic variance explained (R 2 ) by PRS across different combinations of base and target ancestries. We will use R for visualisation. Open a new terminal and open R Open a new tab in the terminal ( plus icon in the top left corner ) In this new terminal window, make sure you are in the 'out' directory: cd /home/manager/data/Data_Day4/data/out/ Now open R: R Once in R, combine the summary files and visualise the performance of each PRS: # Load necessary libraries library ( ggplot2 ) library ( RColorBrewer ) # Create a function to read the files and add ancestry information read_and_label <- function ( file, ancestry ) { data <- read.table ( file, header = TRUE, sep = \"\\t\" ) data $Ancestry <- ancestry return ( data ) } # Read each file with the corresponding ancestry information EUR_EUR <- read_and_label ( \"SBP.eur.eur.summary\" , \"EUR_EUR\" ) AFR_AFR <- read_and_label ( \"SBP.afr.afr.summary\" , \"AFR_AFR\" ) EUR_AFR <- read_and_label ( \"SBP.eur.afr.summary\" , \"EUR_AFR\" ) # Combine all data into one dataframe all_data <- rbind ( EUR_EUR, AFR_AFR, EUR_AFR ) # Create a bar graph with different colors for each ancestry png ( '/home/manager/data/Data_Day4/data/out/PRS_ancestry_analysis.png' , unit = 'px' , res =300 , width =3500 , height =4500) ancestry <- ggplot ( all_data, aes ( x = Ancestry, y = PRS.R2, fill = Ancestry )) + geom_bar ( stat = \"identity\" , position = \"dodge\" ) + labs ( title = \"R2 Values by Ancestry\" , x = \"Ancestry\" , y = \"R2 Value\" ) + theme_minimal () + scale_fill_brewer ( palette = \"Set3\" ) + theme ( plot.title = element_text ( hjust = 0 .5, size = 16 , face = \"bold\" ) , axis.title.x = element_text ( size = 14 , face = \"bold\" ) , axis.title.y = element_text ( size = 14 , face = \"bold\" ) , axis.text.x = element_text ( size = 12 , angle = 45 , hjust = 1) , axis.text.y = element_text ( size = 12) , legend.position = \"none\" ) print ( ancestry ) dev.off () Examine the bar plot indicating the R 2 for each base:target ancestry pair: xdg-open PRS_ancestry_analysis.png QUESTIONS Which base:target pair has the highest phenotypic variance explained? EUR:EUR. Which base:target pair has the lowest phenotypic variance explained? AFR:AFR. Explain the results? Are they as expected? THINK - PAIR - SHARE \u203c\ufe0f Note that all target phenotype data in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Top","title":"Exercise 2 Visualising and comparing R2"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/","text":"Day 3b practical We need to move into the directory you will be working in; cd ~/data/Data_Day4/data Introduction to Cross-Ancestry PRS computation Before starting the practical, the following commands will need to be run from within your virtual machine. These commands set up an 'environment' that allows you to work outside the virtual machine, which has memory restrictions. Set up the environment using conda: conda create -n \"PRScsx\" python =3 .7 conda activate PRScsx pip install scipy pip install h5py The aim of this practical is to provide you with a basic understanding and some experience of running PRS-CSx software. After completing this practical, you should: Be able to perform cross-population analyses. Be familiar with running cross-ancestry PRS analyses using PRS-CSx. Understand how to evaluate linear models using Akaike\u2019s Information Criterion. 1. The 1000 Genomes datasets The data we will be working with comes from the 1000 Genomes Project reference panel. The data relates to individuals from 26 different source populations around the world. For simplicity, the populations have been collapsed into 5 broader continental super-populations: East Asian, European, South Asian, Amerindian, African ((EAS, EUR, SAS, EUR and AFR)). The scripts used to download and process the 1000Genomes data for the purposes of this course will be provided in the course appendix at the end of this week. 2. Cross-population allele frequency Genetic variation is conveyed using allelic frequencies. Allele frequency is shaped by evolutionary forces and drift. Here we compare profiles of allele frequency across the five ancestral populations. Global differences in allelic frequency has important implications for the portability of PRS across populations. Using plink it is possible to generate allele frequency statistics for each SNP, across populations, using the annotations provided in the file pop_info.pheno . In /home/manager/data/Data_Day4 : cd ../ ./software/plink_linux --bfile ./data/chr1-22 --freq --within ./data/pop_info.pheno Population-stratified allele frequencies are reported in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: AFR grep -F 'AFR' plink.frq.strat | wc -l From there we can print the number of SNPs with minor allele frequencies greater than 0 (and are hence potentially available for genomic analyes). grep -F 'AFR' plink.frq.strat | awk '$6 >0' | wc -l EUR grep -F 'EUR' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in EUR. grep -F 'EUR' plink.frq.strat | awk '$6 >0' | wc -l EAS grep -F 'EAS' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in EAS. grep -F 'EAS' plink.frq.strat | awk '$6 >0' | wc -l SAS grep -F 'SAS' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in SAS. grep -F 'SAS' plink.frq.strat | awk '$6 >0' | wc -l AFR grep -F 'AFR' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in AFR. grep -F 'AFR' plink.frq.strat | awk '$6 >0' | wc -l Questions (i) Which population contains the most SNPs? (ii) What is the significance of the observed population order? 3. Distribution of allele frequencies In this exercise, we will analyse and compare the distribution of allele frequencies across different ancestries. We will use R for visualisation. Open a new terminal and open R Open a new tab in the terminal ( plus icon in the top left corner ) In this new terminal window, make sure you are in the correct directory: cd /home/manager/data/Data_Day4/out/ Now open R: R Generate the plot: # Install the necessary libraries install.packages ( \"dplyr\" ) install.packages ( \"ggplot2\" ) # Load necessary libraries library ( dplyr ) library ( ggplot2 ) # Create a function to read the files and add ancestry information freq <-read.table ( \"~/data/Data_Day4/plink.frq.strat\" , header = T ) plotDat <- freq %>% mutate ( AlleleFrequency = cut ( MAF, seq (0 , 1 , 0 .25 ))) %>% group_by ( AlleleFrequency, CLST ) %>% summarise ( FractionOfSNPs = n () /nrow ( freq ) * 100) # Create a bar graph png ( '/home/manager/data/Data_Day4/out/MAF_ancestry_analysis.png' , unit = 'px' , res =300 , width =3500 , height =4500) maf_ancestry <- ggplot ( na.omit ( plotDat ) , aes ( AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST )) + geom_line () + scale_y_continuous ( limits = c (0 , 12)) + ggtitle ( \"Distribution of allele frequency across genome\" ) print ( maf_ancestry ) dev.off () Examine the plot the MAF across each ancestry: # This does not work when you are in R, ensure you out of R before running: xdg-open MAF_ancestry_analysis.png Questions (i) Which population has the most SNPs? (ii) What is the significance of the observed population ordering? (iii) What is the reason behind these two features? Introduction to PRS-CSx 5. Background to PRS-CSX PRS-CSx is a Python based command line tool that integrates GWAS summary statistics and LD reference data from multiple populations to estimate population-specific PRS. PRS-CSx applies a Bayesian model with a continuous shrinkage prior to SNP effects genome-wide. Sparseness of the genetic architecture across populations is controlled by a parameter phi. For a given value of phi, PRS-CSx uses Markov chain Monte Carlo to sample from the posterior of SNP effects from which the mean SNP effects are calculated and used in the PRS. Step 1: Set up environment First change to the working directory with the data for this practical cd /home/manager/data/Data_Day4/data Make a directory called hm3_by_ancestry within the data folder, and move a folder back out of the data folder mkdir hm3_by_ancestry cd .. AFR for chr in {21..22}; do \\ /home/manager/data/Data_Day4/software/plink_linux \\ --bfile /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --chr $chr \\ --make-bed \\ --out /home/manager/data/Data_Day4/data/hm3_by_ancestry/AFR_1kg.hm3.chr${chr}_only.csx; done EUR for chr in {21..22}; do \\ /home/manager/data/Data_Day4/software/plink_linux \\ --bfile /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --chr $chr \\ --make-bed \\ --out /home/manager/data/Data_Day4/data/hm3_by_ancestry/EUR_1kg.hm3.chr${chr}_only.csx; done Set up the necessary environment variables for threading and verify they are set correctly. export N_THREADS=2 export MKL_NUM_THREADS=$N_THREADS export NUMEXPR_NUM_THREADS=$N_THREADS export OMP_NUM_THREADS=$N_THREADS Verify the variables are set echo $N_THREADS echo $MKL_NUM_THREADS echo $NUMEXPR_NUM_THREADS echo $OMP_NUM_THREADS Step 2: Run CSX. Derive new SNPs weights trained on European and African summary stats Generate job file containing the threaded PRScsx commands. First, to minimize computational resources and time, we should create a script to run the tasks in parallel. Make a script called create_multithread.sh nano create_multithread.sh Then copy and paste the code below into that script. After save, then close the script ctrl + x #!/bin/bash # Create the script file SCRIPT_FILE = \"multithread.sh\" # Write the header of the script file echo \"#!/bin/bash\" > $SCRIPT_FILE for chr in {21 ..22 } ; do echo \"python3 /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir=/home/manager/data/Data_Day4/reference/csx \\ --bim_prefix=/home/manager/data/Data_Day4/data/hm3_by_ancestry/AFR_1kg.hm3.chr ${ chr } _only.csx \\ --sst_file=/home/manager/data/Data_Day4/data/3b/data/sumstats_by_chr/EUR-SBP-simulated.sumstats.chr ${ chr } ,/home/manager/data/Data_Day4/data/3b/data/sumstats_by_chr/AFR-SBP-simulated.sumstats.chr ${ chr } \\ --n_gwas=25732,4855 \\ --chrom= ${ chr } \\ --n_iter=1000 \\ --n_burnin=500 \\ --thin=5 \\ --pop=EUR,AFR \\ --phi=1e-4 \\ --out_dir=/home/manager/data/Data_Day4/out/csx \\ --out_name=afr.target_chr ${ chr } .csx\" >> $SCRIPT_FILE done Run: Ctrl + O, followed by Enter ' to save ' Run: Ctrl + X, to Exit You will need to change permission for the script to be able to execute chmod +x create_multithread.sh Run the builder ./create_multithread.sh To be able to run the next command you first install 'parallel' sudo apt install parallel Run the Job File with GNU Parallel: (May take a while) parallel --verbose --jobs $N_THREADS < multithread.sh Step 3: Combine CSX-derived SNP weights across chromosomes (Currently Excludes Chromosome 3) Load R and the necessary library R Call in the package library(dplyr) Define the path to the directory containing the PRS-CSX output files path <- \"/home/manager/data/Data_Day4/out/csx\" Define the ancestry you want to combine (\"EUR\" or \"AFR\") ancestry <- \"EUR\" Initialize an empty data frame to store the combined data combined_data <- data.frame() Loop through chromosomes 21 to 22, (currently excluding chromosome 3) for (chr in setdiff(21:22, 3)) { # Construct the file name file_name <- paste0(\"afr.target_chr\", chr, \".csx_\", ancestry, \"_pst__a1_b0.5_phi1e-04_chr\", chr, \".txt\") file_path <- file.path(path, file_name) # Check if file exists before reading if (file.exists(file_path)) { # Read the data from the file data <- read.table(file_path, header = FALSE, sep = \"\\t\", col.names = c(\"CHR\", \"rsid\", \"pos\", \"ref\", \"alt\", \"beta\")) # Combine the data combined_data <- rbind(combined_data, data) } else { warning(paste(\"File not found:\", file_path)) } } Write the combined data to a new file output_file <- file.path(path, paste0(\"combined_\", ancestry, \"_pst_.txt\")) write.table(combined_data, output_file, sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE) Task: Replace 'ancestry <- \"EUR\" ' with 'ancestry <- \"AFR\" ' and repeat the subsequent steps shown above Step 4: Merge genotype-phenotype data Prepare data The data is slow to merge unless you split the input bim file into just chr21 and chr22 (Q- why are those faster?) cd /home/manager/data/Data_Day4/data/3b/data/ plink --bfile AFR_1kg.hm3.only.csx --chr 21 22 --make-bed --out AFR_1kg.hm3.only.csx_21_22 Start R with sudo rights to allow you to install sudo R # Load libraries. For any unavailable package, install it with **install.packages(\"_package_name\")** install.packages(\"BiocManager\") BiocManager::install(\"snpStats\") library(data.table) library(ggplot2) library(snpStats) # Define the path to the directory containing the PLINK files and phenotypic data plink_path <- \"/home/manager/data/Data_Day4/data/3b/data/\" # Read PLINK files and phenotype data into R bim_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.bim\") fam_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.fam\") bed_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.bed\") pheno_file <- file.path(plink_path, \"sbp_afr_1kg.sim_pheno\") # Read the genotype data using snpStats geno_data <- read.plink(bed_file, bim_file, fam_file) # Extract SNP IDs from geno_data$map$snp.name snp_ids <- geno_data$map$snp.name if (is.null(snp_ids) || !is.character(snp_ids)) { stop(\"SNP IDs are missing or not in the correct format.\") } # Convert the genotype data to a matrix and then to a data.table geno_matrix <- as(geno_data$genotypes, \"matrix\") geno_df <- data.table(geno_matrix) setnames(geno_df, snp_ids) # Add IID column from the fam file geno_df[, IID := geno_data$fam$member] # Read the phenotypic data** pheno_data <- fread(pheno_file, sep = \" \", header = TRUE) Merge phenotype and genotype data # Do merge combined_data <- merge(pheno_data, geno_df, by = \"IID\") # Keep only genotype columns geno <- combined_data[, !names(combined_data) %in% c(\"FID\", \"IID\", \"pheno100\", \"pheno20\", \"pheno33\", \"pheno10\"), with = FALSE] phen <- combined_data$pheno100 # Convert geno to numeric matrix** geno <- as.matrix(geno) mode(geno) <- \"numeric\" # Convert phen to vector phen <- as.vector(phen) Step 5: Split data into validation and test sets Specify Proportion # Here we specify that 40% of all IDs will be used to construct the validation group set.seed(154) vali_proportion <- 0.4 vali_size <- round(nrow(geno) * vali_proportion) vali_indices <- sample(1:nrow(geno), vali_size, replace = FALSE) test_indices <- setdiff(1:nrow(geno), vali_indices) Subsetting of individuals X_vali <- geno[vali_indices, , drop=FALSE] y_vali <- phen[vali_indices] X_test <- geno[test_indices, , drop=FALSE] y_test <- phen[test_indices] Step 6: Prepare the regression model input using the CSX-derived AFR and EUR weights # Read the merged CSX output files AFR_betas <- fread(file.path(\"/home/manager/data/Data_Day4/out/csx/combined_AFR_pst_eff.txt\"), sep = \"\\t\", header = TRUE) EUR_betas <- fread(file.path(\"/home/manager/data/Data_Day4/out/csx/combined_EUR_pst_eff.txt\"), sep = \"\\t\", header = TRUE) # Assuming the beta files have columns: \"CHR\", \"rsid\", \"pos\", \"ref\", \"alt\", \"beta\" overlap_prs <- merge(AFR_betas, EUR_betas, by = \"rsid\", suffixes = c(\"_afr\", \"_eur\")) # Filter overlap_prs to include only SNPs present in X_vali overlap_prs <- overlap_prs[rsid %in% colnames(X_vali)] # Ensure that X_vali and X_test only contain SNPs present in W_afr and W_eur common_snps <- intersect(colnames(X_vali), overlap_prs$rsid) X_vali <- X_vali[, common_snps, drop=FALSE] X_test <- X_test[, common_snps, drop=FALSE] # Reorder the columns of X_vali and X_test to match the order of SNPs in overlap_prs X_vali <- X_vali[, match(overlap_prs$rsid, colnames(X_vali)), drop=FALSE] X_test <- X_test[, match(overlap_prs$rsid, colnames(X_test)), drop=FALSE] # Extract the overlapping rsid and their corresponding betas W_afr <- overlap_prs$beta_afr W_eur <- overlap_prs$beta_eur # Convert W_afr and W_eur to numeric vectors W_afr <- as.numeric(W_afr) W_eur <- as.numeric(W_eur) Step 7: Prepare the variant weights matrices as vectors # Pre-check the alignment between the different objects if (ncol(X_vali) != length(W_afr) || ncol(X_vali) != length(W_eur)) { stop(\"Dimensions of X_vali and W_afr/W_eur do not match.\") } # In the validation sample: # (i) Compute XWafr_vali XWafr_vali <- X_vali %*% W_afr # (ii) Convert XWafr_vali to have zero mean and unit variance XWafr_vali_z <- scale(XWafr_vali) # (iii) Compute XWeur_vali XWeur_vali <- X_vali %*% W_eur # (iv) Convert XWeur_vali to have zero mean and unit variance XWeur_vali_z <- scale(XWeur_vali) # (v) Combine the normalized matrices XW_vali <- cbind(XWafr_vali_z, XWeur_vali_z) # Fit the model model <- lm(scale(y_vali) ~ XWafr_vali_z + XWeur_vali_z - 1) # '- 1' removes the intercept # Obtain the regression parameters a_hat <- coef(model)[1] b_hat <- coef(model)[2] print(paste(\"a_hat =\", a_hat)) print(paste(\"b_hat =\", b_hat)) Step 8: Predict phenotype on validation and test dataset Generate a linear combination of AFR and EUR PRSs for each individual # Each ancestry component is weighted by the regression coicient of that ancestry, in the preceding step y_hat_vali <- a_hat * XWafr_vali_z + b_hat * XWeur_vali_z # In the test sample: # Compute XWafr_test and XWeur_test XWafr_test <- X_test %*% W_afr XWafr_test_z <- scale(XWafr_test) XWeur_test <- X_test %*% W_eur XWeur_test_z <- scale(XWeur_test) # y_hat in the test sample y_hat <- a_hat * XWafr_test_z + b_hat * XWeur_test_z Step 9: Plot phenotype distributions of validation and test data: Check that both distributions are approximately normal library(ggplot2) # Create data frames for validation and test sets vali_data <- data.frame(trait = y_vali, dataset = \"Validation\") test_data <- data.frame(trait = y_test, dataset = \"Test\") # Combine both data frames combined_data <- rbind(vali_data, test_data) # Plot the distributions ggplot(combined_data, aes(x = trait, fill = dataset)) + geom_density(alpha = 0.5) + labs(title = \"Trait Distributions for Validation and Test Sets\", x = \"Trait Value\", y = \"Density\") + theme_minimal() Step 10: Plot true values against predicted values The next steps use standard normal phenotype data to reduce scale differences between PRS and trait values min_true <- min(min(y_vali), min(y_test)) max_true <- max(max(y_vali), max(y_test)) min_pred <- min(min(y_hat_vali), min(y_hat)) max_pred <- max(max(y_hat_vali), max(y_hat)) pdf(\"true_against_pred.pdf\", width = 10, height = 5) par(mfrow = c(1, 2)) plot(scale(y_vali), y_hat_vali, pch = 19, col = rgb(0, 0, 0, 0.5), xlab = 'True Values', ylab = 'Predicted Values', main = 'Validation Dataset') abline(0, 1, col = 'red', lty = 2) plot(scale(y_test), y_hat, pch = 19, col = rgb(0, 0, 0, 0.5), xlab = 'True Values', ylab = 'Predicted Values', main = 'Test Dataset') abline(0, 1, col = 'red', lty = 2) dev.off() Step 11: Calculate deviance-based R 2 # Calculate the deviance (SS_res) deviance <- sum((scale(y_test) - y_hat) ^ 2) print(paste(\"deviance =\", deviance)) # Calculate the mean of the scaled y_test y_test_mean <- mean(scale(y_test)) # Calculate the null deviance (SS_tot) deviance_null <- sum((scale(y_test) - y_test_mean)^ 2) print(paste(\"deviance_null =\", deviance_null)) # Calculate R2 R2 <- 1 - (deviance / deviance_null) print(paste(\"R2 =\", R2)) Results graph: pdf true against pred","title":"Day3b.docx"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#day-3b-practical","text":"We need to move into the directory you will be working in; cd ~/data/Data_Day4/data","title":"Day 3b practical"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#introduction-to-cross-ancestry-prs-computation","text":"Before starting the practical, the following commands will need to be run from within your virtual machine. These commands set up an 'environment' that allows you to work outside the virtual machine, which has memory restrictions. Set up the environment using conda: conda create -n \"PRScsx\" python =3 .7 conda activate PRScsx pip install scipy pip install h5py The aim of this practical is to provide you with a basic understanding and some experience of running PRS-CSx software. After completing this practical, you should: Be able to perform cross-population analyses. Be familiar with running cross-ancestry PRS analyses using PRS-CSx. Understand how to evaluate linear models using Akaike\u2019s Information Criterion.","title":"Introduction to Cross-Ancestry PRS computation"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#1-the-1000-genomes-datasets","text":"The data we will be working with comes from the 1000 Genomes Project reference panel. The data relates to individuals from 26 different source populations around the world. For simplicity, the populations have been collapsed into 5 broader continental super-populations: East Asian, European, South Asian, Amerindian, African ((EAS, EUR, SAS, EUR and AFR)). The scripts used to download and process the 1000Genomes data for the purposes of this course will be provided in the course appendix at the end of this week.","title":"1. The 1000 Genomes datasets"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#2-cross-population-allele-frequency","text":"Genetic variation is conveyed using allelic frequencies. Allele frequency is shaped by evolutionary forces and drift. Here we compare profiles of allele frequency across the five ancestral populations. Global differences in allelic frequency has important implications for the portability of PRS across populations. Using plink it is possible to generate allele frequency statistics for each SNP, across populations, using the annotations provided in the file pop_info.pheno . In /home/manager/data/Data_Day4 : cd ../ ./software/plink_linux --bfile ./data/chr1-22 --freq --within ./data/pop_info.pheno Population-stratified allele frequencies are reported in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: AFR grep -F 'AFR' plink.frq.strat | wc -l From there we can print the number of SNPs with minor allele frequencies greater than 0 (and are hence potentially available for genomic analyes). grep -F 'AFR' plink.frq.strat | awk '$6 >0' | wc -l EUR grep -F 'EUR' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in EUR. grep -F 'EUR' plink.frq.strat | awk '$6 >0' | wc -l EAS grep -F 'EAS' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in EAS. grep -F 'EAS' plink.frq.strat | awk '$6 >0' | wc -l SAS grep -F 'SAS' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in SAS. grep -F 'SAS' plink.frq.strat | awk '$6 >0' | wc -l AFR grep -F 'AFR' plink.frq.strat | wc -l Number of SNPs with MAF > 0 in AFR. grep -F 'AFR' plink.frq.strat | awk '$6 >0' | wc -l","title":"2. Cross-population allele frequency"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#questions","text":"","title":"Questions"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#i-which-population-contains-the-most-snps","text":"","title":"(i) Which population contains the most SNPs?"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#ii-what-is-the-significance-of-the-observed-population-order","text":"","title":"(ii) What  is the significance of the observed population order?"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#3-distribution-of-allele-frequencies","text":"In this exercise, we will analyse and compare the distribution of allele frequencies across different ancestries. We will use R for visualisation. Open a new terminal and open R Open a new tab in the terminal ( plus icon in the top left corner ) In this new terminal window, make sure you are in the correct directory: cd /home/manager/data/Data_Day4/out/ Now open R: R Generate the plot: # Install the necessary libraries install.packages ( \"dplyr\" ) install.packages ( \"ggplot2\" ) # Load necessary libraries library ( dplyr ) library ( ggplot2 ) # Create a function to read the files and add ancestry information freq <-read.table ( \"~/data/Data_Day4/plink.frq.strat\" , header = T ) plotDat <- freq %>% mutate ( AlleleFrequency = cut ( MAF, seq (0 , 1 , 0 .25 ))) %>% group_by ( AlleleFrequency, CLST ) %>% summarise ( FractionOfSNPs = n () /nrow ( freq ) * 100) # Create a bar graph png ( '/home/manager/data/Data_Day4/out/MAF_ancestry_analysis.png' , unit = 'px' , res =300 , width =3500 , height =4500) maf_ancestry <- ggplot ( na.omit ( plotDat ) , aes ( AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST )) + geom_line () + scale_y_continuous ( limits = c (0 , 12)) + ggtitle ( \"Distribution of allele frequency across genome\" ) print ( maf_ancestry ) dev.off () Examine the plot the MAF across each ancestry: # This does not work when you are in R, ensure you out of R before running: xdg-open MAF_ancestry_analysis.png","title":"3. Distribution of allele frequencies"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#questions_1","text":"","title":"Questions"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#i-which-population-has-the-most-snps","text":"","title":"(i) Which population has the most SNPs?"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#ii-what-is-the-significance-of-the-observed-population-ordering","text":"","title":"(ii) What  is the significance of the observed population ordering?"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#iii-what-is-the-reason-behind-these-two-features","text":"","title":"(iii) What is the reason behind these two features?"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#introduction-to-prs-csx","text":"","title":"Introduction to PRS-CSx"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#5-background-to-prs-csx","text":"PRS-CSx is a Python based command line tool that integrates GWAS summary statistics and LD reference data from multiple populations to estimate population-specific PRS. PRS-CSx applies a Bayesian model with a continuous shrinkage prior to SNP effects genome-wide. Sparseness of the genetic architecture across populations is controlled by a parameter phi. For a given value of phi, PRS-CSx uses Markov chain Monte Carlo to sample from the posterior of SNP effects from which the mean SNP effects are calculated and used in the PRS.","title":"5. Background to PRS-CSX"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-1-set-up-environment","text":"First change to the working directory with the data for this practical cd /home/manager/data/Data_Day4/data Make a directory called hm3_by_ancestry within the data folder, and move a folder back out of the data folder mkdir hm3_by_ancestry cd .. AFR for chr in {21..22}; do \\ /home/manager/data/Data_Day4/software/plink_linux \\ --bfile /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --chr $chr \\ --make-bed \\ --out /home/manager/data/Data_Day4/data/hm3_by_ancestry/AFR_1kg.hm3.chr${chr}_only.csx; done EUR for chr in {21..22}; do \\ /home/manager/data/Data_Day4/software/plink_linux \\ --bfile /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --chr $chr \\ --make-bed \\ --out /home/manager/data/Data_Day4/data/hm3_by_ancestry/EUR_1kg.hm3.chr${chr}_only.csx; done Set up the necessary environment variables for threading and verify they are set correctly. export N_THREADS=2 export MKL_NUM_THREADS=$N_THREADS export NUMEXPR_NUM_THREADS=$N_THREADS export OMP_NUM_THREADS=$N_THREADS Verify the variables are set echo $N_THREADS echo $MKL_NUM_THREADS echo $NUMEXPR_NUM_THREADS echo $OMP_NUM_THREADS","title":"Step 1: Set up environment"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-2-run-csx-derive-new-snps-weights-trained-on-european-and-african-summary-stats","text":"Generate job file containing the threaded PRScsx commands. First, to minimize computational resources and time, we should create a script to run the tasks in parallel. Make a script called create_multithread.sh nano create_multithread.sh Then copy and paste the code below into that script. After save, then close the script ctrl + x #!/bin/bash # Create the script file SCRIPT_FILE = \"multithread.sh\" # Write the header of the script file echo \"#!/bin/bash\" > $SCRIPT_FILE for chr in {21 ..22 } ; do echo \"python3 /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir=/home/manager/data/Data_Day4/reference/csx \\ --bim_prefix=/home/manager/data/Data_Day4/data/hm3_by_ancestry/AFR_1kg.hm3.chr ${ chr } _only.csx \\ --sst_file=/home/manager/data/Data_Day4/data/3b/data/sumstats_by_chr/EUR-SBP-simulated.sumstats.chr ${ chr } ,/home/manager/data/Data_Day4/data/3b/data/sumstats_by_chr/AFR-SBP-simulated.sumstats.chr ${ chr } \\ --n_gwas=25732,4855 \\ --chrom= ${ chr } \\ --n_iter=1000 \\ --n_burnin=500 \\ --thin=5 \\ --pop=EUR,AFR \\ --phi=1e-4 \\ --out_dir=/home/manager/data/Data_Day4/out/csx \\ --out_name=afr.target_chr ${ chr } .csx\" >> $SCRIPT_FILE done Run: Ctrl + O, followed by Enter ' to save ' Run: Ctrl + X, to Exit You will need to change permission for the script to be able to execute chmod +x create_multithread.sh Run the builder ./create_multithread.sh To be able to run the next command you first install 'parallel' sudo apt install parallel Run the Job File with GNU Parallel: (May take a while) parallel --verbose --jobs $N_THREADS < multithread.sh","title":"Step 2: Run CSX. Derive new SNPs weights trained on European and African summary stats"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-3-combine-csx-derived-snp-weights-across-chromosomes-currently-excludes-chromosome-3","text":"Load R and the necessary library R Call in the package library(dplyr) Define the path to the directory containing the PRS-CSX output files path <- \"/home/manager/data/Data_Day4/out/csx\" Define the ancestry you want to combine (\"EUR\" or \"AFR\") ancestry <- \"EUR\" Initialize an empty data frame to store the combined data combined_data <- data.frame() Loop through chromosomes 21 to 22, (currently excluding chromosome 3) for (chr in setdiff(21:22, 3)) { # Construct the file name file_name <- paste0(\"afr.target_chr\", chr, \".csx_\", ancestry, \"_pst__a1_b0.5_phi1e-04_chr\", chr, \".txt\") file_path <- file.path(path, file_name) # Check if file exists before reading if (file.exists(file_path)) { # Read the data from the file data <- read.table(file_path, header = FALSE, sep = \"\\t\", col.names = c(\"CHR\", \"rsid\", \"pos\", \"ref\", \"alt\", \"beta\")) # Combine the data combined_data <- rbind(combined_data, data) } else { warning(paste(\"File not found:\", file_path)) } } Write the combined data to a new file output_file <- file.path(path, paste0(\"combined_\", ancestry, \"_pst_.txt\")) write.table(combined_data, output_file, sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE)","title":"Step 3: Combine CSX-derived SNP weights across chromosomes (Currently Excludes Chromosome 3)"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#task-replace-ancestry-eur-with-ancestry-afr-and-repeat-the-subsequent-steps-shown-above","text":"","title":"Task: Replace 'ancestry &lt;- \"EUR\" ' with 'ancestry &lt;- \"AFR\" ' and repeat the subsequent steps shown above"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-4-merge-genotype-phenotype-data","text":"Prepare data The data is slow to merge unless you split the input bim file into just chr21 and chr22 (Q- why are those faster?) cd /home/manager/data/Data_Day4/data/3b/data/ plink --bfile AFR_1kg.hm3.only.csx --chr 21 22 --make-bed --out AFR_1kg.hm3.only.csx_21_22 Start R with sudo rights to allow you to install sudo R # Load libraries. For any unavailable package, install it with **install.packages(\"_package_name\")** install.packages(\"BiocManager\") BiocManager::install(\"snpStats\") library(data.table) library(ggplot2) library(snpStats) # Define the path to the directory containing the PLINK files and phenotypic data plink_path <- \"/home/manager/data/Data_Day4/data/3b/data/\" # Read PLINK files and phenotype data into R bim_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.bim\") fam_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.fam\") bed_file <- file.path(plink_path, \"AFR_1kg.hm3.only.csx_21_22.bed\") pheno_file <- file.path(plink_path, \"sbp_afr_1kg.sim_pheno\") # Read the genotype data using snpStats geno_data <- read.plink(bed_file, bim_file, fam_file) # Extract SNP IDs from geno_data$map$snp.name snp_ids <- geno_data$map$snp.name if (is.null(snp_ids) || !is.character(snp_ids)) { stop(\"SNP IDs are missing or not in the correct format.\") } # Convert the genotype data to a matrix and then to a data.table geno_matrix <- as(geno_data$genotypes, \"matrix\") geno_df <- data.table(geno_matrix) setnames(geno_df, snp_ids) # Add IID column from the fam file geno_df[, IID := geno_data$fam$member] # Read the phenotypic data** pheno_data <- fread(pheno_file, sep = \" \", header = TRUE) Merge phenotype and genotype data # Do merge combined_data <- merge(pheno_data, geno_df, by = \"IID\") # Keep only genotype columns geno <- combined_data[, !names(combined_data) %in% c(\"FID\", \"IID\", \"pheno100\", \"pheno20\", \"pheno33\", \"pheno10\"), with = FALSE] phen <- combined_data$pheno100 # Convert geno to numeric matrix** geno <- as.matrix(geno) mode(geno) <- \"numeric\" # Convert phen to vector phen <- as.vector(phen)","title":"Step 4: Merge genotype-phenotype data"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-5-split-data-into-validation-and-test-sets","text":"Specify Proportion # Here we specify that 40% of all IDs will be used to construct the validation group set.seed(154) vali_proportion <- 0.4 vali_size <- round(nrow(geno) * vali_proportion) vali_indices <- sample(1:nrow(geno), vali_size, replace = FALSE) test_indices <- setdiff(1:nrow(geno), vali_indices) Subsetting of individuals X_vali <- geno[vali_indices, , drop=FALSE] y_vali <- phen[vali_indices] X_test <- geno[test_indices, , drop=FALSE] y_test <- phen[test_indices]","title":"Step 5: Split data into validation and test sets"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-6-prepare-the-regression-model-input-using-the-csx-derived-afr-and-eur-weights","text":"# Read the merged CSX output files AFR_betas <- fread(file.path(\"/home/manager/data/Data_Day4/out/csx/combined_AFR_pst_eff.txt\"), sep = \"\\t\", header = TRUE) EUR_betas <- fread(file.path(\"/home/manager/data/Data_Day4/out/csx/combined_EUR_pst_eff.txt\"), sep = \"\\t\", header = TRUE) # Assuming the beta files have columns: \"CHR\", \"rsid\", \"pos\", \"ref\", \"alt\", \"beta\" overlap_prs <- merge(AFR_betas, EUR_betas, by = \"rsid\", suffixes = c(\"_afr\", \"_eur\")) # Filter overlap_prs to include only SNPs present in X_vali overlap_prs <- overlap_prs[rsid %in% colnames(X_vali)] # Ensure that X_vali and X_test only contain SNPs present in W_afr and W_eur common_snps <- intersect(colnames(X_vali), overlap_prs$rsid) X_vali <- X_vali[, common_snps, drop=FALSE] X_test <- X_test[, common_snps, drop=FALSE] # Reorder the columns of X_vali and X_test to match the order of SNPs in overlap_prs X_vali <- X_vali[, match(overlap_prs$rsid, colnames(X_vali)), drop=FALSE] X_test <- X_test[, match(overlap_prs$rsid, colnames(X_test)), drop=FALSE] # Extract the overlapping rsid and their corresponding betas W_afr <- overlap_prs$beta_afr W_eur <- overlap_prs$beta_eur # Convert W_afr and W_eur to numeric vectors W_afr <- as.numeric(W_afr) W_eur <- as.numeric(W_eur)","title":"Step 6: Prepare the regression model input using the CSX-derived AFR and EUR weights"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-7-prepare-the-variant-weights-matrices-as-vectors","text":"# Pre-check the alignment between the different objects if (ncol(X_vali) != length(W_afr) || ncol(X_vali) != length(W_eur)) { stop(\"Dimensions of X_vali and W_afr/W_eur do not match.\") } # In the validation sample: # (i) Compute XWafr_vali XWafr_vali <- X_vali %*% W_afr # (ii) Convert XWafr_vali to have zero mean and unit variance XWafr_vali_z <- scale(XWafr_vali) # (iii) Compute XWeur_vali XWeur_vali <- X_vali %*% W_eur # (iv) Convert XWeur_vali to have zero mean and unit variance XWeur_vali_z <- scale(XWeur_vali) # (v) Combine the normalized matrices XW_vali <- cbind(XWafr_vali_z, XWeur_vali_z) # Fit the model model <- lm(scale(y_vali) ~ XWafr_vali_z + XWeur_vali_z - 1) # '- 1' removes the intercept # Obtain the regression parameters a_hat <- coef(model)[1] b_hat <- coef(model)[2] print(paste(\"a_hat =\", a_hat)) print(paste(\"b_hat =\", b_hat))","title":"Step 7: Prepare the variant weights matrices as vectors"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-8-predict-phenotype-on-validation-and-test-dataset","text":"Generate a linear combination of AFR and EUR PRSs for each individual # Each ancestry component is weighted by the regression coicient of that ancestry, in the preceding step y_hat_vali <- a_hat * XWafr_vali_z + b_hat * XWeur_vali_z # In the test sample: # Compute XWafr_test and XWeur_test XWafr_test <- X_test %*% W_afr XWafr_test_z <- scale(XWafr_test) XWeur_test <- X_test %*% W_eur XWeur_test_z <- scale(XWeur_test) # y_hat in the test sample y_hat <- a_hat * XWafr_test_z + b_hat * XWeur_test_z","title":"Step 8: Predict phenotype on validation and test dataset"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-9-plot-phenotype-distributions-of-validation-and-test-data","text":"Check that both distributions are approximately normal library(ggplot2) # Create data frames for validation and test sets vali_data <- data.frame(trait = y_vali, dataset = \"Validation\") test_data <- data.frame(trait = y_test, dataset = \"Test\") # Combine both data frames combined_data <- rbind(vali_data, test_data) # Plot the distributions ggplot(combined_data, aes(x = trait, fill = dataset)) + geom_density(alpha = 0.5) + labs(title = \"Trait Distributions for Validation and Test Sets\", x = \"Trait Value\", y = \"Density\") + theme_minimal()","title":"Step 9: Plot phenotype distributions of validation and test data:"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#step-10-plot-true-values-against-predicted-values","text":"The next steps use standard normal phenotype data to reduce scale differences between PRS and trait values min_true <- min(min(y_vali), min(y_test)) max_true <- max(max(y_vali), max(y_test)) min_pred <- min(min(y_hat_vali), min(y_hat)) max_pred <- max(max(y_hat_vali), max(y_hat)) pdf(\"true_against_pred.pdf\", width = 10, height = 5) par(mfrow = c(1, 2)) plot(scale(y_vali), y_hat_vali, pch = 19, col = rgb(0, 0, 0, 0.5), xlab = 'True Values', ylab = 'Predicted Values', main = 'Validation Dataset') abline(0, 1, col = 'red', lty = 2) plot(scale(y_test), y_hat, pch = 19, col = rgb(0, 0, 0, 0.5), xlab = 'True Values', ylab = 'Predicted Values', main = 'Test Dataset') abline(0, 1, col = 'red', lty = 2) dev.off() Step 11: Calculate deviance-based R 2 # Calculate the deviance (SS_res) deviance <- sum((scale(y_test) - y_hat) ^ 2) print(paste(\"deviance =\", deviance)) # Calculate the mean of the scaled y_test y_test_mean <- mean(scale(y_test)) # Calculate the null deviance (SS_tot) deviance_null <- sum((scale(y_test) - y_test_mean)^ 2) print(paste(\"deviance_null =\", deviance_null)) # Calculate R2 R2 <- 1 - (deviance / deviance_null) print(paste(\"R2 =\", R2))","title":"Step 10: Plot true values against predicted values"},{"location":"tmp2/practical_docs_hidden/Day3b.docx/#results","text":"graph: pdf true against pred","title":"Results"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/","text":"BridgePRS Learning Objectives In the previous lecture we covered in detail the modelling used by BridgePRS. Here we will use the BridgePRS software to apply the method. The aim of this practical is to provide you with a basic understanding and some experience of running BridgePRS software. After completing this practical, you should: Be able to perform cross-population analyses. Set up the configuration files used as input by the software. Be familiar with running cross-ancestry PRS analyses using PRS-CSx. BridgePRS input data In the BridgePRS directory there is a data folder which we will use in this practical. View the data directory $ ls -l data total 5368 drwxr-xr-x 73 hoggac01 staff 2336 26 Jul 16:00 1000G_sample -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 afr.config -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 eas.config -rw-r--r-- 1 hoggac01 staff 410 12 Aug 14:35 eur.config drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_AFR drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_EAS drwxr-xr-x 5 hoggac01 staff 160 7 Aug 20:30 pop_EUR -rw-r--r-- 1 hoggac01 staff 200376 7 Aug 21:30 qc_snplist.txt The pop_* folders contain simulated genotype, phenotype and GWAS summary statistics representative of Europeans, East Asians and Africans for input to BridgePRS. Each pop_* folder is split into summary statistics, and individual level genotype and phenotype folders, e.g. $ ls -l data/pop_AFR/ total 0 drwxr-xr-x 68 hoggac01 staff 2176 14 Jul 17:22 genotypes drwxr-xr-x 4 hoggac01 staff 128 14 Jul 17:22 phenotypes drwxr-xr-x 68 hoggac01 staff 2176 12 Aug 11:02 sumstats Look at each directory e.g. ls pop_AFR/genotypes . There are two sets of summary statistics in each sumstats folder from the analysis of the same simulated continuos phenotype, the \"half\" files were generated using half the sample size. For computation speed the summary statistics only have a small subset of SNPs, 19k-20k genomewide zcat data/pop_EAS/sumstats/EAS.chr* | wc -l zcat data/pop_EUR/sumstats/EUR.chr* | wc -l zcat data/pop_AFR/sumstats/AFR.chr* | wc -l or on a Mac gzcat data/pop_EAS/sumstats/EAS.chr* | wc -l gzcat data/pop_EUR/sumstats/EUR.chr* | wc -l gzcat data/pop_AFR/sumstats/AFR.chr* | wc -l Results in these files are only shown for SNP with MAF>0. The SNPs are a subset of the HapMap panel, there seems to be a bias to polymorphoic EUR SNPs. Take a look a look at the files, e.g. zcat data/pop_AFR/sumstats/AFR.chr19.glm.linear.gz | head zcat data/pop_AFR/sumstats/AFR_half.chr19.glm.linear.gz | head again use gzcat on a Mac. In the OBS_CT column you'll see can that the \"_half\" summary statistics files have half the sample size, 10,000 compared to 20,000 for the EAS and AFR populations and 40,000 compared to 80,000 for the EUR population. The same SNPs are contained in each set of summary statistics. The phenotypes folders has two files: \"test\" and \"validation\" with IDs, the outcome phenotype and covariates. \"Test\" data is used to optimise the PRS and \"validation\" data is not used to estimate the PRS, it is just to assess model performance. The genotypes folders are in plink1.9 format and are split by chromosome. These folders contain the genetic data for individuals in the phenotypes folder. Test data will only be used for individuals with both genotype and phenotype information. Similarly model performance metrics will only use samples with both genotype and phenotype information, however, predictions are generated for all validation samples with genotype data. Passing arguments to run BridgePRS Example run of BridgePRS: ./bridgePRS pipeline go -o out/ --config_files data/eas.config data/eur.config --fst 0.11 --phenotype y --cores 4 --restart Arguments can be passed to BridgePRS on both the commandline and in config files. config files, used above, are a neat way to store population specific arguments, therefore for a standard two population analysis two config are required. By default the first config file is for the target population and the second is for the base population. The -o argument specifies the output folder. The --fst argument is used to specify a prior distribution used in the BridgePRS analysis and should be the Fst between the base and target populations used in the analysis. Our first analysis uses European base data and East Asian target data, the Fst between these populations is 0.11. The --phenotype argument specifies the column label of the phenotype in the test and validation files, e.g. EAS_valid.dat . The --cores argument specifies the number of cores used in the analysis. A full list of arguments that can be used on the commandline can be found here.... The *.config files .config files to tell the software where to find the required input files and the column headers of the summary statistics files, take a look, e.g. cat data/eas.config LD_PATH=1000G_sample LDPOP=EAS POP=EAS SUMSTATS_PREFIX=pop_EAS/sumstats/EAS.chr #SUMSTATS_PREFIX=pop_EAS/sumstats/EAS_half.chr SUMSTATS_SUFFIX=.glm.linear.gz GENOTYPE_PREFIX=pop_EAS/genotypes/chr PHENOTYPE_FILE=pop_EAS/phenotypes/EAS_test.dat VALIDATION_FILE=pop_EAS/phenotypes/EAS_valid.dat COVARIATES=PC1,PC2 SNP_FILE=qc_snplist.txt SSF-P=P SSF-SNPID=ID SSF-SE=SE SSF-SS=OBS_CT SSF-BETA=BETA SSF-REF=REF SSF-ALT=A1 SSF-MAF=A1_FREQ This config file conatins all possible arguments that can be used in config files. config files use the same argument names as the commandline arguments but in uppercase, and use \"=\" instead of a space between the argument name and the argument being passed. The POP argument simply labels the population used in this .config file for output. Estimating Linkage Dissequilibrium (LD) BridgePRS requires individual level genetic data in plink1.9 binary format to estimate linkage dissequilibrium (LD) in the populations which produced the GWAS summary statistics. The genotype test and validation data could be used, i.e. data in these folders pop_/genotypes/. If these data are small, less than 500 samples, or are not representative of the GWAS population we provide 1000 Genomes (1000G) data to estimate LD. Suitable 1000G data for this analysis is in the 1000G_sample folder for the small subset of SNPs used in these examples. The .config points to the folder with reference LD data by the LD_PATH argument in the config file. LD reference data is available for the five 1000G super population (abbreviations required to use in brackets): East Asian (EAS), South Asian (SAS), European (Eur), African (AFR) and American (AMR). For real data analyses 1000G reference data for larger subsets of SNPs can be downloaded here Can you work out what the other arguments are doing? BridgePRS output The main output is in the folder out/prs-combined_EAS-EUR/ . First view the output summary plot evince out/prs-combined_AFR-EUR/bridge.afr-eur.prs-combined.result.pdf on a Mac simply use open instead of evince . The barplot at the top which shows the varaince explained (R2) by the three PRS BridgePRS estimates and the variance explained by a weighted average of the three model. The weighted model is BridgePRS estimated \"best\" PRS This weighted combined PRS should be used. The three separate PRS estimated by BridgePRS are: * PRS using a prior effect-size distribution from the European model -- stage2 model * PRS using only the target (Non-European) dataset, stage 1 analysis - stage 1 model * PRS using both stage 1 and stage 2 results - stage1+2 model Each of these 3 models are given weights corresponding to how well they fit the test data. These weights are then used to combine the PRS to give the single weighted combined PRS. The models, stage1, stage2 and stage1+2, should not be used unless users have a strong prior belief that the models is better, i.e. Stage 2 model reflects the belief that the target population GWAS is only informative in conjugtion with the base population GWAS. Stage 1 model reflects the belief that the target population GWAS is informative and the base population GWAS gives no addition information. Stage 1+2 model reflects the belief both the base and target population GWAS contribute independent information. EAS_weighted_combined_preds.dat has PRS predictions for samples in the validation data using all four models: stage1, stage2, stage1+2 and weighted. EAS_weighted_combined_snp_weights.dat has the SNP weights for the combined to allow this model to be applied to other samples. Using BridgePRS without target summary statistics Often GWAS summary statistics are only available in one population. BridgePRS can use these summary statistics and optimise them to estimate a PRS for another target population given individual level from the target population. Here is an example ./bridgePRS prs-single run -o out_single/ --config_files data/eur_eas.config --phenotype y --cores 10 Look at data/eur_eas.config , the file uses EUR GWAS summary statistics and EAS test and validation data. Results of interest are written to the folder out_single/prs-single_EAS/quantify/ . Model performance is shown in the file EAS_quantify_var_explained.txt and plotted in .... See hpw these results compare with the previous analysis which included EAS GWAS summary statistics. cat out_single/prs-single_EAS/quantify/EAS_quantify_var_explained.txt cat out/prs-combined_EAS-EUR/EAS_weighted_combined_var_explained.txt This single summary statistic analysis is equilvant to the stage 2 analysis previously but with all the weight on the EUR prior. The superior performance of the previous stage 2 analysis shows how the EAS summary statistics have been incorporated to improve the PRS. Further analysis with BridgePRS African analysis Run BridgePRS again to estimate PRS in Africans using afr.config . Qustions? In addition to pointing to differnt input files what other difference is there between the EAS and AFR config files? How do the results for EAS and AFR compare? Analyses with other GWAS summary statistics For each population the config files contain commented out links to GWAS summary statistics of the same phenotype using half the same size: 40k for EUR and 10k for both EAS and AFR. Edit eas.config to use the EAS 10k GWAS summary statistics. To run the analysis write results to a new output directory e.g. out_half_target . Run the similar analysis for African samples by editing afr.config . Compare with previous results using the 10k EAS and EAS GWAS. Compare EAS and AFR results. Check you've run the analyses using the correct GWAS summary statistics, e.g. less less out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log less less out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log or grep Sumstats out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log grep Sumstats out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log If you have made a mistake, correct and run again using the --restart flag which deletes the previously genereated results. Qustions? How has using the less well powered EAS and AFR GWAS affected the predictive accuracy of the BridgePRS models? How do AFR and EUR results compare? Analyses with smaller EUR GWAS summary statistics Edit the config files again to run analyses using the 40k EUR GWAS (i.e. EUR_half ) and the 20k EAS and AFR GWAS and write to results to a new directory e.g. out_half_eur . Qustions?","title":"Day4a.docx"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#bridgeprs","text":"","title":"BridgePRS"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#learning-objectives","text":"In the previous lecture we covered in detail the modelling used by BridgePRS. Here we will use the BridgePRS software to apply the method. The aim of this practical is to provide you with a basic understanding and some experience of running BridgePRS software. After completing this practical, you should: Be able to perform cross-population analyses. Set up the configuration files used as input by the software. Be familiar with running cross-ancestry PRS analyses using PRS-CSx.","title":"Learning Objectives"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#bridgeprs-input-data","text":"In the BridgePRS directory there is a data folder which we will use in this practical. View the data directory $ ls -l data total 5368 drwxr-xr-x 73 hoggac01 staff 2336 26 Jul 16:00 1000G_sample -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 afr.config -rw-r--r-- 1 hoggac01 staff 469 12 Aug 14:35 eas.config -rw-r--r-- 1 hoggac01 staff 410 12 Aug 14:35 eur.config drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_AFR drwxr-xr-x 5 hoggac01 staff 160 14 Jul 17:22 pop_EAS drwxr-xr-x 5 hoggac01 staff 160 7 Aug 20:30 pop_EUR -rw-r--r-- 1 hoggac01 staff 200376 7 Aug 21:30 qc_snplist.txt The pop_* folders contain simulated genotype, phenotype and GWAS summary statistics representative of Europeans, East Asians and Africans for input to BridgePRS. Each pop_* folder is split into summary statistics, and individual level genotype and phenotype folders, e.g. $ ls -l data/pop_AFR/ total 0 drwxr-xr-x 68 hoggac01 staff 2176 14 Jul 17:22 genotypes drwxr-xr-x 4 hoggac01 staff 128 14 Jul 17:22 phenotypes drwxr-xr-x 68 hoggac01 staff 2176 12 Aug 11:02 sumstats Look at each directory e.g. ls pop_AFR/genotypes . There are two sets of summary statistics in each sumstats folder from the analysis of the same simulated continuos phenotype, the \"half\" files were generated using half the sample size. For computation speed the summary statistics only have a small subset of SNPs, 19k-20k genomewide zcat data/pop_EAS/sumstats/EAS.chr* | wc -l zcat data/pop_EUR/sumstats/EUR.chr* | wc -l zcat data/pop_AFR/sumstats/AFR.chr* | wc -l or on a Mac gzcat data/pop_EAS/sumstats/EAS.chr* | wc -l gzcat data/pop_EUR/sumstats/EUR.chr* | wc -l gzcat data/pop_AFR/sumstats/AFR.chr* | wc -l Results in these files are only shown for SNP with MAF>0. The SNPs are a subset of the HapMap panel, there seems to be a bias to polymorphoic EUR SNPs. Take a look a look at the files, e.g. zcat data/pop_AFR/sumstats/AFR.chr19.glm.linear.gz | head zcat data/pop_AFR/sumstats/AFR_half.chr19.glm.linear.gz | head again use gzcat on a Mac. In the OBS_CT column you'll see can that the \"_half\" summary statistics files have half the sample size, 10,000 compared to 20,000 for the EAS and AFR populations and 40,000 compared to 80,000 for the EUR population. The same SNPs are contained in each set of summary statistics. The phenotypes folders has two files: \"test\" and \"validation\" with IDs, the outcome phenotype and covariates. \"Test\" data is used to optimise the PRS and \"validation\" data is not used to estimate the PRS, it is just to assess model performance. The genotypes folders are in plink1.9 format and are split by chromosome. These folders contain the genetic data for individuals in the phenotypes folder. Test data will only be used for individuals with both genotype and phenotype information. Similarly model performance metrics will only use samples with both genotype and phenotype information, however, predictions are generated for all validation samples with genotype data.","title":"BridgePRS input data"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#passing-arguments-to-run-bridgeprs","text":"Example run of BridgePRS: ./bridgePRS pipeline go -o out/ --config_files data/eas.config data/eur.config --fst 0.11 --phenotype y --cores 4 --restart Arguments can be passed to BridgePRS on both the commandline and in config files. config files, used above, are a neat way to store population specific arguments, therefore for a standard two population analysis two config are required. By default the first config file is for the target population and the second is for the base population. The -o argument specifies the output folder. The --fst argument is used to specify a prior distribution used in the BridgePRS analysis and should be the Fst between the base and target populations used in the analysis. Our first analysis uses European base data and East Asian target data, the Fst between these populations is 0.11. The --phenotype argument specifies the column label of the phenotype in the test and validation files, e.g. EAS_valid.dat . The --cores argument specifies the number of cores used in the analysis. A full list of arguments that can be used on the commandline can be found here....","title":"Passing arguments to run BridgePRS"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#the-config-files","text":".config files to tell the software where to find the required input files and the column headers of the summary statistics files, take a look, e.g. cat data/eas.config LD_PATH=1000G_sample LDPOP=EAS POP=EAS SUMSTATS_PREFIX=pop_EAS/sumstats/EAS.chr #SUMSTATS_PREFIX=pop_EAS/sumstats/EAS_half.chr SUMSTATS_SUFFIX=.glm.linear.gz GENOTYPE_PREFIX=pop_EAS/genotypes/chr PHENOTYPE_FILE=pop_EAS/phenotypes/EAS_test.dat VALIDATION_FILE=pop_EAS/phenotypes/EAS_valid.dat COVARIATES=PC1,PC2 SNP_FILE=qc_snplist.txt SSF-P=P SSF-SNPID=ID SSF-SE=SE SSF-SS=OBS_CT SSF-BETA=BETA SSF-REF=REF SSF-ALT=A1 SSF-MAF=A1_FREQ This config file conatins all possible arguments that can be used in config files. config files use the same argument names as the commandline arguments but in uppercase, and use \"=\" instead of a space between the argument name and the argument being passed. The POP argument simply labels the population used in this .config file for output.","title":"The *.config files"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#estimating-linkage-dissequilibrium-ld","text":"BridgePRS requires individual level genetic data in plink1.9 binary format to estimate linkage dissequilibrium (LD) in the populations which produced the GWAS summary statistics. The genotype test and validation data could be used, i.e. data in these folders pop_/genotypes/. If these data are small, less than 500 samples, or are not representative of the GWAS population we provide 1000 Genomes (1000G) data to estimate LD. Suitable 1000G data for this analysis is in the 1000G_sample folder for the small subset of SNPs used in these examples. The .config points to the folder with reference LD data by the LD_PATH argument in the config file. LD reference data is available for the five 1000G super population (abbreviations required to use in brackets): East Asian (EAS), South Asian (SAS), European (Eur), African (AFR) and American (AMR). For real data analyses 1000G reference data for larger subsets of SNPs can be downloaded here Can you work out what the other arguments are doing?","title":"Estimating Linkage Dissequilibrium (LD)"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#bridgeprs-output","text":"The main output is in the folder out/prs-combined_EAS-EUR/ . First view the output summary plot evince out/prs-combined_AFR-EUR/bridge.afr-eur.prs-combined.result.pdf on a Mac simply use open instead of evince . The barplot at the top which shows the varaince explained (R2) by the three PRS BridgePRS estimates and the variance explained by a weighted average of the three model. The weighted model is BridgePRS estimated \"best\" PRS This weighted combined PRS should be used. The three separate PRS estimated by BridgePRS are: * PRS using a prior effect-size distribution from the European model -- stage2 model * PRS using only the target (Non-European) dataset, stage 1 analysis - stage 1 model * PRS using both stage 1 and stage 2 results - stage1+2 model Each of these 3 models are given weights corresponding to how well they fit the test data. These weights are then used to combine the PRS to give the single weighted combined PRS. The models, stage1, stage2 and stage1+2, should not be used unless users have a strong prior belief that the models is better, i.e. Stage 2 model reflects the belief that the target population GWAS is only informative in conjugtion with the base population GWAS. Stage 1 model reflects the belief that the target population GWAS is informative and the base population GWAS gives no addition information. Stage 1+2 model reflects the belief both the base and target population GWAS contribute independent information. EAS_weighted_combined_preds.dat has PRS predictions for samples in the validation data using all four models: stage1, stage2, stage1+2 and weighted. EAS_weighted_combined_snp_weights.dat has the SNP weights for the combined to allow this model to be applied to other samples.","title":"BridgePRS output"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#using-bridgeprs-without-target-summary-statistics","text":"Often GWAS summary statistics are only available in one population. BridgePRS can use these summary statistics and optimise them to estimate a PRS for another target population given individual level from the target population. Here is an example ./bridgePRS prs-single run -o out_single/ --config_files data/eur_eas.config --phenotype y --cores 10 Look at data/eur_eas.config , the file uses EUR GWAS summary statistics and EAS test and validation data. Results of interest are written to the folder out_single/prs-single_EAS/quantify/ . Model performance is shown in the file EAS_quantify_var_explained.txt and plotted in .... See hpw these results compare with the previous analysis which included EAS GWAS summary statistics. cat out_single/prs-single_EAS/quantify/EAS_quantify_var_explained.txt cat out/prs-combined_EAS-EUR/EAS_weighted_combined_var_explained.txt This single summary statistic analysis is equilvant to the stage 2 analysis previously but with all the weight on the EUR prior. The superior performance of the previous stage 2 analysis shows how the EAS summary statistics have been incorporated to improve the PRS.","title":"Using BridgePRS without target summary statistics"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#further-analysis-with-bridgeprs","text":"","title":"Further analysis with BridgePRS"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#african-analysis","text":"Run BridgePRS again to estimate PRS in Africans using afr.config .","title":"African analysis"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#qustions","text":"In addition to pointing to differnt input files what other difference is there between the EAS and AFR config files? How do the results for EAS and AFR compare?","title":"Qustions?"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#analyses-with-other-gwas-summary-statistics","text":"For each population the config files contain commented out links to GWAS summary statistics of the same phenotype using half the same size: 40k for EUR and 10k for both EAS and AFR. Edit eas.config to use the EAS 10k GWAS summary statistics. To run the analysis write results to a new output directory e.g. out_half_target . Run the similar analysis for African samples by editing afr.config . Compare with previous results using the 10k EAS and EAS GWAS. Compare EAS and AFR results. Check you've run the analyses using the correct GWAS summary statistics, e.g. less less out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log less less out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log or grep Sumstats out_half_target/logs/bridgePRS.eas-eur.pipeline.go.log grep Sumstats out_half_target/logs/bridgePRS.afr-eur.pipeline.go.log If you have made a mistake, correct and run again using the --restart flag which deletes the previously genereated results.","title":"Analyses with other GWAS summary statistics"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#qustions_1","text":"How has using the less well powered EAS and AFR GWAS affected the predictive accuracy of the BridgePRS models? How do AFR and EUR results compare?","title":"Qustions?"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#analyses-with-smaller-eur-gwas-summary-statistics","text":"Edit the config files again to run analyses using the 40k EUR GWAS (i.e. EUR_half ) and the 20k EAS and AFR GWAS and write to results to a new directory e.g. out_half_eur .","title":"Analyses with smaller EUR GWAS summary statistics"},{"location":"tmp2/practical_docs_hidden/Day4a.docx/#qustions_2","text":"","title":"Qustions?"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/","text":"Day 4 - Practical 2: Introduction to Admixture analysis Module Goals The goal of this practical is to provide you with basic understanding of Admixture and the basic elements behind Admixture PRS scores. Upon completion of this practical, you should: * Gain familiarity with a variety of tools used in the context of admixed population research * Go through the basic steps of formulating admixture-informed polygenic risk scores Part1: Plot Decay of Ancestry LD over time Here we explore how Admixture LD varies over time and as a function of the genetic distance between loci. In R: library(ggplot2) library(reshape2) library(viridis) #range of values of r (recombination fraction) r = seq(0, 0.5, 0.1) dtmat = matrix(NA, nrow = 6, ncol = 10) # matrix to store values of dt for(i in 1:6){ dt = 0.25 for(j in 1:10){ dtmat[i,j] = dt dt = dt*(1 -r[i])^j } } dtmat = reshape2::melt(dtmat) colnames(dtmat) = c(\"r\",\"g\",\"Dt\") dtmat$r = (dtmat$r - 1)/10 ggplot(dtmat, aes(x = g, y = Dt, group = r, color = as.factor(r))) + geom_line(linewidth = 1.2) + theme_minimal(base_size = 14) + theme( axis.text = element_text(size = 14), axis.title = element_text(size = 16), legend.title = element_text(size = 14), legend.text = element_text(size = 12), plot.title = element_text(size = 18, face = \"bold\"), plot.subtitle = element_text(size = 14), panel.grid.major = element_line(color = \"gray80\") ) + scale_color_viridis_d() + scale_x_continuous(breaks = c(1:10)) + labs( title = \"Decay of Linkage Disequilibrium Over Generations\", subtitle = \"Effect of Recombination Fraction (r) on Admixture LD\", x = \"Generations since admixture (t)\", y = \"Admixture LD\", color = \"Recombination Fraction (r)\" ) Questions (i) Describe what happens to admixture LD over time? (ii) Why does recombination also have an impact? Part 2: Global Ancestry Inference We will now run an analysis using the software ADMIXTURE to calculate global ancestry proportions across a sample of 28 individuals. Here we perform a supervised analysis. Please execute the following code from location ~/RFMIX_WCS_2024/data/plink/ ./admixture samples_n28_qc_thin.bed 2 --supervised -j4 Questions (i) What do you think the number specified after the inout file represents? The next step is to create a plot the results # Plot Global Ancestry Results R library(ggplot2) library(reshape2) # Read the data from files fam <- read.table(\"samples_n28_qc_thin.fam\", header = FALSE) pop <- read.table(\"samples_n28_qc_thin.pop\", header = FALSE) Q <- read.table(\"samples_n28_qc_thin.2.Q\", header = FALSE) # Merge the data into one data frame merged_data <- cbind(fam, pop, Q) # Extract necessary columns (assuming the structure of the files as in the image) colnames(merged_data) <- c(\"FID\", \"IID\", \"PaternalID\", \"MaternalID\", \"Sex\", \"Phenotype\", \"Population\", \"AFR\", \"EUR\") # Order data by decreasing AFR merged_data <- merged_data[order(-merged_data$AFR), ] # Prepare data for plotting plot_data <- merged_data[, c(\"IID\", \"AFR\", \"EUR\")] plot_data$IID <- factor(plot_data$IID, levels = plot_data$IID) # Ensure order is maintained in plot plot_data_melted <- melt(plot_data, id.vars = \"IID\") # Create the plot p <- ggplot(plot_data_melted, aes(x = IID, y = value, fill = variable)) + geom_bar(stat = \"identity\", position = \"stack\") + scale_fill_manual(values = c(\"AFR\" = \"red\", \"EUR\" = \"darkgreen\")) + labs(x = \"Individual ID\", y = \"Ancestry Proportion\", fill = \"Ancestry\", title = \"Global Ancestry Proportions\") + theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10, face = \"bold\"), axis.text.y = element_text(face = \"bold\"), # Bold y-axis numbers axis.title.x = element_text(face = \"bold\"), axis.title.y = element_text(face = \"bold\"), legend.title = element_text(face = \"bold\"), plot.title = element_text(face = \"bold\", hjust = 0.5)) # Save the plot with specified dimensions ggsave(\"ancestry_plot.png\", plot = p, width = 10, height = 6, units = \"in\", dpi = 300) Questions (i) What are the ancestry assignments of the 28 individuals? (Provide estimated proportions where necessary) Part 3: Local Ancestry Inference Next we will use the RFMix software to calculate local ancestry on chromosome 22 for the same 28 individuals. The RFMix algorithm uses an unsupervised learning algorithm. # Run the following UNIX command from the home directory module load cmake module load bcftools/1.10.2 for i in {22..22}; do ./software/rfmix -f ./data/rfmix/chr1-22_phased.bcf.gz -r ./reference/chr1-22.b.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bcf.gz --analyze-range=26.86-31.80 -m ./data/rfmix/1KG_superpop_vs_ID.txt --chromosome=${i} -g ./reference/1kg_chr1-22.gmap --n-threads=4 -o ./out/rfmix/chr${i}.local_ancestry; done Questions (i) What information is provided in the simulation results table displayed on-screen ? Part 4: Plot local admixture on chromosome 22 In this step we will plot the output from the previous RFMix run. Execute the following code from the home directory R library(ggplot2) library(dplyr) library(tidyr) # Function to read the .msp.tsv file read_msp_file <- function(msp_file) { # Read the entire file as text lines <- readLines(msp_file) # Determine the number of header lines (lines starting with '#') header_lines <- lines[grepl(\"^#\", lines)] num_header_lines <- length(header_lines) # Extract column names from the last header line col_names <- strsplit(header_lines[num_header_lines], \"\\t\")[[1]] # Read the data skipping the header lines msp_df <- read.table(msp_file, header = FALSE, skip = num_header_lines, sep = \"\\t\") # Assign column names colnames(msp_df) <- col_names return(msp_df) } # Function to read the .Q file read_Q_file <- function(Q_file) { Q_df <- read.table(Q_file, header = TRUE, sep = \"\\t\", comment.char = \"#\") colnames(Q_df) <- c(\"sample\", \"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\") return(Q_df) } # Specification of file paths msp_file <- './out/rfmix/chr22.local_ancestry.msp.tsv' Q_file <- './out/rfmix/chr22.local_ancestry.rfmix.Q' # Read in files msp_df <- read_msp_file(msp_file) Q_df <- read_Q_file(Q_file) # Check for NA or empty column names print(colnames(msp_df)) # Extract ancestry columns based on pattern recognition of column names ancestry_cols <- colnames(msp_df)[grep(\"\\\\.0$|\\\\.1$\", colnames(msp_df))] # Function to determine ancestry based on RFMix codes determine_ancestry <- function(value) { ancestry_map <- c(\"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\") return(ancestry_map[value + 1]) } # Rename columns uniquely colnames(msp_df)[7:62] <- paste0(\"haplo_\", colnames(msp_df)[7:62]) # Prepare data for plotting plot_data <- msp_df %>% pivot_longer(cols = starts_with(\"haplo_\"), names_to = \"haplo_col\", values_to = \"ancestry_code\", names_repair = \"unique\") %>% mutate( individual = gsub(\"\\\\..*\", \"\", haplo_col), strand = ifelse(grepl(\"\\\\.0$\", haplo_col), \"Strand 1\", \"Strand 2\"), ancestry = determine_ancestry(ancestry_code) ) # Create plot of chromosome 22 across the sample plot <- ggplot(plot_data, aes(x = sgpos, xend = egpos, y = interaction(individual, strand, lex.order = TRUE), yend = interaction(individual, strand, lex.order = TRUE), color = ancestry)) + geom_segment(linewidth = 4) + scale_color_manual(values = c(\"AFR\" = \"blue\", \"AMR\" = \"orange\", \"EAS\" = \"green\", \"EUR\" = \"red\", \"SAS\" = \"purple\")) + labs(x = \"Genetic position (cM)\", y = \"Individual ID and Haplotype\", title = \"Local Ancestry Across Chromosome 22\", color = \"Ancestry\") + theme_minimal() + theme(axis.text.y = element_text(size = 8), axis.title.y = element_text(size = 10), axis.title.x = element_text(size = 10)) # Save the plot to a file ggsave(\"./out/rfmix/local_ancestry_chromosome22_5Mb_subregion.png\", plot = plot, width = 10, height = 8) Questions (i) How many different continental ancestries do you see represented across the 58 strands? (ii) Why is the number of different ancestry backgrounds higher than it was in the previous step? Part 5: Formatting of admixture files for analysis using PRSice Step 1 - Convert phased genotypes to GenomicRange format # Run from the home directory library(vcfR) library(memuse) library(panelr) library(GenomicRanges) library(data.table) clean_memory <- function(vars_to_remove) { rm(list = vars_to_remove) gc() } # Read in phased VCF file vcfr_inputfile_chr22 <- read.vcfR(\"./data/rfmix/chr22_phased.vcf.gz\", verbose = FALSE) extracted_haps22 <- extract.haps(vcfr_inputfile_chr22, mask = FALSE, unphased_as_NA = TRUE, verbose = TRUE) extracted_snp_info22 <- getFIX(vcfr_inputfile_chr22) # Convert haplotypes to data frame haps_df <- data.frame(extracted_haps22, check.names = FALSE) haps_dt <- setDT(haps_df, keep.rownames = \"snps\") # Convert SNP info to data frame snp_info_df <- data.frame(extracted_snp_info22) # Check for numerical and ordering consistency between haplotypes and SNP info if (!identical(haps_dt[['snps']], snp_info_df[['ID']])) { stop(\"Numerical and ordering inconsistency between haplotypes and SNP info\") } # Merge haplotypes and SNP info merge_chr22 <- cbind(snp_info_df, haps_dt) # Convert to long format using panelr chr22_haplo_long <- long_panel(merge_chr22, prefix = \"_\", begin = 0, end = 1, label_location = \"end\", as_panel_data = FALSE) # Insert 'end' column after 'POS' and create 'wave' column chr22_haplo_long$end <- chr22_haplo_long$POS chr22_haplo_long$wave <- ifelse(chr22_haplo_long$wave == \"0\", \"+\", ifelse(chr22_haplo_long$wave == \"1\", \"-\", \"Z\")) # Remove row names and drop redundant columns using base R rownames(chr22_haplo_long) <- NULL drops <- c(\"id\", \"snps\", \"QUAL\", \"FILTER\") chr22_haplo_long <- chr22_haplo_long[, !names(chr22_haplo_long) %in% drops] # Rename columns names(chr22_haplo_long)[3] <- \"start\" names(chr22_haplo_long)[1] <- \"strand\" header <- gsub(\".*_\", \"\", colnames(chr22_haplo_long)[7:ncol(chr22_haplo_long)]) names(chr22_haplo_long)[7:ncol(chr22_haplo_long)] <- header # Create GRanges object gr_obj_chr22 <- makeGRangesFromDataFrame(chr22_haplo_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Save the GRanges object saveRDS(gr_obj_chr22, file = \"./out/rfmix/chr22_phased_gr.rds\") # Clean up memory clean_memory(c(\"vcfr_inputfile_chr22\", \"extracted_haps22\", \"merge_chr22\", \"haps_df\", \"haps_dt\", \"snp_info_df\", \"chr22_haplo_long\", \"gr_obj_chr22\")) Part 5: Step 2 - Merge genotypes from Step 1 with local ancestry calls by RFMix # Read in MSP file msp <- fread(\"./out/rfmix/chr22.local_ancestry.msp.tsv\") # Reformat genome-wide local ancestry output as GRanges object colnames(msp)[1] <- \"chm\" msp_gr <- makeGRangesFromDataFrame(msp, seqnames.field = \"chm\", start.field = \"spos\", end.field = \"epos\", keep.extra.columns = TRUE) # Convert the elements of the GRange object into a dataframe chr22_rf <- data.frame(seqnames = seqnames(msp_gr), ranges = ranges(msp_gr), strand = strand(msp_gr), mcols(msp_gr), check.names = FALSE) names(chr22_rf)[1:5] <- c(\"chr\", \"start\", \"end\", \"width\", \"strand\") rownames(chr22_rf) <- NULL # Clean up column headers header <- gsub(\".*_\", \"\", colnames(chr22_rf)[9:ncol(chr22_rf)]) names(chr22_rf)[9:ncol(chr22_rf)] <- header # Convert local ancestry calls from wide to long format chr22_rf_long <- long_panel(chr22_rf, prefix = \".\", begin = 0, end = 1, label_location = \"end\", as_panel_data = FALSE) chr22_rf_long <- as.data.frame(chr22_rf_long, check.names = FALSE) chr22_rf_long$strand <- ifelse(chr22_rf_long$wave == \"0\", \"+\", ifelse(chr22_rf_long$wave == \"1\", \"-\", \"Z\")) # Drop redundant columns drops <- c(\"wave\", \"id\") chr22_rf_long <- chr22_rf_long[, !(names(chr22_rf_long) %in% drops)] rownames(chr22_rf_long) <- NULL # Convert the reconfigured dataframe file into a GRanges object chr22_msp_gr <- makeGRangesFromDataFrame(chr22_rf_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Ensure chr22_haplo_long is a GRanges object before finding overlaps chr22_haplo_gr <- makeGRangesFromDataFrame(chr22_haplo_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Find overlaps and store matching features # Matching is coordinates based. Base position (\"start\"/\"end\")is used to match the two files matched_regions <- findOverlaps(chr22_haplo_gr, chr22_msp_gr) chr22_haps_lanc_gr <- chr22_haplo_gr[queryHits(matched_regions)] #Store matching features in a new dataframe, add metadata from RFmix output. mcols(chr22_haps_lanc_gr) <- cbind.data.frame(mcols(chr22_haps_lanc_gr), mcols(chr22_msp_gr[subjectHits(matched_regions)])) # Local ancestry calls are now aligned with genotypic data and positional coordinates # Convert to dataframe without adding 'X' to numeric column names genes_df <- as.data.frame(chr22_haps_lanc_gr) names(genes_df) <- sub('^X', '', names(genes_df)) # Output the dataframe write.table(genes_df, file = \"./out/rfmix/chr22_phased_geno_lanc.txt\", quote = FALSE, row.names=F) # Clean up memory rm(list = c(\"chr22_haplo_gr\", \"chr22_haplo_long\", \"msp\", \"msp_gr\", \"chr22_rf\", \"header\", \"chr22_rf_long\", \"chr22_msp_gr\", \"matched_regions\", \"chr22_haps_lanc_gr\")) gc() Part 5: Step 3 - Create separate Plink files # Partition genotype and local ancestry data chr22_genos <- genes_df[, c(1, 2, 6, 9:36)] chr22_LA <- genes_df[, c(1, 2, 6, 40:ncol(genes_df))] # Reintegrate in interleaved format d <- chr22_genos[, -c(1:3)] # Retain ID columns only d2 <- chr22_LA[, -c(1:3)] # Prepare headers indx <- rbind(names(d), names(d2)) dmerge <- cbind(d, d2) dfinal <- dmerge[, indx] # Convert LAnc data from long to wide format LA_wide <- lapply(1:ncol(chr22_LA), function(i) as.data.frame(matrix(chr22_LA[, i], ncol = 2, byrow = TRUE))) # Check length of LA_wide length(LA_wide) # Expected number. Each item contains a set of matched strand pairs per individual LA_final <- as.data.frame(do.call(cbind, LA_wide)) LA_final <- LA_final[, -c(2, 4, 6)] # Remove duplicates of first 3 cols colnames(LA_final)[4:ncol(LA_final)] <- colnames(dfinal) # Apply headers # Convert genotype calls to horizontal orientation geno_wide <- lapply(1:ncol(chr22_genos), function(i) as.data.frame(matrix(chr22_genos[, i], ncol = 2, byrow = TRUE))) # Genotypic part: Get horizontal genotypes geno_final <- as.data.frame(do.call(cbind, geno_wide)) # Merge horizontal genotypes # Clean up and finalize geno_final geno_final <- geno_final[, -c(2, 4, 6)] # Redundant columns colnames(geno_final)[4:ncol(geno_final)] <- colnames(dfinal) # Name columns colnames(geno_final)[1:3] <- c(\"CHROM\", \"BP\", \"ID\") colnames(LA_final)[1:3] <- c(\"CHROM\", \"BP\", \"ID\") # Write final tables write.table(geno_final, \"./out/rfmix/chr22_geno.txt\", row.names = FALSE, quote = FALSE) write.table(LA_final, \"./out/rfmix/chr22_LA.txt\", row.names = FALSE, quote = FALSE) Part 5: Step 4 - Use custom software (RFTransform) to create Plink files for input into PRSice module load cmake ./software/RFTransform/build/RFTransformer ./out/rfmix/chr22_geno.txt ./out/rfmix/chr22_LA.txt ./out/plink/chr22 # Perform general QC ahead of running PRSice on ancestry-deconvolved individuals # (i) Remove SNPs with low minor allele count (MAC) # Plink - Remove monomorphic SNPs (minor allele count 0-4). #AFR for i in {22..22}; do ./software/plink2 \\ --bfile ./out/plink/chr${i}-AFR \\ --mac 5 \\ --make-bed \\ --out ./out/plink/chr${i}-AFR.mac done #EUR for i in {22..22}; do ./software/plink2 \\ --bfile ./out/plink/chr${i}-EUR \\ --mac 5 \\ --make-bed \\ --out ./out/plink//chr${i}-EUR.mac done # PRSice - Generate ancestry-specific weights # AFR Rscript ./software/PRSice.R \\ --prsice ./software/PRSice_linux \\ --base ./data/plink/AFR-BMI.Phenotype.glm.linear \\ --extract ./data/plink/snp.valid \\ --A1 A1 \\ --pvalue P \\ --stat BETA \\ --pheno ./data/plink/pheno.plink \\ --beta \\ --snp ID \\ --score sum \\ --target ./out/plink/chr22-AFR.mac \\ --binary-target F \\ --out ./out/prsice/BMI_AFR-base # EUR Rscript ./software/PRSice.R \\ --prsice ./software/PRSice_linux \\ --base ./data/plink/EUR-BMI.Phenotype.glm.linear \\ --extract ./data/plink/snp.valid \\ --A1 A1 \\ --pvalue P \\ --stat BETA \\ --pheno ./data/plink/pheno.plink \\ --beta \\ --snp ID \\ --score sum \\ --target ./out/plink/chr22-EUR.mac \\ --binary-target F \\ --out ./out/prsice/BMI_EUR-base Part 5: Step 5 - Evaluate the Admixture-informed PRS library(dplyr) # Read the PRS files into dataframes file1 <- read.table(\"./out/prsice/BMI_EUR-base.best\", header = TRUE, check.names=F) file2 <- read.table(\"./out/prsice/BMI_AFR-base.best\", header = TRUE, check.names=F) # Add the fourth column of both files file1$PRS_SUM <- file1$PRS + file2$PRS # Load the phenotype data pheno <- read.table(\"./data/plink/pheno.plink\", header = F) colnames(pheno) <- c(\"FID\", \"IID\", \"phenotype\") # Convert phenotype column to numeric pheno$phenotype <- as.numeric(pheno$phenotype) # Merge PRS data with phenotype data merged_data <- merge(file1[, c(\"FID\", \"IID\", \"PRS\", \"PRS_SUM\")], pheno, by = c(\"FID\", \"IID\")) merged_data <- merge(merged_data, file2[, c(\"FID\", \"IID\", \"PRS\")], by = c(\"FID\", \"IID\")) # Rename columns names(merged_data)[names(merged_data) == \"PRS.x\"] <- \"PRS1\" names(merged_data)[names(merged_data) == \"PRS.y\"] <- \"PRS2\" # Perform linear regression for each PRS and the combined PRS model1 <- lm(phenotype ~ PRS1, data = merged_data) model2 <- lm(phenotype ~ PRS2, data = merged_data) model_sum <- lm(phenotype ~ PRS_SUM, data = merged_data) # Extract R-squared values r_squared1 <- summary(model1)$r.squared r_squared2 <- summary(model2)$r.squared r_squared_sum <- summary(model_sum)$r.squared # Print the R-squared values cat(\"R-squared for PRS1: \", r_squared1, \"\\n\") cat(\"R-squared for PRS2: \", r_squared2, \"\\n\") cat(\"R-squared for PRS_SUM: \", r_squared_sum, \"\\n\") Questions (i) How does the R-squared of the combined-ancestry PRS perform relative to the 2 partial-genome PRSs?","title":"Day4b.docx"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#day-4-practical-2-introduction-to-admixture-analysis","text":"","title":"Day 4 - Practical 2: Introduction to Admixture analysis"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#module-goals","text":"The goal of this practical is to provide you with basic understanding of Admixture and the basic elements behind Admixture PRS scores. Upon completion of this practical, you should: * Gain familiarity with a variety of tools used in the context of admixed population research * Go through the basic steps of formulating admixture-informed polygenic risk scores","title":"Module Goals"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part1-plot-decay-of-ancestry-ld-over-time","text":"Here we explore how Admixture LD varies over time and as a function of the genetic distance between loci. In R: library(ggplot2) library(reshape2) library(viridis) #range of values of r (recombination fraction) r = seq(0, 0.5, 0.1) dtmat = matrix(NA, nrow = 6, ncol = 10) # matrix to store values of dt for(i in 1:6){ dt = 0.25 for(j in 1:10){ dtmat[i,j] = dt dt = dt*(1 -r[i])^j } } dtmat = reshape2::melt(dtmat) colnames(dtmat) = c(\"r\",\"g\",\"Dt\") dtmat$r = (dtmat$r - 1)/10 ggplot(dtmat, aes(x = g, y = Dt, group = r, color = as.factor(r))) + geom_line(linewidth = 1.2) + theme_minimal(base_size = 14) + theme( axis.text = element_text(size = 14), axis.title = element_text(size = 16), legend.title = element_text(size = 14), legend.text = element_text(size = 12), plot.title = element_text(size = 18, face = \"bold\"), plot.subtitle = element_text(size = 14), panel.grid.major = element_line(color = \"gray80\") ) + scale_color_viridis_d() + scale_x_continuous(breaks = c(1:10)) + labs( title = \"Decay of Linkage Disequilibrium Over Generations\", subtitle = \"Effect of Recombination Fraction (r) on Admixture LD\", x = \"Generations since admixture (t)\", y = \"Admixture LD\", color = \"Recombination Fraction (r)\" )","title":"Part1: Plot Decay of Ancestry LD over time"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#questions","text":"","title":"Questions"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#i-describe-what-happens-to-admixture-ld-over-time","text":"","title":"(i) Describe what happens to admixture LD over time?"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#ii-why-does-recombination-also-have-an-impact","text":"","title":"(ii) Why does recombination also have an impact?"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part-2-global-ancestry-inference","text":"We will now run an analysis using the software ADMIXTURE to calculate global ancestry proportions across a sample of 28 individuals. Here we perform a supervised analysis. Please execute the following code from location ~/RFMIX_WCS_2024/data/plink/ ./admixture samples_n28_qc_thin.bed 2 --supervised -j4","title":"Part 2: Global Ancestry Inference"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#questions_1","text":"","title":"Questions"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#i-what-do-you-think-the-number-specified-after-the-inout-file-represents","text":"The next step is to create a plot the results # Plot Global Ancestry Results R library(ggplot2) library(reshape2) # Read the data from files fam <- read.table(\"samples_n28_qc_thin.fam\", header = FALSE) pop <- read.table(\"samples_n28_qc_thin.pop\", header = FALSE) Q <- read.table(\"samples_n28_qc_thin.2.Q\", header = FALSE) # Merge the data into one data frame merged_data <- cbind(fam, pop, Q) # Extract necessary columns (assuming the structure of the files as in the image) colnames(merged_data) <- c(\"FID\", \"IID\", \"PaternalID\", \"MaternalID\", \"Sex\", \"Phenotype\", \"Population\", \"AFR\", \"EUR\") # Order data by decreasing AFR merged_data <- merged_data[order(-merged_data$AFR), ] # Prepare data for plotting plot_data <- merged_data[, c(\"IID\", \"AFR\", \"EUR\")] plot_data$IID <- factor(plot_data$IID, levels = plot_data$IID) # Ensure order is maintained in plot plot_data_melted <- melt(plot_data, id.vars = \"IID\") # Create the plot p <- ggplot(plot_data_melted, aes(x = IID, y = value, fill = variable)) + geom_bar(stat = \"identity\", position = \"stack\") + scale_fill_manual(values = c(\"AFR\" = \"red\", \"EUR\" = \"darkgreen\")) + labs(x = \"Individual ID\", y = \"Ancestry Proportion\", fill = \"Ancestry\", title = \"Global Ancestry Proportions\") + theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10, face = \"bold\"), axis.text.y = element_text(face = \"bold\"), # Bold y-axis numbers axis.title.x = element_text(face = \"bold\"), axis.title.y = element_text(face = \"bold\"), legend.title = element_text(face = \"bold\"), plot.title = element_text(face = \"bold\", hjust = 0.5)) # Save the plot with specified dimensions ggsave(\"ancestry_plot.png\", plot = p, width = 10, height = 6, units = \"in\", dpi = 300)","title":"(i) What do you think the number specified after the inout file represents?"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#questions_2","text":"","title":"Questions"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#i-what-are-the-ancestry-assignments-of-the-28-individuals-provide-estimated-proportions-where-necessary","text":"","title":"(i) What are the ancestry assignments of the 28 individuals? (Provide estimated proportions where necessary)"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part-3-local-ancestry-inference","text":"Next we will use the RFMix software to calculate local ancestry on chromosome 22 for the same 28 individuals. The RFMix algorithm uses an unsupervised learning algorithm. # Run the following UNIX command from the home directory module load cmake module load bcftools/1.10.2 for i in {22..22}; do ./software/rfmix -f ./data/rfmix/chr1-22_phased.bcf.gz -r ./reference/chr1-22.b.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bcf.gz --analyze-range=26.86-31.80 -m ./data/rfmix/1KG_superpop_vs_ID.txt --chromosome=${i} -g ./reference/1kg_chr1-22.gmap --n-threads=4 -o ./out/rfmix/chr${i}.local_ancestry; done","title":"Part 3: Local Ancestry Inference"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#questions_3","text":"","title":"Questions"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#i-what-information-is-provided-in-the-simulation-results-table-displayed-on-screen","text":"","title":"(i) What information is provided in the simulation results table displayed on-screen ?"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part-4-plot-local-admixture-on-chromosome-22","text":"In this step we will plot the output from the previous RFMix run. Execute the following code from the home directory R library(ggplot2) library(dplyr) library(tidyr) # Function to read the .msp.tsv file read_msp_file <- function(msp_file) { # Read the entire file as text lines <- readLines(msp_file) # Determine the number of header lines (lines starting with '#') header_lines <- lines[grepl(\"^#\", lines)] num_header_lines <- length(header_lines) # Extract column names from the last header line col_names <- strsplit(header_lines[num_header_lines], \"\\t\")[[1]] # Read the data skipping the header lines msp_df <- read.table(msp_file, header = FALSE, skip = num_header_lines, sep = \"\\t\") # Assign column names colnames(msp_df) <- col_names return(msp_df) } # Function to read the .Q file read_Q_file <- function(Q_file) { Q_df <- read.table(Q_file, header = TRUE, sep = \"\\t\", comment.char = \"#\") colnames(Q_df) <- c(\"sample\", \"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\") return(Q_df) } # Specification of file paths msp_file <- './out/rfmix/chr22.local_ancestry.msp.tsv' Q_file <- './out/rfmix/chr22.local_ancestry.rfmix.Q' # Read in files msp_df <- read_msp_file(msp_file) Q_df <- read_Q_file(Q_file) # Check for NA or empty column names print(colnames(msp_df)) # Extract ancestry columns based on pattern recognition of column names ancestry_cols <- colnames(msp_df)[grep(\"\\\\.0$|\\\\.1$\", colnames(msp_df))] # Function to determine ancestry based on RFMix codes determine_ancestry <- function(value) { ancestry_map <- c(\"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\") return(ancestry_map[value + 1]) } # Rename columns uniquely colnames(msp_df)[7:62] <- paste0(\"haplo_\", colnames(msp_df)[7:62]) # Prepare data for plotting plot_data <- msp_df %>% pivot_longer(cols = starts_with(\"haplo_\"), names_to = \"haplo_col\", values_to = \"ancestry_code\", names_repair = \"unique\") %>% mutate( individual = gsub(\"\\\\..*\", \"\", haplo_col), strand = ifelse(grepl(\"\\\\.0$\", haplo_col), \"Strand 1\", \"Strand 2\"), ancestry = determine_ancestry(ancestry_code) ) # Create plot of chromosome 22 across the sample plot <- ggplot(plot_data, aes(x = sgpos, xend = egpos, y = interaction(individual, strand, lex.order = TRUE), yend = interaction(individual, strand, lex.order = TRUE), color = ancestry)) + geom_segment(linewidth = 4) + scale_color_manual(values = c(\"AFR\" = \"blue\", \"AMR\" = \"orange\", \"EAS\" = \"green\", \"EUR\" = \"red\", \"SAS\" = \"purple\")) + labs(x = \"Genetic position (cM)\", y = \"Individual ID and Haplotype\", title = \"Local Ancestry Across Chromosome 22\", color = \"Ancestry\") + theme_minimal() + theme(axis.text.y = element_text(size = 8), axis.title.y = element_text(size = 10), axis.title.x = element_text(size = 10)) # Save the plot to a file ggsave(\"./out/rfmix/local_ancestry_chromosome22_5Mb_subregion.png\", plot = plot, width = 10, height = 8)","title":"Part 4: Plot local admixture on chromosome 22"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#questions_4","text":"","title":"Questions"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#i-how-many-different-continental-ancestries-do-you-see-represented-across-the-58-strands","text":"","title":"(i) How many different continental ancestries do you see represented across the 58 strands?"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#ii-why-is-the-number-of-different-ancestry-backgrounds-higher-than-it-was-in-the-previous-step","text":"","title":"(ii) Why is the number of different ancestry backgrounds higher than it was in the previous step?"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part-5-formatting-of-admixture-files-for-analysis-using-prsice","text":"","title":"Part 5: Formatting of admixture files for analysis using PRSice"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#step-1-convert-phased-genotypes-to-genomicrange-format","text":"# Run from the home directory library(vcfR) library(memuse) library(panelr) library(GenomicRanges) library(data.table) clean_memory <- function(vars_to_remove) { rm(list = vars_to_remove) gc() } # Read in phased VCF file vcfr_inputfile_chr22 <- read.vcfR(\"./data/rfmix/chr22_phased.vcf.gz\", verbose = FALSE) extracted_haps22 <- extract.haps(vcfr_inputfile_chr22, mask = FALSE, unphased_as_NA = TRUE, verbose = TRUE) extracted_snp_info22 <- getFIX(vcfr_inputfile_chr22) # Convert haplotypes to data frame haps_df <- data.frame(extracted_haps22, check.names = FALSE) haps_dt <- setDT(haps_df, keep.rownames = \"snps\") # Convert SNP info to data frame snp_info_df <- data.frame(extracted_snp_info22) # Check for numerical and ordering consistency between haplotypes and SNP info if (!identical(haps_dt[['snps']], snp_info_df[['ID']])) { stop(\"Numerical and ordering inconsistency between haplotypes and SNP info\") } # Merge haplotypes and SNP info merge_chr22 <- cbind(snp_info_df, haps_dt) # Convert to long format using panelr chr22_haplo_long <- long_panel(merge_chr22, prefix = \"_\", begin = 0, end = 1, label_location = \"end\", as_panel_data = FALSE) # Insert 'end' column after 'POS' and create 'wave' column chr22_haplo_long$end <- chr22_haplo_long$POS chr22_haplo_long$wave <- ifelse(chr22_haplo_long$wave == \"0\", \"+\", ifelse(chr22_haplo_long$wave == \"1\", \"-\", \"Z\")) # Remove row names and drop redundant columns using base R rownames(chr22_haplo_long) <- NULL drops <- c(\"id\", \"snps\", \"QUAL\", \"FILTER\") chr22_haplo_long <- chr22_haplo_long[, !names(chr22_haplo_long) %in% drops] # Rename columns names(chr22_haplo_long)[3] <- \"start\" names(chr22_haplo_long)[1] <- \"strand\" header <- gsub(\".*_\", \"\", colnames(chr22_haplo_long)[7:ncol(chr22_haplo_long)]) names(chr22_haplo_long)[7:ncol(chr22_haplo_long)] <- header # Create GRanges object gr_obj_chr22 <- makeGRangesFromDataFrame(chr22_haplo_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Save the GRanges object saveRDS(gr_obj_chr22, file = \"./out/rfmix/chr22_phased_gr.rds\") # Clean up memory clean_memory(c(\"vcfr_inputfile_chr22\", \"extracted_haps22\", \"merge_chr22\", \"haps_df\", \"haps_dt\", \"snp_info_df\", \"chr22_haplo_long\", \"gr_obj_chr22\"))","title":"Step 1 - Convert phased genotypes to GenomicRange format"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part-5-step-2-merge-genotypes-from-step-1-with-local-ancestry-calls-by-rfmix","text":"# Read in MSP file msp <- fread(\"./out/rfmix/chr22.local_ancestry.msp.tsv\") # Reformat genome-wide local ancestry output as GRanges object colnames(msp)[1] <- \"chm\" msp_gr <- makeGRangesFromDataFrame(msp, seqnames.field = \"chm\", start.field = \"spos\", end.field = \"epos\", keep.extra.columns = TRUE) # Convert the elements of the GRange object into a dataframe chr22_rf <- data.frame(seqnames = seqnames(msp_gr), ranges = ranges(msp_gr), strand = strand(msp_gr), mcols(msp_gr), check.names = FALSE) names(chr22_rf)[1:5] <- c(\"chr\", \"start\", \"end\", \"width\", \"strand\") rownames(chr22_rf) <- NULL # Clean up column headers header <- gsub(\".*_\", \"\", colnames(chr22_rf)[9:ncol(chr22_rf)]) names(chr22_rf)[9:ncol(chr22_rf)] <- header # Convert local ancestry calls from wide to long format chr22_rf_long <- long_panel(chr22_rf, prefix = \".\", begin = 0, end = 1, label_location = \"end\", as_panel_data = FALSE) chr22_rf_long <- as.data.frame(chr22_rf_long, check.names = FALSE) chr22_rf_long$strand <- ifelse(chr22_rf_long$wave == \"0\", \"+\", ifelse(chr22_rf_long$wave == \"1\", \"-\", \"Z\")) # Drop redundant columns drops <- c(\"wave\", \"id\") chr22_rf_long <- chr22_rf_long[, !(names(chr22_rf_long) %in% drops)] rownames(chr22_rf_long) <- NULL # Convert the reconfigured dataframe file into a GRanges object chr22_msp_gr <- makeGRangesFromDataFrame(chr22_rf_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Ensure chr22_haplo_long is a GRanges object before finding overlaps chr22_haplo_gr <- makeGRangesFromDataFrame(chr22_haplo_long, ignore.strand = FALSE, keep.extra.columns = TRUE) # Find overlaps and store matching features # Matching is coordinates based. Base position (\"start\"/\"end\")is used to match the two files matched_regions <- findOverlaps(chr22_haplo_gr, chr22_msp_gr) chr22_haps_lanc_gr <- chr22_haplo_gr[queryHits(matched_regions)] #Store matching features in a new dataframe, add metadata from RFmix output. mcols(chr22_haps_lanc_gr) <- cbind.data.frame(mcols(chr22_haps_lanc_gr), mcols(chr22_msp_gr[subjectHits(matched_regions)])) # Local ancestry calls are now aligned with genotypic data and positional coordinates # Convert to dataframe without adding 'X' to numeric column names genes_df <- as.data.frame(chr22_haps_lanc_gr) names(genes_df) <- sub('^X', '', names(genes_df)) # Output the dataframe write.table(genes_df, file = \"./out/rfmix/chr22_phased_geno_lanc.txt\", quote = FALSE, row.names=F) # Clean up memory rm(list = c(\"chr22_haplo_gr\", \"chr22_haplo_long\", \"msp\", \"msp_gr\", \"chr22_rf\", \"header\", \"chr22_rf_long\", \"chr22_msp_gr\", \"matched_regions\", \"chr22_haps_lanc_gr\")) gc()","title":"Part 5: Step 2 - Merge genotypes from Step 1 with local ancestry calls by RFMix"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part-5-step-3-create-separate-plink-files","text":"# Partition genotype and local ancestry data chr22_genos <- genes_df[, c(1, 2, 6, 9:36)] chr22_LA <- genes_df[, c(1, 2, 6, 40:ncol(genes_df))] # Reintegrate in interleaved format d <- chr22_genos[, -c(1:3)] # Retain ID columns only d2 <- chr22_LA[, -c(1:3)] # Prepare headers indx <- rbind(names(d), names(d2)) dmerge <- cbind(d, d2) dfinal <- dmerge[, indx] # Convert LAnc data from long to wide format LA_wide <- lapply(1:ncol(chr22_LA), function(i) as.data.frame(matrix(chr22_LA[, i], ncol = 2, byrow = TRUE))) # Check length of LA_wide length(LA_wide) # Expected number. Each item contains a set of matched strand pairs per individual LA_final <- as.data.frame(do.call(cbind, LA_wide)) LA_final <- LA_final[, -c(2, 4, 6)] # Remove duplicates of first 3 cols colnames(LA_final)[4:ncol(LA_final)] <- colnames(dfinal) # Apply headers # Convert genotype calls to horizontal orientation geno_wide <- lapply(1:ncol(chr22_genos), function(i) as.data.frame(matrix(chr22_genos[, i], ncol = 2, byrow = TRUE))) # Genotypic part: Get horizontal genotypes geno_final <- as.data.frame(do.call(cbind, geno_wide)) # Merge horizontal genotypes # Clean up and finalize geno_final geno_final <- geno_final[, -c(2, 4, 6)] # Redundant columns colnames(geno_final)[4:ncol(geno_final)] <- colnames(dfinal) # Name columns colnames(geno_final)[1:3] <- c(\"CHROM\", \"BP\", \"ID\") colnames(LA_final)[1:3] <- c(\"CHROM\", \"BP\", \"ID\") # Write final tables write.table(geno_final, \"./out/rfmix/chr22_geno.txt\", row.names = FALSE, quote = FALSE) write.table(LA_final, \"./out/rfmix/chr22_LA.txt\", row.names = FALSE, quote = FALSE)","title":"Part 5: Step 3 - Create separate Plink files"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part-5-step-4-use-custom-software-rftransform-to-create-plink-files-for-input-into-prsice","text":"module load cmake ./software/RFTransform/build/RFTransformer ./out/rfmix/chr22_geno.txt ./out/rfmix/chr22_LA.txt ./out/plink/chr22 # Perform general QC ahead of running PRSice on ancestry-deconvolved individuals # (i) Remove SNPs with low minor allele count (MAC) # Plink - Remove monomorphic SNPs (minor allele count 0-4). #AFR for i in {22..22}; do ./software/plink2 \\ --bfile ./out/plink/chr${i}-AFR \\ --mac 5 \\ --make-bed \\ --out ./out/plink/chr${i}-AFR.mac done #EUR for i in {22..22}; do ./software/plink2 \\ --bfile ./out/plink/chr${i}-EUR \\ --mac 5 \\ --make-bed \\ --out ./out/plink//chr${i}-EUR.mac done # PRSice - Generate ancestry-specific weights # AFR Rscript ./software/PRSice.R \\ --prsice ./software/PRSice_linux \\ --base ./data/plink/AFR-BMI.Phenotype.glm.linear \\ --extract ./data/plink/snp.valid \\ --A1 A1 \\ --pvalue P \\ --stat BETA \\ --pheno ./data/plink/pheno.plink \\ --beta \\ --snp ID \\ --score sum \\ --target ./out/plink/chr22-AFR.mac \\ --binary-target F \\ --out ./out/prsice/BMI_AFR-base # EUR Rscript ./software/PRSice.R \\ --prsice ./software/PRSice_linux \\ --base ./data/plink/EUR-BMI.Phenotype.glm.linear \\ --extract ./data/plink/snp.valid \\ --A1 A1 \\ --pvalue P \\ --stat BETA \\ --pheno ./data/plink/pheno.plink \\ --beta \\ --snp ID \\ --score sum \\ --target ./out/plink/chr22-EUR.mac \\ --binary-target F \\ --out ./out/prsice/BMI_EUR-base","title":"Part 5: Step 4 - Use custom software (RFTransform) to create Plink files for input into PRSice"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#part-5-step-5-evaluate-the-admixture-informed-prs","text":"library(dplyr) # Read the PRS files into dataframes file1 <- read.table(\"./out/prsice/BMI_EUR-base.best\", header = TRUE, check.names=F) file2 <- read.table(\"./out/prsice/BMI_AFR-base.best\", header = TRUE, check.names=F) # Add the fourth column of both files file1$PRS_SUM <- file1$PRS + file2$PRS # Load the phenotype data pheno <- read.table(\"./data/plink/pheno.plink\", header = F) colnames(pheno) <- c(\"FID\", \"IID\", \"phenotype\") # Convert phenotype column to numeric pheno$phenotype <- as.numeric(pheno$phenotype) # Merge PRS data with phenotype data merged_data <- merge(file1[, c(\"FID\", \"IID\", \"PRS\", \"PRS_SUM\")], pheno, by = c(\"FID\", \"IID\")) merged_data <- merge(merged_data, file2[, c(\"FID\", \"IID\", \"PRS\")], by = c(\"FID\", \"IID\")) # Rename columns names(merged_data)[names(merged_data) == \"PRS.x\"] <- \"PRS1\" names(merged_data)[names(merged_data) == \"PRS.y\"] <- \"PRS2\" # Perform linear regression for each PRS and the combined PRS model1 <- lm(phenotype ~ PRS1, data = merged_data) model2 <- lm(phenotype ~ PRS2, data = merged_data) model_sum <- lm(phenotype ~ PRS_SUM, data = merged_data) # Extract R-squared values r_squared1 <- summary(model1)$r.squared r_squared2 <- summary(model2)$r.squared r_squared_sum <- summary(model_sum)$r.squared # Print the R-squared values cat(\"R-squared for PRS1: \", r_squared1, \"\\n\") cat(\"R-squared for PRS2: \", r_squared2, \"\\n\") cat(\"R-squared for PRS_SUM: \", r_squared_sum, \"\\n\")","title":"Part 5: Step 5 - Evaluate the Admixture-informed PRS"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#questions_5","text":"","title":"Questions"},{"location":"tmp2/practical_docs_hidden/Day4b.docx/#i-how-does-the-r-squared-of-the-combined-ancestry-prs-perform-relative-to-the-2-partial-genome-prss","text":"","title":"(i) How does the R-squared of the combined-ancestry PRS perform relative to the 2 partial-genome PRSs?"},{"location":"tmp2/practical_docs_hidden/Day5_Projects/","text":"Integration of Polygenic Risk Scores Task \u2013 PRSmix calculation [3.5 hrs] You have just completed the Wellcome Connecting Science PRS course and are now acquainted with tools such as PRSCSx and BRIDGEPRS. You also got to hear a talk by Prof Nilanjan Chatterjee, who you later realized has been involved in developing three latest PRS software programs, PROSPER, MUSSEL, and CT-SLEB, that claim to improve PRS prediction in Africans. You are now getting overwhelmed by the sheer number of tools to test out and do not know which tool to use for your PRS project, which involves continental Africans. You decide to read more, and you then stumble across a novel approach called PRSmix, which integrates PRSs developed using diverse methods, forming an integrated PRS that has been noted to outperform previously reported PRS, as shown below. This seems as a much more pragmatic approach, and you are eager to apply it to your PRS projects. Qn1. May you outline the steps (analysis plan) that you will follow to apply the PRSmix approach to the trait you have been assigned. Indicate the metrics you will use to evaluate the predictivity of the PRS for the trait you have been assigned? Qn2. You have been given 15 to 23 PRSs, phenotype, age, sex and PCs depending on your group data files. May you implement your analysis plan and illustrate the codes and outputs that you will share in the form of an Rmarkdown file . May plot the predictivity of the PRSmix vs other PGS in your data file? Qn3. State the pros and cons of using the PRSmix approach in continental Africans? Figure 1 Predictivity of various PRSs compared to PRSmix (Adopted Buu et al. 2024) Group project data files Group 1 https://github.com/tinashedoc/cvx/blob/main/monodta.txt Group 2 https://github.com/tinashedoc/cvx/blob/main/wbcdta.txt Group 3 https://github.com/tinashedoc/cvx/blob/main/pltdta.txt Group 4 https://github.com/tinashedoc/cvx/blob/main/eosdta.txt","title":"Integration of Polygenic Risk Scores"},{"location":"tmp2/practical_docs_hidden/Day5_Projects/#integration-of-polygenic-risk-scores","text":"","title":"Integration of Polygenic Risk Scores"},{"location":"tmp2/practical_docs_hidden/Day5_Projects/#task-prsmix-calculation-35-hrs","text":"You have just completed the Wellcome Connecting Science PRS course and are now acquainted with tools such as PRSCSx and BRIDGEPRS. You also got to hear a talk by Prof Nilanjan Chatterjee, who you later realized has been involved in developing three latest PRS software programs, PROSPER, MUSSEL, and CT-SLEB, that claim to improve PRS prediction in Africans. You are now getting overwhelmed by the sheer number of tools to test out and do not know which tool to use for your PRS project, which involves continental Africans. You decide to read more, and you then stumble across a novel approach called PRSmix, which integrates PRSs developed using diverse methods, forming an integrated PRS that has been noted to outperform previously reported PRS, as shown below. This seems as a much more pragmatic approach, and you are eager to apply it to your PRS projects. Qn1. May you outline the steps (analysis plan) that you will follow to apply the PRSmix approach to the trait you have been assigned. Indicate the metrics you will use to evaluate the predictivity of the PRS for the trait you have been assigned? Qn2. You have been given 15 to 23 PRSs, phenotype, age, sex and PCs depending on your group data files. May you implement your analysis plan and illustrate the codes and outputs that you will share in the form of an Rmarkdown file . May plot the predictivity of the PRSmix vs other PGS in your data file? Qn3. State the pros and cons of using the PRSmix approach in continental Africans? Figure 1 Predictivity of various PRSs compared to PRSmix (Adopted Buu et al. 2024)","title":"Task \u2013 PRSmix calculation [3.5 hrs]"},{"location":"tmp2/practical_docs_hidden/Day5_Projects/#group-project-data-files","text":"","title":"Group project data files"},{"location":"tmp2/practical_docs_hidden/Day5_Projects/#group-1","text":"https://github.com/tinashedoc/cvx/blob/main/monodta.txt","title":"Group 1"},{"location":"tmp2/practical_docs_hidden/Day5_Projects/#group-2","text":"https://github.com/tinashedoc/cvx/blob/main/wbcdta.txt","title":"Group 2"},{"location":"tmp2/practical_docs_hidden/Day5_Projects/#group-3","text":"https://github.com/tinashedoc/cvx/blob/main/pltdta.txt","title":"Group 3"},{"location":"tmp2/practical_docs_hidden/Day5_Projects/#group-4","text":"https://github.com/tinashedoc/cvx/blob/main/eosdta.txt","title":"Group 4"},{"location":"tmp2/practical_docs_hidden/practical_images/base/","text":"A place to put the images for the course","title":"Base"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/","text":"Polygenic Risk Score Analyses Workshop 2022 {width=\"2.939998906386702in\" height=\"2.8874989063867016in\"} Day 2: Introduction to Polygenic Risk Scores Day 2 Timetable +------------+--------+-------------------------+---------------------+ | > Time | > T | | > **Presenter | | | itle** | | | +============+========+=========================+=====================+ | > 9:00 - | A | | > - | | > 9:15 | rrival | | | +------------+--------+-------------------------+---------------------+ | > 9:15 - | [Lec | > Introduction to PRS I | > Dr Paul O'Reilly | | > 10:30 | ture]{ | | | | | .under | | | | | line}: | | | +------------+--------+-------------------------+---------------------+ | 10:30 - | > | | > - | | 11:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 11:00 - | > [Lec | | > Dr Paul O'Reilly | | 12:00 | ture]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 12:00 - | > | | > - | | 13:30 | Lunch | | | +------------+--------+-------------------------+---------------------+ | 13:30 - | > | | > Dr Conrad Iyegbe | | 14:30 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > I | | | +------------+--------+-------------------------+---------------------+ | 14:30 - | > | | > - | | 15:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 15:00 - | > | | > Dr Conrad Iyegbe | | 16:00 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 16:00 - | > [S | | > Dr Nicki Tiffin | | 17:00 | pecial | | | | | > Sem | | | | | inar]{ | | | | | .under | | | | | line}: | | | | | > Pol | | | | | ygenic | | | | | > Risk | | | | | > | | | | | Scores | | | | | > | | | | | > + | | | | | > and | | | | | > | | | | | Ethics | | | +------------+--------+-------------------------+---------------------+ Contents Day 2 Timetable 1 Day 2 Timetable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction to Polygenic Score > Analyses 3 Key Learning Outcomes . . . . . . . . . . . . . . . . . . . . . . . . 3 Resources you will be using . . . . . . . . . . . . . . . . . . . . . . 3 Data Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Understanding GWAS Summary Statistics . . . . . . . . . . . . . . 5 Matching the Base and Target Data sets . . . . . . . . . . . . . . . 6 Linkage Disequilibrium in PRS Analyses . . . . . . . . . . . . . . . 7 Performing Clumping . . . . . . . . . . . . . . . . . . . . . . 7 P-Value Thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Height PRS using GW-significant SNPs only . . . . . . . . . 8 Height PRS across multiple P-value thresholds 10 High Resolution Scoring 12 Stratifying Samples by PRS 15 Case Control Studies 17 Cross-Trait Analysis 18 Introduction to Polygenic Score Analyses Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice (Euesden, Lewis & O'Reilly 2015; Choi & O'Reilly 2019) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome Wide Association Stud- ies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals ( wood_defining_2014 ) Download Link Coronary artery disease (CAD) CARDIoGRAM plus C4D consortium GWAS on 60,801 CAD cases and 123,504 controls Download Link (consortium_comprehensive_2015) Data Structure You will find all practical materials in the PRS_Workshop/Day_2 directory. Relevant materials that you should see there at the start of the practical are as follows: Practical Base_Data GIANT_Height.txt cad.add.txt cad.add.readme Target_Data TAR.fam TAR.bim TAR.bed TAR.height TAR.cad TAR.covariate Software plink_mac plink_linux plink.exe PRSice.R PRSice_mac PRSice_linux PRSice_win64.exe {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"} Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a pheno- type, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymor- phism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS sum- mary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs - and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed, where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"} Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes iden- tifying the independent genetic effects (or their best proxies if these are not geno- typed/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of meth- ods using the different options to date ( mak_polygenic_2017 ). In this work- shop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LD- pred ( vilhjalmsson_modeling_2015 ) and lassosum ( mak_polygenic_2017 ) papers. Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 > 0.1, with \ud835\udc5f 2 typically calculated from \ud835\udc5d\u210e\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \u210e\ud835\udc4e\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52 data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( chang_second_2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: 1 cd \\~/Desktop/PRS\\_Workshop/ Next type the following command (NB. See warning below): 1 ./Software/plink_linux 2 --bfile Target_Data/TAR 3 --clump Base_Data/GIANT_Height.txt 4 --clump-p1 1 5 --clump-snp-field MarkerName 6 --clump-field p 7 --clump-kb 250 8 --clump-r2 0.1 9 --out Results/Height {width=\"0.3229155730533683in\" height=\"0.3229166666666667in\"} The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 > 0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43 -value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43 -value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the PRS_Workshop/Day_2 directory, run the following command in the terminal: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --bar-levels 5e-8 14 --no-full 15 --fastscore 16 --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID (--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43 -value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addi- tion, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43 -value \\< 5*\u00d7*10 *\u2212*8 . {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the em- pirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"} Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43 -value threshold provides the \\\"best\\\" predic- tion for our particular data, then we can calculate the PRS under several \ud835\udc43 -value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. []{#_bookmark13 .anchor}Figure 1.1: BARPLOT generated by PRSice {width=\"2.7440616797900264in\" height=\"2.761874453193351in\"} See dudbridge_power_2013 for theory on factors affecting the best-fit PRS). This process is implemented in PRSice and can be performed automatically as fol- lows: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --fastscore 15 --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT (fig. 1.1) generated by PRSice {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43 -value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a large number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot (fig. 1.2) presenting the model fit of PRS calculated at all P-value thresholds. []{#_bookmark15 .anchor}Figure 1.2: High Resolution Plot generated by PRSice {width=\"2.463332239720035in\" height=\"2.455in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user in- puts, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --out Results/Height.sex When covariates were include in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43 \ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by minusing the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43 \ud835\udc45\ud835\udc46). Usually, with categorical variables, dummy variables have to be generated to rep- resent the different categories. Alternatively, residualized phenotype, generated by regresing the covariates against the phenotype, can be used for downstream anal- yses. A useful feature of PRSice is to automatically generate the dummy variable for users. This can be achieved with the following command: 1 Rscript.exe ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --cov-factor Sex 16 --out Results/Height.sex []{#_bookmark16 .anchor}Figure 1.3: Example of a quantile plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot (fig. 1.3). To generate quantile plots in PRSice, simply add --quantile 10 option. {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 10 17 --out Results/Height.sex {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} Figure 1.4: Example of a strata plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} A disadvantage of the quantile plot is that it only seperate samples into quantiles of equal size. However, it is somtimes interesting to investigate whether a specific strata (e.g. top 5% of samples), contain a higher PRS than the reference strata. For example, mavaddat_prediction_2015 found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break, which represents the upper bound of each strata, and --quant-ref, which represents the upper bound of the reference quantile: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 100 17 --quant-break 1,5,10,20,40,60,80,90,95,99,100 18 --quant-ref 60 19 --out Results/Height.sex {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Tar- get_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/cad.add.txt 4 --target Target_Data/TAR 5 --snp markername 6 --A1 effect_allele 7 --A2 noneffect_allele 8 --chr chr 9 --bp bp_hg19 10 --stat beta 11 --beta 12 --pvalue p_dgc 13 --pheno Target_Data/CAD.pheno 14 --binary-target T 15 --out Results/CAD.highres {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"3.5316666666666667in\" height=\"2.066457786526684in\"} []{#_bookmark19 .anchor}Figure 1.5: Plot taken from Ruderfer et al. 2014 {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ruderfer_polygenic_2014 (fig. 1.5), which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/CAD.pheno 12 --binary-target T 13 --out Results/Cross.highres {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Day2.docx"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#day-2-timetable","text":"+------------+--------+-------------------------+---------------------+ | > Time | > T | | > **Presenter | | | itle** | | | +============+========+=========================+=====================+ | > 9:00 - | A | | > - | | > 9:15 | rrival | | | +------------+--------+-------------------------+---------------------+ | > 9:15 - | [Lec | > Introduction to PRS I | > Dr Paul O'Reilly | | > 10:30 | ture]{ | | | | | .under | | | | | line}: | | | +------------+--------+-------------------------+---------------------+ | 10:30 - | > | | > - | | 11:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 11:00 - | > [Lec | | > Dr Paul O'Reilly | | 12:00 | ture]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 12:00 - | > | | > - | | 13:30 | Lunch | | | +------------+--------+-------------------------+---------------------+ | 13:30 - | > | | > Dr Conrad Iyegbe | | 14:30 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > I | | | +------------+--------+-------------------------+---------------------+ | 14:30 - | > | | > - | | 15:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 15:00 - | > | | > Dr Conrad Iyegbe | | 16:00 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 16:00 - | > [S | | > Dr Nicki Tiffin | | 17:00 | pecial | | | | | > Sem | | | | | inar]{ | | | | | .under | | | | | line}: | | | | | > Pol | | | | | ygenic | | | | | > Risk | | | | | > | | | | | Scores | | | | | > | | | | | > + | | | | | > and | | | | | > | | | | | Ethics | | | +------------+--------+-------------------------+---------------------+ Contents Day 2 Timetable 1 Day 2 Timetable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction to Polygenic Score > Analyses 3 Key Learning Outcomes . . . . . . . . . . . . . . . . . . . . . . . . 3 Resources you will be using . . . . . . . . . . . . . . . . . . . . . . 3 Data Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Understanding GWAS Summary Statistics . . . . . . . . . . . . . . 5 Matching the Base and Target Data sets . . . . . . . . . . . . . . . 6 Linkage Disequilibrium in PRS Analyses . . . . . . . . . . . . . . . 7 Performing Clumping . . . . . . . . . . . . . . . . . . . . . . 7 P-Value Thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Height PRS using GW-significant SNPs only . . . . . . . . . 8 Height PRS across multiple P-value thresholds 10 High Resolution Scoring 12 Stratifying Samples by PRS 15 Case Control Studies 17 Cross-Trait Analysis 18","title":"Day 2 Timetable"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#introduction-to-polygenic-score-analyses","text":"","title":"Introduction to Polygenic Score Analyses"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice (Euesden, Lewis & O'Reilly 2015; Choi & O'Reilly 2019) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome Wide Association Stud- ies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals ( wood_defining_2014 ) Download Link Coronary artery disease (CAD) CARDIoGRAM plus C4D consortium GWAS on 60,801 CAD cases and 123,504 controls Download Link","title":"Resources you will be using"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#consortium_comprehensive_2015","text":"","title":"(consortium_comprehensive_2015)"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#data-structure","text":"You will find all practical materials in the PRS_Workshop/Day_2 directory. Relevant materials that you should see there at the start of the practical are as follows: Practical Base_Data GIANT_Height.txt cad.add.txt cad.add.readme Target_Data TAR.fam TAR.bim TAR.bed TAR.height TAR.cad TAR.covariate Software plink_mac plink_linux plink.exe PRSice.R PRSice_mac PRSice_linux PRSice_win64.exe {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"}","title":"Data Structure"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a pheno- type, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymor- phism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Understanding GWAS Summary Statistics"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS sum- mary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs - and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed, where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"}","title":"Matching the Base and Target Data sets"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes iden- tifying the independent genetic effects (or their best proxies if these are not geno- typed/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of meth- ods using the different options to date ( mak_polygenic_2017 ). In this work- shop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LD- pred ( vilhjalmsson_modeling_2015 ) and lassosum ( mak_polygenic_2017 ) papers.","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 > 0.1, with \ud835\udc5f 2 typically calculated from \ud835\udc5d\u210e\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \u210e\ud835\udc4e\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52 data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( chang_second_2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: 1 cd \\~/Desktop/PRS\\_Workshop/ Next type the following command (NB. See warning below): 1 ./Software/plink_linux 2 --bfile Target_Data/TAR 3 --clump Base_Data/GIANT_Height.txt 4 --clump-p1 1 5 --clump-snp-field MarkerName 6 --clump-field p 7 --clump-kb 250 8 --clump-r2 0.1 9 --out Results/Height {width=\"0.3229155730533683in\" height=\"0.3229166666666667in\"} The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 > 0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Performing Clumping"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43 -value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43 -value thresholds.","title":"P-Value Thresholding"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the PRS_Workshop/Day_2 directory, run the following command in the terminal: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --bar-levels 5e-8 14 --no-full 15 --fastscore 16 --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID (--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43 -value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addi- tion, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43 -value \\< 5*\u00d7*10 *\u2212*8 . {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the em- pirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43 -value threshold provides the \\\"best\\\" predic- tion for our particular data, then we can calculate the PRS under several \ud835\udc43 -value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. []{#_bookmark13 .anchor}Figure 1.1: BARPLOT generated by PRSice {width=\"2.7440616797900264in\" height=\"2.761874453193351in\"} See dudbridge_power_2013 for theory on factors affecting the best-fit PRS). This process is implemented in PRSice and can be performed automatically as fol- lows: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --fastscore 15 --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT (fig. 1.1) generated by PRSice {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43 -value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a large number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot (fig. 1.2) presenting the model fit of PRS calculated at all P-value thresholds. []{#_bookmark15 .anchor}Figure 1.2: High Resolution Plot generated by PRSice {width=\"2.463332239720035in\" height=\"2.455in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user in- puts, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --out Results/Height.sex When covariates were include in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43 \ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by minusing the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43 \ud835\udc45\ud835\udc46). Usually, with categorical variables, dummy variables have to be generated to rep- resent the different categories. Alternatively, residualized phenotype, generated by regresing the covariates against the phenotype, can be used for downstream anal- yses. A useful feature of PRSice is to automatically generate the dummy variable for users. This can be achieved with the following command: 1 Rscript.exe ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --cov-factor Sex 16 --out Results/Height.sex []{#_bookmark16 .anchor}Figure 1.3: Example of a quantile plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"}","title":"High Resolution Scoring"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot (fig. 1.3). To generate quantile plots in PRSice, simply add --quantile 10 option. {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 10 17 --out Results/Height.sex {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} Figure 1.4: Example of a strata plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} A disadvantage of the quantile plot is that it only seperate samples into quantiles of equal size. However, it is somtimes interesting to investigate whether a specific strata (e.g. top 5% of samples), contain a higher PRS than the reference strata. For example, mavaddat_prediction_2015 found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break, which represents the upper bound of each strata, and --quant-ref, which represents the upper bound of the reference quantile: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 100 17 --quant-break 1,5,10,20,40,60,80,90,95,99,100 18 --quant-ref 60 19 --out Results/Height.sex {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"}","title":"Stratifying Samples by PRS"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Tar- get_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/cad.add.txt 4 --target Target_Data/TAR 5 --snp markername 6 --A1 effect_allele 7 --A2 noneffect_allele 8 --chr chr 9 --bp bp_hg19 10 --stat beta 11 --beta 12 --pvalue p_dgc 13 --pheno Target_Data/CAD.pheno 14 --binary-target T 15 --out Results/CAD.highres {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"3.5316666666666667in\" height=\"2.066457786526684in\"} []{#_bookmark19 .anchor}Figure 1.5: Plot taken from Ruderfer et al. 2014 {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Case Control Studies"},{"location":"tmp2/practical_docs_hidden/practical_images/Day2.docxfolder/Day2.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ruderfer_polygenic_2014 (fig. 1.5), which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/CAD.pheno 12 --binary-target T 13 --out Results/Cross.highres {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Cross-Trait Analysis"},{"location":"tmp2/practical_docs_hidden/practical_images/day3/base/","text":"base","title":"Base"},{"location":"tmp2/practical_docs_hidden/scripts/base/","text":"scripts base","title":"Base"},{"location":"tmp2/practical_docs_hidden/scripts/day4update/","text":"wget https://raw.githubusercontent.com/WCSCourses/PRS2024/main/scripts/prs24_day4_builds.sh chmod +x prs24_day4_builds.sh ./prs24_day4_builds.sh","title":"Day4update"},{"location":"tmp2/prs_2023-main/","text":"Polygenic Risk Scores Uganda 2023 Base for the Polygenic Risk Scores course Repository Course overview The boost in collections of African genomic datasets is providing opportunities for further in-depth understanding of the causes of human diseases. As African genomic data from genome-wide analytical studies continues to grow, it is imperative that African scientists are empowered with skills to analyse these data using the latest tools and approaches for advancing research and genomics applications in Africa and globally. This short course will equip scientists based in Africa with tools and approaches for polygenic risk scores (PRS) analysis. The course will cover both applied and theoretical topics in PRS research, delivered across a variety of lectures, tutorials, computational practicals and special guest seminars from experts in the field. By the end of the workshop, attendees should have an in-depth theoretical understanding and practical skills in PRS analysis of global populations. The course will begin with an overview of genome-wide association studies, an introduction to PRS analysis, advanced topics in PRS (e.g., pathway-based PRS, PRS Environment interactions, PRS to identify rare variants). This will be followed by the key topic of the \u2018PRS Portability Problem\u2019 and how to address it using PRS methods developed for application to diverse and admixed ancestry samples. Finally, attendees will devise, perform and present their own research project as part of a group on a topic relevant to the content of the course, with feedback from the workshop team. PRS Course website Instructors Marion Amujal , Makerere University, Uganda Shakuntala Baichoo , University of Mauritius, Mauritius Palwende Boua , Institut de Recherche en Sciences de la Sant\u00e9, Burkina Faso Tinashe Chikowore , University of the Witwatersrand, South Africa Itunuoluwa Isewon , Covenant University, Nigeria Conrad Iyegbe , Icahn School of Medicine, USA Christopher Kintu ,Makerere University, Uganda Carene Ndong Sima ,Stellenbosch University, South Africa Tsaone Tamuhla, University of Cape Town, South Africa Lesedi Williams , University of Botswana Overview Detailed timetable View Timetable here - \"in dev\" Course manual LMS LMS Link DAILY FEEDBACK Please provide anonymous feedback here Day 1 - GWAS and Relevant Statistics Day 1 Part A Online Manual Day 1 Part B Online Manual Day 2 - Introduction to PRS Day 2 Online Manual - Introduction to PRS Day 3 - Advanced PRS Analyses Day 3 Online Manual - Introduction to PRS Day 4 - Genetic Variation and Population Genetics Day 4 Online Manual - Introduction to PRS Day 5 - Group Projects Day 5 Project Description Appendix Any reuse of the course materials, data or code is encouraged with due acknowledgement. License This work is licensed under a Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) .","title":"Polygenic Risk Scores Uganda 2023"},{"location":"tmp2/prs_2023-main/#polygenic-risk-scores-uganda-2023","text":"Base for the Polygenic Risk Scores course Repository","title":"Polygenic Risk Scores Uganda 2023"},{"location":"tmp2/prs_2023-main/#course-overview","text":"The boost in collections of African genomic datasets is providing opportunities for further in-depth understanding of the causes of human diseases. As African genomic data from genome-wide analytical studies continues to grow, it is imperative that African scientists are empowered with skills to analyse these data using the latest tools and approaches for advancing research and genomics applications in Africa and globally. This short course will equip scientists based in Africa with tools and approaches for polygenic risk scores (PRS) analysis. The course will cover both applied and theoretical topics in PRS research, delivered across a variety of lectures, tutorials, computational practicals and special guest seminars from experts in the field. By the end of the workshop, attendees should have an in-depth theoretical understanding and practical skills in PRS analysis of global populations. The course will begin with an overview of genome-wide association studies, an introduction to PRS analysis, advanced topics in PRS (e.g., pathway-based PRS, PRS Environment interactions, PRS to identify rare variants). This will be followed by the key topic of the \u2018PRS Portability Problem\u2019 and how to address it using PRS methods developed for application to diverse and admixed ancestry samples. Finally, attendees will devise, perform and present their own research project as part of a group on a topic relevant to the content of the course, with feedback from the workshop team. PRS Course website","title":"Course overview"},{"location":"tmp2/prs_2023-main/#instructors","text":"Marion Amujal , Makerere University, Uganda Shakuntala Baichoo , University of Mauritius, Mauritius Palwende Boua , Institut de Recherche en Sciences de la Sant\u00e9, Burkina Faso Tinashe Chikowore , University of the Witwatersrand, South Africa Itunuoluwa Isewon , Covenant University, Nigeria Conrad Iyegbe , Icahn School of Medicine, USA Christopher Kintu ,Makerere University, Uganda Carene Ndong Sima ,Stellenbosch University, South Africa Tsaone Tamuhla, University of Cape Town, South Africa Lesedi Williams , University of Botswana","title":"Instructors"},{"location":"tmp2/prs_2023-main/#overview","text":"","title":"Overview"},{"location":"tmp2/prs_2023-main/#detailed-timetable","text":"View Timetable here - \"in dev\"","title":"Detailed timetable"},{"location":"tmp2/prs_2023-main/#course-manual","text":"LMS LMS Link DAILY FEEDBACK Please provide anonymous feedback here Day 1 - GWAS and Relevant Statistics Day 1 Part A Online Manual Day 1 Part B Online Manual Day 2 - Introduction to PRS Day 2 Online Manual - Introduction to PRS Day 3 - Advanced PRS Analyses Day 3 Online Manual - Introduction to PRS Day 4 - Genetic Variation and Population Genetics Day 4 Online Manual - Introduction to PRS Day 5 - Group Projects Day 5 Project Description Appendix Any reuse of the course materials, data or code is encouraged with due acknowledgement.","title":"Course manual"},{"location":"tmp2/prs_2023-main/#license","text":"This work is licensed under a Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) .","title":"License"},{"location":"tmp2/prs_2023-main/course_data/readME/","text":"This is a directory for course data Files can be uploaded via command line or web portal You can upload large files via git-lfs https://git-lfs.github.com","title":"This is a directory for course data"},{"location":"tmp2/prs_2023-main/course_data/readME/#this-is-a-directory-for-course-data","text":"Files can be uploaded via command line or web portal You can upload large files via git-lfs https://git-lfs.github.com","title":"This is a directory for course data"},{"location":"tmp2/prs_2023-main/images/base/","text":"A place to put the images for the course","title":"Base"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/","text":"Polygenic Risk Score Analyses Workshop 2022 {width=\"2.939998906386702in\" height=\"2.8874989063867016in\"} Day 2: Introduction to Polygenic Risk Scores Day 2 Timetable +------------+--------+-------------------------+---------------------+ | > Time | > T | | > **Presenter | | | itle** | | | +============+========+=========================+=====================+ | > 9:00 - | A | | > - | | > 9:15 | rrival | | | +------------+--------+-------------------------+---------------------+ | > 9:15 - | [Lec | > Introduction to PRS I | > Dr Paul O'Reilly | | > 10:30 | ture]{ | | | | | .under | | | | | line}: | | | +------------+--------+-------------------------+---------------------+ | 10:30 - | > | | > - | | 11:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 11:00 - | > [Lec | | > Dr Paul O'Reilly | | 12:00 | ture]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 12:00 - | > | | > - | | 13:30 | Lunch | | | +------------+--------+-------------------------+---------------------+ | 13:30 - | > | | > Dr Conrad Iyegbe | | 14:30 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > I | | | +------------+--------+-------------------------+---------------------+ | 14:30 - | > | | > - | | 15:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 15:00 - | > | | > Dr Conrad Iyegbe | | 16:00 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 16:00 - | > [S | | > Dr Nicki Tiffin | | 17:00 | pecial | | | | | > Sem | | | | | inar]{ | | | | | .under | | | | | line}: | | | | | > Pol | | | | | ygenic | | | | | > Risk | | | | | > | | | | | Scores | | | | | > | | | | | > + | | | | | > and | | | | | > | | | | | Ethics | | | +------------+--------+-------------------------+---------------------+ Contents Day 2 Timetable 1 Day 2 Timetable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction to Polygenic Score > Analyses 3 Key Learning Outcomes . . . . . . . . . . . . . . . . . . . . . . . . 3 Resources you will be using . . . . . . . . . . . . . . . . . . . . . . 3 Data Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Understanding GWAS Summary Statistics . . . . . . . . . . . . . . 5 Matching the Base and Target Data sets . . . . . . . . . . . . . . . 6 Linkage Disequilibrium in PRS Analyses . . . . . . . . . . . . . . . 7 Performing Clumping . . . . . . . . . . . . . . . . . . . . . . 7 P-Value Thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Height PRS using GW-significant SNPs only . . . . . . . . . 8 Height PRS across multiple P-value thresholds 10 High Resolution Scoring 12 Stratifying Samples by PRS 15 Case Control Studies 17 Cross-Trait Analysis 18 Introduction to Polygenic Score Analyses Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice (Euesden, Lewis & O'Reilly 2015; Choi & O'Reilly 2019) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome Wide Association Stud- ies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals ( wood_defining_2014 ) Download Link Coronary artery disease (CAD) CARDIoGRAM plus C4D consortium GWAS on 60,801 CAD cases and 123,504 controls Download Link (consortium_comprehensive_2015) Data Structure You will find all practical materials in the PRS_Workshop/Day_2 directory. Relevant materials that you should see there at the start of the practical are as follows: Practical Base_Data GIANT_Height.txt cad.add.txt cad.add.readme Target_Data TAR.fam TAR.bim TAR.bed TAR.height TAR.cad TAR.covariate Software plink_mac plink_linux plink.exe PRSice.R PRSice_mac PRSice_linux PRSice_win64.exe {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"} Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a pheno- type, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymor- phism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS sum- mary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs - and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed, where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"} Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes iden- tifying the independent genetic effects (or their best proxies if these are not geno- typed/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of meth- ods using the different options to date ( mak_polygenic_2017 ). In this work- shop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LD- pred ( vilhjalmsson_modeling_2015 ) and lassosum ( mak_polygenic_2017 ) papers. Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 > 0.1, with \ud835\udc5f 2 typically calculated from \ud835\udc5d\u210e\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \u210e\ud835\udc4e\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52 data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( chang_second_2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: 1 cd \\~/Desktop/PRS\\_Workshop/ Next type the following command (NB. See warning below): 1 ./Software/plink_linux 2 --bfile Target_Data/TAR 3 --clump Base_Data/GIANT_Height.txt 4 --clump-p1 1 5 --clump-snp-field MarkerName 6 --clump-field p 7 --clump-kb 250 8 --clump-r2 0.1 9 --out Results/Height {width=\"0.3229155730533683in\" height=\"0.3229166666666667in\"} The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 > 0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43 -value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43 -value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the PRS_Workshop/Day_2 directory, run the following command in the terminal: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --bar-levels 5e-8 14 --no-full 15 --fastscore 16 --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID (--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43 -value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addi- tion, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43 -value \\< 5*\u00d7*10 *\u2212*8 . {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the em- pirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"} Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43 -value threshold provides the \\\"best\\\" predic- tion for our particular data, then we can calculate the PRS under several \ud835\udc43 -value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. []{#_bookmark13 .anchor}Figure 1.1: BARPLOT generated by PRSice {width=\"2.7440616797900264in\" height=\"2.761874453193351in\"} See dudbridge_power_2013 for theory on factors affecting the best-fit PRS). This process is implemented in PRSice and can be performed automatically as fol- lows: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --fastscore 15 --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT (fig. 1.1) generated by PRSice {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43 -value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a large number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot (fig. 1.2) presenting the model fit of PRS calculated at all P-value thresholds. []{#_bookmark15 .anchor}Figure 1.2: High Resolution Plot generated by PRSice {width=\"2.463332239720035in\" height=\"2.455in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user in- puts, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --out Results/Height.sex When covariates were include in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43 \ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by minusing the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43 \ud835\udc45\ud835\udc46). Usually, with categorical variables, dummy variables have to be generated to rep- resent the different categories. Alternatively, residualized phenotype, generated by regresing the covariates against the phenotype, can be used for downstream anal- yses. A useful feature of PRSice is to automatically generate the dummy variable for users. This can be achieved with the following command: 1 Rscript.exe ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --cov-factor Sex 16 --out Results/Height.sex []{#_bookmark16 .anchor}Figure 1.3: Example of a quantile plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot (fig. 1.3). To generate quantile plots in PRSice, simply add --quantile 10 option. {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 10 17 --out Results/Height.sex {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} Figure 1.4: Example of a strata plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} A disadvantage of the quantile plot is that it only seperate samples into quantiles of equal size. However, it is somtimes interesting to investigate whether a specific strata (e.g. top 5% of samples), contain a higher PRS than the reference strata. For example, mavaddat_prediction_2015 found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break, which represents the upper bound of each strata, and --quant-ref, which represents the upper bound of the reference quantile: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 100 17 --quant-break 1,5,10,20,40,60,80,90,95,99,100 18 --quant-ref 60 19 --out Results/Height.sex {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Tar- get_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/cad.add.txt 4 --target Target_Data/TAR 5 --snp markername 6 --A1 effect_allele 7 --A2 noneffect_allele 8 --chr chr 9 --bp bp_hg19 10 --stat beta 11 --beta 12 --pvalue p_dgc 13 --pheno Target_Data/CAD.pheno 14 --binary-target T 15 --out Results/CAD.highres {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"3.5316666666666667in\" height=\"2.066457786526684in\"} []{#_bookmark19 .anchor}Figure 1.5: Plot taken from Ruderfer et al. 2014 {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ruderfer_polygenic_2014 (fig. 1.5), which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/CAD.pheno 12 --binary-target T 13 --out Results/Cross.highres {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Day2.docx"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#day-2-timetable","text":"+------------+--------+-------------------------+---------------------+ | > Time | > T | | > **Presenter | | | itle** | | | +============+========+=========================+=====================+ | > 9:00 - | A | | > - | | > 9:15 | rrival | | | +------------+--------+-------------------------+---------------------+ | > 9:15 - | [Lec | > Introduction to PRS I | > Dr Paul O'Reilly | | > 10:30 | ture]{ | | | | | .under | | | | | line}: | | | +------------+--------+-------------------------+---------------------+ | 10:30 - | > | | > - | | 11:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 11:00 - | > [Lec | | > Dr Paul O'Reilly | | 12:00 | ture]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 12:00 - | > | | > - | | 13:30 | Lunch | | | +------------+--------+-------------------------+---------------------+ | 13:30 - | > | | > Dr Conrad Iyegbe | | 14:30 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > I | | | +------------+--------+-------------------------+---------------------+ | 14:30 - | > | | > - | | 15:00 | Coffee | | | | | > | | | | | Break | | | | | > and | | | | | > Q&A | | | +------------+--------+-------------------------+---------------------+ | 15:00 - | > | | > Dr Conrad Iyegbe | | 16:00 | [Pract | | > & Tutors | | | ical]{ | | | | | .under | | | | | line}: | | | | | > | | | | | Introd | | | | | uction | | | | | > to | | | | | > PRS | | | | | > II | | | +------------+--------+-------------------------+---------------------+ | 16:00 - | > [S | | > Dr Nicki Tiffin | | 17:00 | pecial | | | | | > Sem | | | | | inar]{ | | | | | .under | | | | | line}: | | | | | > Pol | | | | | ygenic | | | | | > Risk | | | | | > | | | | | Scores | | | | | > | | | | | > + | | | | | > and | | | | | > | | | | | Ethics | | | +------------+--------+-------------------------+---------------------+ Contents Day 2 Timetable 1 Day 2 Timetable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction to Polygenic Score > Analyses 3 Key Learning Outcomes . . . . . . . . . . . . . . . . . . . . . . . . 3 Resources you will be using . . . . . . . . . . . . . . . . . . . . . . 3 Data Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Understanding GWAS Summary Statistics . . . . . . . . . . . . . . 5 Matching the Base and Target Data sets . . . . . . . . . . . . . . . 6 Linkage Disequilibrium in PRS Analyses . . . . . . . . . . . . . . . 7 Performing Clumping . . . . . . . . . . . . . . . . . . . . . . 7 P-Value Thresholding . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Height PRS using GW-significant SNPs only . . . . . . . . . 8 Height PRS across multiple P-value thresholds 10 High Resolution Scoring 12 Stratifying Samples by PRS 15 Case Control Studies 17 Cross-Trait Analysis 18","title":"Day 2 Timetable"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#introduction-to-polygenic-score-analyses","text":"","title":"Introduction to Polygenic Score Analyses"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice (Euesden, Lewis & O'Reilly 2015; Choi & O'Reilly 2019) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome Wide Association Stud- ies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals ( wood_defining_2014 ) Download Link Coronary artery disease (CAD) CARDIoGRAM plus C4D consortium GWAS on 60,801 CAD cases and 123,504 controls Download Link","title":"Resources you will be using"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#consortium_comprehensive_2015","text":"","title":"(consortium_comprehensive_2015)"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#data-structure","text":"You will find all practical materials in the PRS_Workshop/Day_2 directory. Relevant materials that you should see there at the start of the practical are as follows: Practical Base_Data GIANT_Height.txt cad.add.txt cad.add.readme Target_Data TAR.fam TAR.bim TAR.bed TAR.height TAR.cad TAR.covariate Software plink_mac plink_linux plink.exe PRSice.R PRSice_mac PRSice_linux PRSice_win64.exe {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"}","title":"Data Structure"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a pheno- type, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymor- phism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Understanding GWAS Summary Statistics"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS sum- mary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs - and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed, where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. {width=\"0.3229166666666667in\" height=\"0.3229166666666667in\"}","title":"Matching the Base and Target Data sets"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes iden- tifying the independent genetic effects (or their best proxies if these are not geno- typed/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of meth- ods using the different options to date ( mak_polygenic_2017 ). In this work- shop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LD- pred ( vilhjalmsson_modeling_2015 ) and lassosum ( mak_polygenic_2017 ) papers.","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 > 0.1, with \ud835\udc5f 2 typically calculated from \ud835\udc5d\u210e\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \u210e\ud835\udc4e\ud835\udc5d\ud835\udc59\ud835\udc5c\ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52 data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( chang_second_2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: 1 cd \\~/Desktop/PRS\\_Workshop/ Next type the following command (NB. See warning below): 1 ./Software/plink_linux 2 --bfile Target_Data/TAR 3 --clump Base_Data/GIANT_Height.txt 4 --clump-p1 1 5 --clump-snp-field MarkerName 6 --clump-field p 7 --clump-kb 250 8 --clump-r2 0.1 9 --out Results/Height {width=\"0.3229155730533683in\" height=\"0.3229166666666667in\"} The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 > 0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Performing Clumping"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43 -value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43 -value thresholds.","title":"P-Value Thresholding"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the PRS_Workshop/Day_2 directory, run the following command in the terminal: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --bar-levels 5e-8 14 --no-full 15 --fastscore 16 --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID (--snp), the effect allele (--A1), the non-effect allele (--A2), the effect size (--stat) and the \ud835\udc43 -value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addi- tion, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43 -value \\< 5*\u00d7*10 *\u2212*8 . {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the em- pirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43 -value threshold provides the \\\"best\\\" predic- tion for our particular data, then we can calculate the PRS under several \ud835\udc43 -value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. []{#_bookmark13 .anchor}Figure 1.1: BARPLOT generated by PRSice {width=\"2.7440616797900264in\" height=\"2.761874453193351in\"} See dudbridge_power_2013 for theory on factors affecting the best-fit PRS). This process is implemented in PRSice and can be performed automatically as fol- lows: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --fastscore 15 --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT (fig. 1.1) generated by PRSice {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43 -value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a large number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: 1 Rscript ./Software/PRSice.R 2 --dir . 3 --prsice Software/PRSice_linux 4 --base Base_Data/GIANT_Height.txt 5 --target Target_Data/TAR 6 --snp MarkerName 7 --A1 Allele1 8 --A2 Allele2 9 --stat b 10 --beta 11 --pvalue p 12 --pheno Target_Data/TAR.height 13 --binary-target F 14 --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot (fig. 1.2) presenting the model fit of PRS calculated at all P-value thresholds. []{#_bookmark15 .anchor}Figure 1.2: High Resolution Plot generated by PRSice {width=\"2.463332239720035in\" height=\"2.455in\"} {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"} Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user in- puts, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --out Results/Height.sex When covariates were include in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43 \ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by minusing the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"0.3541666666666667in\" height=\"0.3593744531933508in\"}\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43 \ud835\udc45\ud835\udc46). Usually, with categorical variables, dummy variables have to be generated to rep- resent the different categories. Alternatively, residualized phenotype, generated by regresing the covariates against the phenotype, can be used for downstream anal- yses. A useful feature of PRSice is to automatically generate the dummy variable for users. This can be achieved with the following command: 1 Rscript.exe ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --cov-factor Sex 16 --out Results/Height.sex []{#_bookmark16 .anchor}Figure 1.3: Example of a quantile plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"}","title":"High Resolution Scoring"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot (fig. 1.3). To generate quantile plots in PRSice, simply add --quantile 10 option. {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 10 17 --out Results/Height.sex {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} Figure 1.4: Example of a strata plot generated by PRSice {width=\"2.4641655730533683in\" height=\"2.4674989063867017in\"} A disadvantage of the quantile plot is that it only seperate samples into quantiles of equal size. However, it is somtimes interesting to investigate whether a specific strata (e.g. top 5% of samples), contain a higher PRS than the reference strata. For example, mavaddat_prediction_2015 found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break, which represents the upper bound of each strata, and --quant-ref, which represents the upper bound of the reference quantile: 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/TAR.height 12 --binary-target F 13 --cov Target_Data/TAR.covariate 14 --cov-col Sex 15 --plot 16 --quantile 100 17 --quant-break 1,5,10,20,40,60,80,90,95,99,100 18 --quant-ref 60 19 --out Results/Height.sex {width=\"0.3281244531933508in\" height=\"0.3281244531933508in\"}","title":"Stratifying Samples by PRS"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Tar- get_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/cad.add.txt 4 --target Target_Data/TAR 5 --snp markername 6 --A1 effect_allele 7 --A2 noneffect_allele 8 --chr chr 9 --bp bp_hg19 10 --stat beta 11 --beta 12 --pvalue p_dgc 13 --pheno Target_Data/CAD.pheno 14 --binary-target T 15 --out Results/CAD.highres {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} {width=\"3.5316666666666667in\" height=\"2.066457786526684in\"} []{#_bookmark19 .anchor}Figure 1.5: Plot taken from Ruderfer et al. 2014 {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Case Control Studies"},{"location":"tmp2/prs_2023-main/images/Day2.docxfolder/Day2.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ruderfer_polygenic_2014 (fig. 1.5), which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. {width=\"0.34781167979002625in\" height=\"0.34781167979002625in\"} 1 Rscript ./Software/PRSice.R 2 --prsice Software/PRSice_linux 3 --base Base_Data/GIANT_Height.txt 4 --target Target_Data/TAR 5 --snp MarkerName 6 --A1 Allele1 7 --A2 Allele2 8 --stat b 9 --beta 10 --pvalue p 11 --pheno Target_Data/CAD.pheno 12 --binary-target T 13 --out Results/Cross.highres {width=\"0.3541655730533683in\" height=\"0.3593744531933508in\"}","title":"Cross-Trait Analysis"},{"location":"tmp2/prs_2023-main/images/day3/base/","text":"base","title":"Base"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/","text":"Polygenic Risk Score Analyses Workshop 2023 Day 1a: GWAS & relevant Statistics Introduction to Bash Most software in Bioinformatics and Statistical Genetics need to be run in a Unix environment (e.g. Linux or Mac OS) and most high-performance computer clusters run Unix systems. Therefore, although there are alternatives available on Windows (command line, Linux subsystems or Virtual Machines), it will be highly beneficial to become familiar with performing research in a Unix-only environment. Moving around the File System To begin our practical, please open up a \\\"terminal\\\" on your computer (on a Mac this is stored in Applications/Utilities/). We can change our directory using the following command: cd \\<Path>\\ where *\\ * is the path to the target directory. Some common usage of cd includes cd ~/ # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd XXX # will bring you to the XXX directory, so long as it is in the current directory As an example, we can move to the data directory by typing: cd data/ Looking at the Current Directory Next we can move into the ~/data/Data_Day1b/ folder (from the data/ folder type: cd Data_Day1b/). We can list out the folder content by typing: ls For ls, there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size Counting Number of Lines in File We can also count the number of lines in a file with the following command (where *\\ * is the file of interest): wc -l <file> Often we would like to store the output of a command, which we can do by redirecting the output of the command to a file. For example, we can redirect the count of the GIANT_Height.txt to giant_count using the following command: wc -l GIANT_Height.txt > giant_count.txt Search File Content Another common task is to search for specific words or characters in a file (e.g. does this file contain our gene of interest?). This can be performed using the \"grep\" command as follows: grep <string> file For example, to check if the Single Nucleotide Polymorphism (SNP) rs10786427 is present in GIANT_Height.txt , we can do: grep rs10786427 GIANT_Height.txt In addition, grep allows us to check if patterns contained in one file can be found in another file. For example, if we want to extract a subset of samples from the phenotype file (e.g. extract the list of samples in Data/Day_1a/TAR.height ), we can do: grep -f Select.sample TAR.height An extremely useful feature of the terminal is chaining multiple commands into one command, which we call piping . For example, we can use piping to count the number of samples in Select.sample that were found in TAR.height in a single command, as follows: bash grep -f Select.sample TAR.height | wc -l Filtering and Reshu\ufb04ing Files A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new results file that only contains SNP rsIDs (column 1), allele frequencies (column 4) and P -values (column 7) as follows: awk '{ print $1,$4,$7}' GIANT_Height.txt > GIANT_Height_3cols.txt We can also use a \\\"conditional statement\\\" in awk to extract all significant [SNPs] from the results file, using the following command: awk '{if($7 < 5e-8) { print } }' GIANT_Height.txt > Significant_SNPs.txt Or the short form: awk '$7 < 5e-8{ print}' GIANT_Height.txt > Significant_SNPs.txt \"if( \\(7<5e-8)\" and \"\\) 7 < 5e-8\" tell awk to extract any rows with column 7 (the column containing P -value) with a value of smaller than 5e-8 and {print} means that we would like to print the entire row when this criterion is met. Introduction to R R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop. Basics If you are not using R Studio then you can type R in your terminal to run R in the terminal. ## Adding script to working dir cd ~/data/Day1a_Data/Day1a_Data wget https://raw.githubusercontent.com/WCSCourses/prs_2023/main/scripts/nagelkerke.R Working Directory When we start R , we will be working in a specific folder called the working directory . We can check the current/working directory we are in by typing: getwd() And we can change our working directory to the Practical folder by setwd(\"~/data/Day1a_Data/Day1a_Data\") Libraries Most functionality of R is organised in \\\"packages\\\" or \\\"libraries\\\". To access these functions, we will have to install and \\\"load\\\" these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Alternatively, we can import functions (e.g. that we have written) from an R script file on our computer. For example, you can load the Nagelkerke R2 function by typing source(\"nagelkerke.R\") And you are now able to use the Nagelkerke R2 function (we will use this function at the end of this worksheet). Variables in R You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\") Functions You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2) Plotting While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point() Regression Models In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial)) We will need the NagelkerkeR2 function to calculate the pseudo R2 for logistic model source(\"Software/nagelkerke.R\") reg <- glm(y~x, family=binomial) Calculate the Nagelkerke R2 using the NagelkerkeR2 function NagelkerkeR2(reg)","title":"Polygenic Risk Score Analyses Workshop 2023"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#polygenic-risk-score-analyses-workshop-2023","text":"","title":"Polygenic Risk Score Analyses Workshop 2023"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#day-1a-gwas-relevant-statistics","text":"","title":"Day 1a: GWAS &amp; relevant Statistics"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#introduction-to-bash","text":"Most software in Bioinformatics and Statistical Genetics need to be run in a Unix environment (e.g. Linux or Mac OS) and most high-performance computer clusters run Unix systems. Therefore, although there are alternatives available on Windows (command line, Linux subsystems or Virtual Machines), it will be highly beneficial to become familiar with performing research in a Unix-only environment.","title":"Introduction to Bash"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#moving-around-the-file-system","text":"To begin our practical, please open up a \\\"terminal\\\" on your computer (on a Mac this is stored in Applications/Utilities/). We can change our directory using the following command: cd \\<Path>\\ where *\\ * is the path to the target directory. Some common usage of cd includes cd ~/ # will bring you to your home directory cd ../ # will bring you to the parent directory (up one level) cd XXX # will bring you to the XXX directory, so long as it is in the current directory As an example, we can move to the data directory by typing: cd data/","title":"Moving around the File System"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#looking-at-the-current-directory","text":"Next we can move into the ~/data/Data_Day1b/ folder (from the data/ folder type: cd Data_Day1b/). We can list out the folder content by typing: ls For ls, there are a number of additional Unix command options that you can append to it to get additional information, for example: ls -l # shows files as list ls -lh # shows files as a list with human readable format ls -lt # shows the files as a list sorted by time-last-edited ls -lS # shows the files as a list sorted by size","title":"Looking at the Current Directory"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#counting-number-of-lines-in-file","text":"We can also count the number of lines in a file with the following command (where *\\ * is the file of interest): wc -l <file> Often we would like to store the output of a command, which we can do by redirecting the output of the command to a file. For example, we can redirect the count of the GIANT_Height.txt to giant_count using the following command: wc -l GIANT_Height.txt > giant_count.txt","title":"Counting Number of Lines in File"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#search-file-content","text":"Another common task is to search for specific words or characters in a file (e.g. does this file contain our gene of interest?). This can be performed using the \"grep\" command as follows: grep <string> file For example, to check if the Single Nucleotide Polymorphism (SNP) rs10786427 is present in GIANT_Height.txt , we can do: grep rs10786427 GIANT_Height.txt In addition, grep allows us to check if patterns contained in one file can be found in another file. For example, if we want to extract a subset of samples from the phenotype file (e.g. extract the list of samples in Data/Day_1a/TAR.height ), we can do: grep -f Select.sample TAR.height An extremely useful feature of the terminal is chaining multiple commands into one command, which we call piping . For example, we can use piping to count the number of samples in Select.sample that were found in TAR.height in a single command, as follows: bash grep -f Select.sample TAR.height | wc -l","title":"Search File Content"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#filtering-and-reshuffling-files","text":"A very powerful feature of the terminal is the awk programming language, which allows us to extract subsets of a data file, filter data according to some criteria or perform arithmetic operations on the data. awk manipulates a data file by per- forming operations on its columns - this is extremely useful for scientific data sets because typically the columns features or variables of interest. For example, we can use awk to produce a new results file that only contains SNP rsIDs (column 1), allele frequencies (column 4) and P -values (column 7) as follows: awk '{ print $1,$4,$7}' GIANT_Height.txt > GIANT_Height_3cols.txt We can also use a \\\"conditional statement\\\" in awk to extract all significant [SNPs] from the results file, using the following command: awk '{if($7 < 5e-8) { print } }' GIANT_Height.txt > Significant_SNPs.txt Or the short form: awk '$7 < 5e-8{ print}' GIANT_Height.txt > Significant_SNPs.txt \"if( \\(7<5e-8)\" and \"\\) 7 < 5e-8\" tell awk to extract any rows with column 7 (the column containing P -value) with a value of smaller than 5e-8 and {print} means that we would like to print the entire row when this criterion is met.","title":"Filtering and Reshu\ufb04ing Files"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#introduction-to-r","text":"R is a useful programming language that allows us to perform a variety of statis- tical tests and data manipulation. It can also be used to generate fantastic data visualisations. Here we will go through some of the basics of R so that you can better understand the practicals throughout the workshop.","title":"Introduction to R"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#basics","text":"If you are not using R Studio then you can type R in your terminal to run R in the terminal. ## Adding script to working dir cd ~/data/Day1a_Data/Day1a_Data wget https://raw.githubusercontent.com/WCSCourses/prs_2023/main/scripts/nagelkerke.R","title":"Basics"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#working-directory","text":"When we start R , we will be working in a specific folder called the working directory . We can check the current/working directory we are in by typing: getwd() And we can change our working directory to the Practical folder by setwd(\"~/data/Day1a_Data/Day1a_Data\")","title":"Working Directory"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#libraries","text":"Most functionality of R is organised in \\\"packages\\\" or \\\"libraries\\\". To access these functions, we will have to install and \\\"load\\\" these packages. Most commonly used packages are installed together with the standard installation process. You can install a new library using the install.packages function. For example, to install ggplot2 , run the command: install.packages(\"ggplot2\") After installation, you can load the library by typing library(ggplot2) Alternatively, we can import functions (e.g. that we have written) from an R script file on our computer. For example, you can load the Nagelkerke R2 function by typing source(\"nagelkerke.R\") And you are now able to use the Nagelkerke R2 function (we will use this function at the end of this worksheet).","title":"Libraries"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#variables-in-r","text":"You can assign a value or values to any variable you want using \\<-. e.g Assign a number to a a <- 1 Assign a vector containing a,b,c to v1 v1 <- c(\"a\", \"b\",\"c\")","title":"Variables in R"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#functions","text":"You can perform lots of operations in R using di\ufb00erent built-in R functions. Some examples are below: Assign number of samples nsample <- 10000 Generate nsample random normal variable with mean = 0 and sd = 1 normal <- rnorm(nsample, mean=0,sd=1) normal.2 <- rnorm(nsample, mean=0,sd=1) We can examine the first few entries of the result using head head(normal) And we can obtain the mean and sd using mean(normal) sd(normal) We can also calculate the correlation between two variables using cor cor(normal, normal.2)","title":"Functions"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#plotting","text":"While R contains many powerful plotting functions in its base packages,customisationn can be di\ufb03cult (e.g. changing the colour scales, arranging the axes). ggplot2 is a powerful visualization package that provides extensive flexibility and customi- sation of plots. As an example, we can do the following Load the package library(ggplot2) Specify sample size nsample <-1000 Generate random grouping using sample with replacement groups <- sample(c(\"a\",\"b\"), nsample, replace=T) Now generate the data dat <- data.frame(x=rnorm(nsample), y=rnorm(nsample), groups) Generate a scatter plot with di\ufb00erent coloring based on group ggplot(dat, aes(x=x,y=y,color=groups))+geom_point()","title":"Plotting"},{"location":"tmp2/prs_2023-main/modules/Day1a.docx/#regression-models","text":"In statistical modelling, regression analyses are a set of statistical techniques for estimating the relationships among variables or features. We can perform regression analysis in R . Use the following code to perform linear regression on simulated variables \"x\" and \"y\": Simulate data nsample <- 10000 x <- rnorm(nsample) y <- rnorm(nsample) Run linear regression lm(y~x) We can store the result into a variable reg <- lm(y~x) And get a detailed output using summary summary(lm(y~x)) We can also extract the coe\ufb03cient of regression using reg$coe\ufb03cient And we can obtain the residuals by residual <- resid(reg) Examine the first few entries of residuals head(residual) We can also include covariates into the model covar <- rnorm(nsample) lm(y~x+covar) And can even perform interaction analysis lm(y~x+covar+x*covar) Alternatively, we can use the glm function to perform the regression: glm(y~x) For binary traits (case controls studies), logistic regression can be performed using Simulate samples nsample <- 10000 x <- rnorm(nsample) Simulate binary traits (must be coded with 0 and 1) y <- sample(c(0,1), size=nsample, replace=T) Perform logistic regression glm(y~x, family=binomial) Obtain the detailed output summary(glm(y~x, family=binomial)) We will need the NagelkerkeR2 function to calculate the pseudo R2 for logistic model source(\"Software/nagelkerke.R\") reg <- glm(y~x, family=binomial) Calculate the Nagelkerke R2 using the NagelkerkeR2 function NagelkerkeR2(reg)","title":"Regression Models"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/","text":"Polygenic Risk Score Analyses Workshop 2023 Practical 1 Introduction to PLINK I: basics Key Learning Outcomes After completing this practical, you should be able to: Explore and generate genetic data sets needed for GWAS Recode and reorder allelic data Use the PLINK website 4. Select and exclude lists of samples and SNPs \u26a0\ufe0f All data used in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Introduction PLINK is the most popular software program for performing genome-wide association analyses it is extremely extensive, allowing a huge number of analyses to be performed. It also includes many options for reformatting your data and provides useful data summaries. Software packages are usually best learnt by having a go at running some of their basic applications and progressing from there (rather than reading the entire user manual first!) - so we begin by running some basic PLINK commands and then work steadily towards performing more sophisticated analyses through these PLINK tutorials. Command line basics In all of the instructions below: - Anything in between the symbols \\<> needs to be changed in some way. For example, \\<file_name> indicates that you should replace that entire statement (including the \\<> symbols) with the appropriate file name. - Bold indicates non- command-line instructions (e.g. right-click ) Let's begin Open up a terminal Navigate to the Day 1b working directory cd ~/data/Data_Day1b/ List all files in this directory by typing ls Test PLINK with no input by typing plink Note that you can see lots of PLINK options by using the built-in help function: plink --help \ud83d\udcdd Calling PLINK with no output will test if PLINK is installed and available in the directory, because you should see some output showing the PLINK license and some commands. If you do not see this, then please ask for help now! Exploring Data Sets Open an Explorer window ('Finder' on a Mac) and navigate to your PLINK working directory. \ud83d\udcdd An explorer window should show the same files as the ls command Open the file called 'D1D.map' with a Text Editor e.g. by typing right-click > Open . Open the file 'D1D.ped'. Note this is a large file - if it will not open or is very slow, skip this step. Go to the PLINK website http://zzz.bwh.harvard.edu/plink/download.shtml and investigate the format of the MAP/PED files (Look in the blue column on the left side) What do you observe? - What are the 4 columns in the map file? - What are the first 6 columns in a ped file? - What information is in the remaining columns of the ped file? Create 'binary' format PLINK files using the recode command: plink --file D1D --make-bed --out D1D List files ( ls ) and check which new files have appeared Open and examine files ending .bim and .fam. Do not open the .bed file. Open and skim the '.log' file. What do you observe? How is the fam file similar to the ped file? How is it different? How is the bim file similar to the map file? How is it different? (Use the PLINK website if necessary) Recoding alleles as counts Genotype data in allele count format is very useful, for example to use in regression modelling in statistical software such as R. Generate the D1D data in allele count format: plink --bfile D1D --recodeA --out D1D_AC \ud83d\udcdd There are several options for recoding SNPs in different ways - more information on the PLINK website (see next section). Again note that a log file was created - skim the log file or screen output Look inside the .raw file. What do you think the 0/1/2 represent? Do there appear to be more 0s or 2s? Why might this be? PLINK website Go to http://zzz.bwh.harvard.edu/plink/download.shtml and skim through the front page to get an idea of PLINK's functionality. Note the list of clickable links on the left side of the website. Under 'Data Management' (click the heading on the left) and read the list of the di\ufb00erent ways you may want to recode and reorder data sets. Don't attempt to read much further as this is a very large and detailed section - a useful future resource but too much for today. Under 'Data Management', click 'Write SNP list' and read the instructions there to write SNP lists. Write SNP list and extract SNPs You will now use the information that you found on the PLINK website to create a command to extract a list of SNPs. Below is a list of requirements - try to do this before you go to the end of this section, where the full command is given and explained. Set the D1D binary file as input Set MAF threshold to 0.05 Set SNP missingness threshold to 0.05 Add the appropriate command to write out a snp list containing only those SNPs with MAF above 0.05 and missingness below 0.05 Use 'D1D_snps' as the output file name After the command has run, check the output for your SNP list and look at it with the default viewer. You will now use the SNP list that you have created to extract those SNPs and create a new set of data files in a single command. Use the D1D binary file set as input Find the command for extracting a set of SNPs listed in a file (hint: Data Management section) and combine it with a command that you learned above to create binary files Use the output file name 'D1D_MAF_MISS' \ud83d\udcdd Log files are uselful to check that the number of SNPs and samples is as expected. Always check your your log files to ensure that they are sensible. SNP lists can also be used to EXCLUDE SNPs - select 'exclude' above instead of 'extract'. Sample ID lists can also be used to 'keep' or 'remove' individuals in the same 'filter' window. Note that both sample IDs (FID IID,separated by a space are required in the sample file list. Solution 1: TO BE REVEALED LATER!! Solution 2: TO BE REVEALED LATER!! Practical 2 Introduction to PLINK II: Performing QC & GWAS Key Learning Outcomes After completing this practical, you should be able to: Generate summaries of the data needed for QC Apply QC thresholds Perform GWAS Generate summaries to perform QC There are many kinds of summaries of the data that can generated in PLINK in order to perform particular quality control (QC) steps, which help to make our data more reliable. Some of these involve summaries in relation to the individuals (e.g. individual missingness, sex-check) and some relate to summaries of SNP data (e.g. MAF, Hardy-Weinburg Equilibrium). Over the next few sub-sections you will go through some examples of generating summary statistics that can be used to perform QC. Individual missingness Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Open the 2 files that were generated (lmiss & imiss). What do the two output files contain? In the imiss file, what is the meaning of the data in the column headed \"F_MISS\"? SNP Missingness Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Look inside the file containing SNP missingness information: D1D_miss.lmiss. What is the meaning of the value under F_MISS? What does the command --test-missing do and why might it be useful? Hardy-Weinberg Equilibrium Generate HWE statistics using the --hardy option. Use output file name D1D_hardy. Open and examine results. Why are there multiple rows for each SNP and what does each mean? Which of the rows do you think should be used to exclude SNPs from the subsequent analysis (if any) for failing the HWE test? Why? Allele frequencies Generate allele frequencies using the command *--*freq. Use D1D_freq as the output name. Examine the output. What is the heading of the column that tells you which nucleotide is the minor allele? \ud83d\udcdd This information is important to remember as many PLINK files use this notation. The minor allele is always labeled the same way Apply QC filters There are di\ufb00erent strategies for performing QC on your data: (a) Create lists of SNPs and individuals and use --remove, --extract, --exclude, --include to create new file sets (good for documentation, collaboration) (b) Apply thresholds one at a time and generate new bed/bim/fam file (good for applying sequential filters) (c) Use options (e.g. --maf ) in other commands (e.g. --assoc) to remove SNPs or samples at required QC thresholds during analysis. \ud83d\udcdd We have already seen how to select or exclude individuals or SNPs by first creating lists (a), so in this section we will set thresholds to generate new files sets in a single command. However, it is useful to have lists of all SNPs and individuals excluded pre-analysis, according to the reason for exclusion, so generating and retaining such files using the techniques that we used before for good practice. Apply individual missingness thresholds Generate new binary file sets (--make-bed) from the 'D1D' binary file set, removing individuals with missingness greater than 3% using a single command (hint: In the 'Inclusion thresholds' section, see the 'Missing/person' sub-section). Use the output file name 'D1D_imiss3pc' Examine the output files (no need to open, and remember the bed file cannot be read) and the log file How many individuals were in the original file? How many individuals were removed? How many males and females were left after screening? Apply SNP missingness and MAF thresholds Create new binary file sets from the 'D1D_imiss3pc' binary file set (NOT the original D1D files) by setting MAF threshold to 0.05 and SNP missingness threshold to 0.02 (See 'Inclusion thresholds' to obtain the correct threshold flags). Use the output file name'D1D_imiss3pc_lmiss2pc_maf5pc Examine the output files and the log file How many SNPs were in the original files? How many SNPs were removed for low minor allele frequency? How many SNPs were removed for missingness? Apply Hardy-Weinberg thresholds Generate a new binary file set called 'D1D_QC' from the D1D_imiss3pc_lmiss2pc_maf5pc file, applying a HWE threshold of 0.0001. This is our final, QC'ed file set. Examine log and output files. -How many SNPs were removed for HWE p-values below the threshold? \ud83d\udcdd It is useful to know how to do this, but be careful about setting this threshold - strong association signals can cause departure from HWE and you may remove great results! Use a lenient threshold and apply to controls only to avoid this problem. HWE can also be checked post-hoc for each SNP. Perform GWAS Case/Control GWAS - no covariates Run the following code, which performs a genetic association study using logistic regression on some case/control data: plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --out D1D_CC What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Are there any other significant associations? Case/Control GWAS - with covariates Here we repeat the previous analysis but this time including some covariates. The file D1D.pcs1234 contains the first 4 principal components from a PCA on the genetic data. Run the analysis specifying the covariates file: plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --covar D1D.pcs.1234 --out D1D_CC_PCadj What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Suggest a reason for the different results when adjusting for the 4 PCs? License This work is licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License and the below text is a summary of the main terms of the full Legal Code (the full licence) available at https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode You are free to: Share --- copy and redistribute the material in any medium or format Adapt --- remix, transform, and build upon the material The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: Attribution --- You must give appropriate credit, providea link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. NonCommercial --- You may not use the material for commercial purposes. ShareAlike --- If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictions --- You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. Notices: You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation. No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.","title":"Day1b.docx"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#practical-1","text":"","title":"Practical 1"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#introduction-to-plink-i-basics","text":"","title":"Introduction to PLINK I: basics"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Explore and generate genetic data sets needed for GWAS Recode and reorder allelic data Use the PLINK website","title":"Key Learning Outcomes"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#4-select-and-exclude-lists-of-samples-and-snps","text":"\u26a0\ufe0f All data used in this workshop are simulated . They have no specific biological meaning and are for demonstration purposes only.","title":"4.  Select and exclude lists of samples and SNPs"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#introduction","text":"PLINK is the most popular software program for performing genome-wide association analyses it is extremely extensive, allowing a huge number of analyses to be performed. It also includes many options for reformatting your data and provides useful data summaries. Software packages are usually best learnt by having a go at running some of their basic applications and progressing from there (rather than reading the entire user manual first!) - so we begin by running some basic PLINK commands and then work steadily towards performing more sophisticated analyses through these PLINK tutorials.","title":"Introduction"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#command-line-basics","text":"In all of the instructions below: - Anything in between the symbols \\<> needs to be changed in some way. For example, \\<file_name> indicates that you should replace that entire statement (including the \\<> symbols) with the appropriate file name. - Bold indicates non- command-line instructions (e.g. right-click )","title":"Command line basics"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#lets-begin","text":"Open up a terminal Navigate to the Day 1b working directory cd ~/data/Data_Day1b/ List all files in this directory by typing ls Test PLINK with no input by typing plink Note that you can see lots of PLINK options by using the built-in help function: plink --help \ud83d\udcdd Calling PLINK with no output will test if PLINK is installed and available in the directory, because you should see some output showing the PLINK license and some commands. If you do not see this, then please ask for help now!","title":"Let's begin"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#exploring-data-sets","text":"Open an Explorer window ('Finder' on a Mac) and navigate to your PLINK working directory. \ud83d\udcdd An explorer window should show the same files as the ls command Open the file called 'D1D.map' with a Text Editor e.g. by typing right-click > Open . Open the file 'D1D.ped'. Note this is a large file - if it will not open or is very slow, skip this step. Go to the PLINK website http://zzz.bwh.harvard.edu/plink/download.shtml and investigate the format of the MAP/PED files (Look in the blue column on the left side) What do you observe? - What are the 4 columns in the map file? - What are the first 6 columns in a ped file? - What information is in the remaining columns of the ped file? Create 'binary' format PLINK files using the recode command: plink --file D1D --make-bed --out D1D List files ( ls ) and check which new files have appeared Open and examine files ending .bim and .fam. Do not open the .bed file. Open and skim the '.log' file. What do you observe? How is the fam file similar to the ped file? How is it different? How is the bim file similar to the map file? How is it different? (Use the PLINK website if necessary)","title":"Exploring Data Sets"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#recoding-alleles-as-counts","text":"Genotype data in allele count format is very useful, for example to use in regression modelling in statistical software such as R. Generate the D1D data in allele count format: plink --bfile D1D --recodeA --out D1D_AC \ud83d\udcdd There are several options for recoding SNPs in different ways - more information on the PLINK website (see next section). Again note that a log file was created - skim the log file or screen output Look inside the .raw file. What do you think the 0/1/2 represent? Do there appear to be more 0s or 2s? Why might this be?","title":"Recoding alleles as counts"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#plink-website","text":"Go to http://zzz.bwh.harvard.edu/plink/download.shtml and skim through the front page to get an idea of PLINK's functionality. Note the list of clickable links on the left side of the website. Under 'Data Management' (click the heading on the left) and read the list of the di\ufb00erent ways you may want to recode and reorder data sets. Don't attempt to read much further as this is a very large and detailed section - a useful future resource but too much for today. Under 'Data Management', click 'Write SNP list' and read the instructions there to write SNP lists.","title":"PLINK website"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#write-snp-list-and-extract-snps","text":"You will now use the information that you found on the PLINK website to create a command to extract a list of SNPs. Below is a list of requirements - try to do this before you go to the end of this section, where the full command is given and explained. Set the D1D binary file as input Set MAF threshold to 0.05 Set SNP missingness threshold to 0.05 Add the appropriate command to write out a snp list containing only those SNPs with MAF above 0.05 and missingness below 0.05 Use 'D1D_snps' as the output file name After the command has run, check the output for your SNP list and look at it with the default viewer. You will now use the SNP list that you have created to extract those SNPs and create a new set of data files in a single command. Use the D1D binary file set as input Find the command for extracting a set of SNPs listed in a file (hint: Data Management section) and combine it with a command that you learned above to create binary files Use the output file name 'D1D_MAF_MISS' \ud83d\udcdd Log files are uselful to check that the number of SNPs and samples is as expected. Always check your your log files to ensure that they are sensible. SNP lists can also be used to EXCLUDE SNPs - select 'exclude' above instead of 'extract'. Sample ID lists can also be used to 'keep' or 'remove' individuals in the same 'filter' window. Note that both sample IDs (FID IID,separated by a space are required in the sample file list. Solution 1: TO BE REVEALED LATER!! Solution 2: TO BE REVEALED LATER!!","title":"Write SNP list and extract SNPs"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#practical-2","text":"","title":"Practical 2"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#introduction-to-plink-ii-performing-qc-gwas","text":"","title":"Introduction to PLINK II: Performing QC &amp; GWAS"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#key-learning-outcomes_1","text":"After completing this practical, you should be able to: Generate summaries of the data needed for QC Apply QC thresholds Perform GWAS","title":"Key Learning Outcomes"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#generate-summaries-to-perform-qc","text":"There are many kinds of summaries of the data that can generated in PLINK in order to perform particular quality control (QC) steps, which help to make our data more reliable. Some of these involve summaries in relation to the individuals (e.g. individual missingness, sex-check) and some relate to summaries of SNP data (e.g. MAF, Hardy-Weinburg Equilibrium). Over the next few sub-sections you will go through some examples of generating summary statistics that can be used to perform QC.","title":"Generate summaries to perform QC"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#individual-missingness","text":"Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Open the 2 files that were generated (lmiss & imiss). What do the two output files contain? In the imiss file, what is the meaning of the data in the column headed \"F_MISS\"?","title":"Individual missingness"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#snp-missingness","text":"Use the D1D binary files to generate files containing missingness information (--missing). Use the output file name 'D1D_miss' Look inside the file containing SNP missingness information: D1D_miss.lmiss. What is the meaning of the value under F_MISS? What does the command --test-missing do and why might it be useful?","title":"SNP Missingness"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#hardy-weinberg-equilibrium","text":"Generate HWE statistics using the --hardy option. Use output file name D1D_hardy. Open and examine results. Why are there multiple rows for each SNP and what does each mean? Which of the rows do you think should be used to exclude SNPs from the subsequent analysis (if any) for failing the HWE test? Why?","title":"Hardy-Weinberg Equilibrium"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#allele-frequencies","text":"Generate allele frequencies using the command *--*freq. Use D1D_freq as the output name. Examine the output. What is the heading of the column that tells you which nucleotide is the minor allele? \ud83d\udcdd This information is important to remember as many PLINK files use this notation. The minor allele is always labeled the same way","title":"Allele frequencies"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#apply-qc-filters","text":"","title":"Apply QC filters"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#there-are-different-strategies-for-performing-qc-on-your-data","text":"(a) Create lists of SNPs and individuals and use --remove, --extract, --exclude, --include to create new file sets (good for documentation, collaboration) (b) Apply thresholds one at a time and generate new bed/bim/fam file (good for applying sequential filters) (c) Use options (e.g. --maf ) in other commands (e.g. --assoc) to remove SNPs or samples at required QC thresholds during analysis. \ud83d\udcdd We have already seen how to select or exclude individuals or SNPs by first creating lists (a), so in this section we will set thresholds to generate new files sets in a single command. However, it is useful to have lists of all SNPs and individuals excluded pre-analysis, according to the reason for exclusion, so generating and retaining such files using the techniques that we used before for good practice.","title":"There are di\ufb00erent strategies for performing QC on your data:"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#apply-individual-missingness-thresholds","text":"Generate new binary file sets (--make-bed) from the 'D1D' binary file set, removing individuals with missingness greater than 3% using a single command (hint: In the 'Inclusion thresholds' section, see the 'Missing/person' sub-section). Use the output file name 'D1D_imiss3pc' Examine the output files (no need to open, and remember the bed file cannot be read) and the log file How many individuals were in the original file? How many individuals were removed? How many males and females were left after screening?","title":"Apply individual missingness thresholds"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#apply-snp-missingness-and-maf-thresholds","text":"Create new binary file sets from the 'D1D_imiss3pc' binary file set (NOT the original D1D files) by setting MAF threshold to 0.05 and SNP missingness threshold to 0.02 (See 'Inclusion thresholds' to obtain the correct threshold flags). Use the output file name'D1D_imiss3pc_lmiss2pc_maf5pc Examine the output files and the log file How many SNPs were in the original files? How many SNPs were removed for low minor allele frequency? How many SNPs were removed for missingness?","title":"Apply SNP missingness and MAF thresholds"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#apply-hardy-weinberg-thresholds","text":"Generate a new binary file set called 'D1D_QC' from the D1D_imiss3pc_lmiss2pc_maf5pc file, applying a HWE threshold of 0.0001. This is our final, QC'ed file set. Examine log and output files. -How many SNPs were removed for HWE p-values below the threshold? \ud83d\udcdd It is useful to know how to do this, but be careful about setting this threshold - strong association signals can cause departure from HWE and you may remove great results! Use a lenient threshold and apply to controls only to avoid this problem. HWE can also be checked post-hoc for each SNP.","title":"Apply Hardy-Weinberg thresholds"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#perform-gwas","text":"","title":"Perform GWAS"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#casecontrol-gwas-no-covariates","text":"Run the following code, which performs a genetic association study using logistic regression on some case/control data: plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --out D1D_CC What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Are there any other significant associations?","title":"Case/Control GWAS - no covariates"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#casecontrol-gwas-with-covariates","text":"Here we repeat the previous analysis but this time including some covariates. The file D1D.pcs1234 contains the first 4 principal components from a PCA on the genetic data. Run the analysis specifying the covariates file: plink --bfile D1D_QC --logistic --adjust --pheno D1D.pheno1 --covar D1D.pcs.1234 --out D1D_CC_PCadj What are the raw and Bonferroni-adjusted p-values for the top hit? What does this mean - is there a significant association? Suggest a reason for the different results when adjusting for the 4 PCs?","title":"Case/Control GWAS - with covariates"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#license","text":"This work is licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License and the below text is a summary of the main terms of the full Legal Code (the full licence) available at https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode","title":"License"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#you-are-free-to","text":"Share --- copy and redistribute the material in any medium or format Adapt --- remix, transform, and build upon the material The licensor cannot revoke these freedoms as long as you follow the license terms.","title":"You are free to:"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#under-the-following-terms","text":"Attribution --- You must give appropriate credit, providea link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. NonCommercial --- You may not use the material for commercial purposes. ShareAlike --- If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictions --- You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.","title":"Under the following terms:"},{"location":"tmp2/prs_2023-main/modules/Day1b.docx/#notices","text":"You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation. No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.","title":"Notices:"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/","text":"Introduction to Polygenic Risk Scores Table of Contents Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents Key Learning Outcomes After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Data Structure You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents Introduction A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS. Understanding GWAS Summary Statistics When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents Matching the Base and Target Data sets The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents Linkage Disequilibrium in PRS Analyses GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents Performing Clumping Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents P-Value Thresholding Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds. Height PRS using GW-significant SNPs only Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2),the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice/PRSice_linux -h Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents Height PRS across multiple P-value thresholds A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents High Resolution Scoring If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents Stratifying Samples by PRS An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents Case Control Studies In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary. Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres \u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status. Cross-Trait Analysis A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis. Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#introduction-to-polygenic-risk-scores","text":"","title":"Introduction to Polygenic Risk Scores"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#table-of-contents","text":"Key Learning Outcomes Resources you will be using Data Structure Introduction Understanding GWAS Summary Statistics Matching the Base and Target Data sets Linkage Disequilibrium in PRS Analyses Performing Clumping P-Value Thresholding Height PRS using GW-significant SNPs only Height PRS across multiple P-value thresholds High Resolution Scoring Stratifying Samples by PRS Case Control Studies Cross-Trait Analysis Back to Table of Contents","title":"Table of Contents"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: Perform basic Polygenic Risk Score (PRS) analyses using PRSice: ( Euesden, Lewis & O'Reilly 2015 ; Choi & O'Reilly 2019 ) Interpret results generated from PRS analyses Customise visualisation of results","title":"Key Learning Outcomes"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#data-structure","text":"You will find all practical materials in the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory. Relevant materials that you should see there at the start of the practical are as follows: First, download the Base datasets using this link . The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following command. cd ~/data/Day2_Target_Data/Day2_Target_Data mv ~/Downloads/Day2_Base_Data.zip ~/data/Day2_Target_Data/Day2_Target_Data Now, your Day2_Base_dat.zip has been moved to your Day2_Target_Data directory. However, the file is zipped so you will need to unzip it: unzip Day2_Base_Data.zip For clarity purposes, rename your Day2_Base_data to Base_data and make a directory for your Target data called \"Target_data\" in which you will move all your target datasets. mv Day2_Base_Data Base_Data mkdir Target_Data mv TAR.* Target_Data You also want to create a \"Results\" directory where all your results will be saved mkdir Results So now in your current working directory (for Day2), you should have 3 directories (in blue) called Base_data, Target_data, and Results \ud83d\udcc2: Base_Data GIANT_Height.txt, cad.add.txt, cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udee0\ufe0f: Software - plink_mac - plink_linux - plink.exe - PRSice.R - PRSice_mac - PRSice_linux - PRSice_win64.exe \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Table of Contents","title":"Data Structure"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#introduction","text":"A PRS is a (usually weak) estimate of an individual's genetic propensity to a phenotype, calculated as a sum of their genome-wide genotypes weighted by corresponding genotype effect sizes obtained from GWAS summary statistics. In the next section we will consider what the effect size means and how it is used in computing PRS.","title":"Introduction"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#understanding-gwas-summary-statistics","text":"When GWAS are performed on a quantitative trait, the effect size is typically given as a beta coefficient (\ud835\udefd) from a linear regression with Single Nucleotide Polymorphism (SNP) genotypes as predictor of phenotype. The \ud835\udefd coefficient estimates the increase in the phenotype for each copy of the effect allele . For example, if the effect allele of a SNP is G and the non-effect allele is A , then the genotypes AA , AG and GG will be coded as 0, 1 and 2 respectively. In this scenario, the \ud835\udefd coefficient reflects how much the phenotype changes for each G allele present (NB. The \ud835\udefd can be positive or negative - so the 'effect allele' is simply the allele that was coded in the regression, not necessarily the allele with a positive effect). When a GWAS is performed on a binary trait (e.g. case-control study), the effect size is usually reported as an Odd Ratios (OR). Using the same example, if the OR from the GWAS is 2 with respect to the G allele, then the OR of AG relative to AA is 2, and the OR of GG relative to AA is 4. So an individual with the GG genotype are estimated* to be 4 times more likely to be a case than someone with the AA genotype (*an Odds Ratio is itself an estimate of a Risk Ratio, which cannot be calculated from a case/control study) \ud83d\udcdc The relationship between the \ud835\udefd coefficient from the logistic regression and the OR is: OR = e \ud835\udefd and log e (OR) = \ud835\udefd. While GWAS usually convert from the \ud835\udefd to the OR when reporting results, most PRS software convert OR back to \ud835\udefd's(\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc52 (\ud835\udc42\ud835\udc45)) to allow simple addition. \ud83d\udcdc Column names are not standardised across reported GWAS results, thus it is important to check which column is the effect (coded) allele and which is the non-effect allele. For example, in the height GWAS conducted by the GIANT consortium, the effect allele is in the column Allele1, while Allele2 represents the non-effect allele. \ud83d\udd0e Let us open the Height GWAS file ( GIANT_Height.txt ) and inspect the SNPs at the top of the file. If we only consider SNPs rs4747841 and rs878177 , what will the \u2018PRS\u2019 of an individual with genotypes AA and TC , respectively, be? And what about for an individual with AG and CC , respectively? (Careful these are not easy to get correct! This shows how careful PRS algorithms/code need to be). Answer In the GIANT_Height.txt, SNPs effect sizes are reported as \ud835\udefd coefficient and measures the effect of the 'effect allele'. So, first check identify which allele is the effect allele for the SNPs of interest grep -E 'rs4747841|rs878177' ./Base_data/GIANT_Height.txt rs4747841 A G 0.551 -0.0011 0.0029 0.7 253213 rs878177 T C 0.3 0.14 0.0031 8.2e-06 251271 Second, multiply the weight of each risk allele by their dosage Individual_1: PRS=?, Individual_2: PRS=? \u2753What do these PRS values mean in terms of the height of those individuals? Back to Table of Contents","title":"Understanding GWAS Summary Statistics"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#matching-the-base-and-target-data-sets","text":"The first step in PRS calculation is to ensure consistency between the GWAS summary statistic file ( base data ) and the target genotype file ( target data ). Since the base and target data are generated independently, they often relate to different SNPs and so the first job is to identify the overlapping SNPs across the two data sets and remove non-overlapping SNPs (this is usually done for you by PRS software). If the overlap is low then it would be a good idea to perform imputation on your target data to increase the number of SNPs that overlap between the data sets. The next, more tricky issue, is that the genotype encoding between the data sets may differ. For example, while the effect allele of a SNP is T in the base data, the effect allele in the target might be G instead. When this occurs, allele flipping should be performed,where the genotype encoding in the target data is reversed so that TT , TG and GG are coded as 2, 1 and 0. Again, this is usually performed automatically by PRS software. \u203c\ufe0fFor SNPs that have complementary alleles, e.g. A/T , G/C , we cannot be certain that the alleles referred to in the target data correspond to those of the base data or whether they are the 'other way around' due to being on the other DNA strand (unless the same genotyping chip was used for all data). These SNPs are known as ambiguous SNPs , and while allele frequency information can be used to match the alleles, we remove ambiguous SNPs in PRSice to avoid the possibility of introducting unknown bias. Back to Table of Contents","title":"Matching the Base and Target Data sets"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#linkage-disequilibrium-in-prs-analyses","text":"GWAS are typically performed one-SNP-at-a-time, which, combined with the strong correlation structure across the genome (Linkage Disequilibrium (LD)), makes identifying the independent genetic effects (or their best proxies if these are not genotyped/imputed) challenging. There are two main options for approximating the PRS that would have been generated from full conditional GWAS: 1. SNPs are clumped so that the retained SNPs are largely independent of each other, allowing their effects to be summed, assuming additive effects, 2. all SNPs are included and the LD between them is accounted for. While option 2 is statistically appealing, option 1 has been most adopted in PRS studies so far, most likely due to its simplicity and the similarity of results of methods using the different options to date ( Mak, T et al., 2017 ). In this workshop we will consider option 1, implemented in PRSice, but if you are interested in how LD can be incorporated as a parameter in PRS calculation then see the LDpred ( Vilhjalmsson, B et al., 2015 )and lassosum ( Mak, T et al., 2017 ) papers. Back to Table of Contents","title":"Linkage Disequilibrium in PRS Analyses"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#performing-clumping","text":"Clumping is the procedure where a SNP data set is 'thinned' by removing SNPs across the genome that are correlated (in high LD) with a nearby SNP that has a smaller association \ud835\udc43 -value. SNPs are first sorted (i.e. ranked) by their \ud835\udc43 -values. Then, starting from the most significant SNP (denoted as the index SNP ), any SNPs in high LD (eg. \ud835\udc5f 2 >0.1, with \ud835\udc5f 2 typically calculated from phased haplotype data) with the index SNP are removed. To reduce computational burden, only SNPs that are within e.g. 250 kb of the index SNP are \ud835\udc50\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc5d\ud835\udc52\ud835\udc51. This process is continued until no index SNPs remain. Use the command below to perform clumping of the Height GWAS data using PLINK( Chang, C et al., 2015 ). First, you will have to navigate to the right folder where the data are stored using the terminal. Open the terminal and type the command below at the terminal prompt: plink \\ --bfile Target_Data/TAR \\ --clump Base_Data/GIANT_Height.txt \\ --clump-p1 1 \\ --clump-snp-field MarkerName \\ --clump-field p \\ --clump-kb 250 \\ --clump-r2 0.1 \\ --out Results/Height \u203c\ufe0fYou can copy & paste code from this document directly to the terminal, but this can cause problems (e.g. when opened by Preview in Mac) and distort the code. Try using Adobe Reader or first copy & pasting to a text editor (e.g. notepad) or use the script file provided that contains all the commands. The command above performs clumping on the height GWAS using LD calculated based on the TAR genotype file. SNPs that have \ud835\udc5f 2 >0.1 within a 250 kb window of the index SNP are removed. This will generate the Height.clumped file, which contains the SNPs retained after clumping. \u2753How many SNPs were in the GIANT_Height.txt file before clumping? Answer 2,183,049 variants \u2753How many SNPs remain after clumbing? Answer 109,496 variants \u2753If we change the r 2 threshold to 0.2, how many SNPs remain? Why are there, now, more SNPs remaining? Answer 162,275 variants \u2753Why is clumping performed for calculation of PRS? (in the standard approach). Back to Table of Contents","title":"Performing Clumping"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#p-value-thresholding","text":"Deciding which SNPs to include in the calculation of PRS is one of the major challenges in the field. A simple and popular approach is to include SNPs according to their GWAS association \ud835\udc43-value. For example, we may choose to include only the genome-wide significant SNPs from the GWAS because those are the SNPs with significant evidence for association. In the next subsection you will compute PRS from GW-significant SNPs only, and then in the subsequent subsection you will generate multiple PRSs using different \ud835\udc43-value thresholds.","title":"P-Value Thresholding"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#height-prs-using-gw-significant-snps-only","text":"Use the commands below to run PRSice with GIANT Height GWAS as base data and the height phenotype as target data. PRSice will calculate Height PRS in the target data and then perform a regression of the Height PRS against the target individual's true height values. From the /home/manager/data/Day2_Target_Data/Day2_Target_Data directory, run the following command in the terminal: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --bar-levels 5e-8 --no-full --fastscore --out Results/Height.gws This command takes the Height GWAS summary statistic file (--base), informs PRSice of the column name for the column containing the SNP ID(--snp), the effect allele (--A1), the non-effect allele (--A2),the effect size (--stat) and the \ud835\udc43-value (--pvalue). We also inform PRSice that the effect size is a \ud835\udefd coefficient (--beta) instead of an OR. The --binary-target F command informs PRSice that the target phenotype is a quantitative trait and thus linear regression should be performed. In addition, we ask PRSice not to perform high-resolution scoring over multiple thresholds (--fastscore), and to compute the PRS using only those SNPs with \ud835\udc43-value \\< 5*\u00d7*10 \u22128 . \ud83d\udcdcThe default of PRSice is to perform clumping with r 2 threshold of 0.1 and a window size of 250kb. To see a full list of command line options available in PRSice, type: ~/PRSice/PRSice_linux -h Take some time to have a look through some of these user options. By looking at the user options, work out which user option or options were used to ensure that the command above only calculated 1 PRS at genome-wide significance of \\< 5*\u00d7*10 \u22128 . PRSice performs strand flipping and clumping automatically and generates the Height.gws.summary file, together with other output that we will look into later in the practical. The summary file contains the following columns: Phenotype - Name of Phenotype. Set - Name of Gene Set. Default is Base Threshold - Best P-value Threshold PRS.R2 - Variance explained by the PRS Full.R2 - Variance explained by the full model (including the covariates) Null.R2 - Variance explained by the covariates (none provided here) Prevalence - The population disease prevalence as indicated by the user (not provided here due to testing continuous trait) Coefficient - The \ud835\udefd coefficient corresponding to the effect estimate of the best-fit PRS on the target trait in the regression. A one unit increase in the PRS increases the outcome by \ud835\udefd Standard.Error - The standard error of the best-fit PRS \ud835\udefd coefficient (see above) P - The \ud835\udc43 -value relating to testing the null hypothesis that the best-fit PRS \ud835\udefd coefficient is zero. Num_SNP - Number of SNPs included in the best-fit PRS Empirical-P - Only provided if permutation is performed. This is the empirical \ud835\udc43 -value corresponding to the association test of the best-fit PRS - this controls for the over-fitting that occurs when multiple thresholds are tested. For now, we can ignore most columns and focus on the PRS.R2 and the P column, which provide information on the model fit. \u2753What is the R 2 for the PRS constructed using only genome-wide significant SNPs? Answer 0.071 \u2753What is the P-value for the association between the PRS and the outcome? Is this significant? (explain your answer) Answer 1.36e-09 Back to Table of Contents","title":"Height PRS using GW-significant SNPs only"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#height-prs-across-multiple-p-value-thresholds","text":"A disadvantage of using only genome-wide significant SNPs is that there are likely to be many true signals among the SNPs that did not reach genome-wide significance. However, since we do not know what \ud835\udc43-value threshold provides the \\\"best\\\" prediction for our particular data, then we can calculate the PRS under several \ud835\udc43-value thresholds and test their prediction accuracy to identify the \\\"best\\\" threshold (NB. See Dudbridge, F 2013 for theory on factors affecting the best-fit PRS) This process is implemented in PRSice and can be performed automatically as follows: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --fastscore --out Results/Height.fast By removing the --bar-levels and --no-full command, we ask PRSice to perform PRS calculation with a number of predefined thresholds (0.001,0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1). The .prsice file is very similar to the .summary file, the only difference is that .prsice file reports the results of model fits for all thresholds instead of the most predictive threshold. This allow us to observe the change in model fitting across different thresholds, visualized by the BARPLOT ( Figure 1.1 ) generated by PRSice Figure 1.1: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.05 \u2753What is the R 2 of the most predictive threshold and how does it compare to PRS generated using genome-wide significant SNPs? Answer 0.26523 Back to Table of Contents","title":"Height PRS across multiple P-value thresholds"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#high-resolution-scoring","text":"If we limit ourselves to a small number of \ud835\udc43-value thresholds, we might \\\"miss\\\" the most predictive threshold. In order to identify this \\\"best\\\" threshold, we will need \\\"high-resolution scoring\\\", that is, to test the predictive power of PRS generated under a larger number of p-value thresholds. We can achieve that by simply removing the --fastscore command from the PRSice script: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --out Results/Height.highres When PRSice performs high-resolution scoring, it will generate a plot ( Figure 1.2.1 ) presenting the model fit of PRS calculated at all P-value thresholds. Figure 1.2.1: High resolution Plot generated by PRSice Figure 1.2.2: BARPLOT generated by PRSice \u2753Which is the most predictive threshold? Answer 0.058 \u2753How much better is the threshold identified using high-resolution scoring, in terms of model R 2 ? Answer The R 2 using high-resolution scoring is 0.268237. In this case, there is not significant difference between the two results. \u2753How does running fastscore vs high-resolution change the most predictive threshold identified? \u2753The default of PRSice is to iterate the P-value threshold from \\< 5*\u00d7*10 \u22128 to 0.5 with a step size of 0.00005, and to inlcude the P-value threshold of 1. Can you identify the commands controlling these parameters? Hint ./Software/PRSice_linux -h Back to Table of Contents Accounting for Covariates When performing PRS, one might want to account for covariates. Based on user inputs, PRSice can automatically incorporate covariates into its model. For example, the following commands will include sex into the regression model as a covariate: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --out Results/Height.sex When covariates are included in the analysis, PRSice will use the model fit of only PRS for all its output. This \ud835\udc43\ud835\udc45\ud835\udc46.\ud835\udc45 2 is calculated by substracting the \ud835\udc45 2 of the null model (e.g. \ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65) from the \ud835\udc45 2 of the full model (e.g.\ud835\udc3b\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61 \u223c \ud835\udc46\ud835\udc52\ud835\udc65 + \ud835\udc43\ud835\udc45\ud835\udc46) \u2139\ufe0f Usually, Principal Components (PCs) are also included as covariates in the analysis to account for population structure and it can be tedious to type all 20 or 40 PCs (e.g. PC1 , PC2 ,..., PC20 ). In PRSice, you can add @ in front of the --cov-col string to activate the automatic substitution of numbers. If @ is found in front of the --cov-col string, any numbers within [ and ] will be parsed. E.g. @PC[1-3] will be read as PC1 , PC2 , PC3 . Discontinuous input are also supported: @cov[1.3-5] will be parsed as cov1 , cov3 , cov4 , cov5 . You can also mix it up, e.g. @PC[1-3]. Sex will be interpreted as PC1 , PC2 , PC3 , Sex by PRSice. \u2753How does the inclusion of sex as covariate change the results? Answer The inclusion of sex as a covariate increased the phenotypic variance explained by both PRS and sex (FULL.R2 = 0.47) Back to Table of Contents","title":"High Resolution Scoring"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#stratifying-samples-by-prs","text":"An interesting application of PRS is to test whether samples with higher PRS have higher phenotypic values. This can be nicely visualized using the quantile plot ( Figure 1.3 ) To generate quantile plots in PRSice, simply add --quantile 10 option. \ud83d\udcdc We can skip the PRS calculation using the --plot option, which will use previoulsy calculated PRS to generate the plots Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 10 --out Results/Height.sex Figure 1.3: Example of a quantile plot generated by PRSice \u2139\ufe0f The --plot option tells PRSice to generate the plots without re-running the whole PRSice analysis. This is handy when you want to change some of the parameters for plotting e.g. the number of quantiles. Try running the previous command with 20 quantiles, and again with 50 quantiles (checking the quantile plot each time . A disadvantage of the quantile plot is that it only separate samples into quantiles of equal size. However, it is sometimes interesting to investigate whether a specific strata (e.g. top 5% of samples),contain a higher PRS than the reference strata. For example, ( Mavaddat, N et al., 2015 ) found that samples in the highest 1% of PRS distribution have a 2.81 increased OR of breast cancer when comparing to samples at the middle quantiles (40th to 60th percentile). We can mimic their table by using --quant-break , which represents the upper bound of each strata, and --quant-ref , which represents the upper bound of the reference quantile: Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/TAR.height --binary-target F --cov Target_Data/TAR.covariate --cov-col Sex --plot --quantile 100 --quant-break 1,5,10,20,40,60,80,90,95,99,100 --quant-ref 60 --out Results/Height.sex Figure 1.4: Example of a strata plot generated by PRSice \ud83d\udcdc See the quantile results in Table from in the QUANTILES file, and the plots in the QUANTILES_PLOT file. Due to the small sample size of the target data the results here are underwhelming, but with high power we may observe strong deviation in the extreme quantiles. Back to Table of Contents","title":"Stratifying Samples by PRS"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#case-control-studies","text":"In the previous exercises, we have performed PRS analyses on height, which is a quantitative trait. For binary phenotypes (e.g case-control) there are a number of differences in the analysis: Logistic regression has to be performed instead of linear regression ORs are usually provided and need to be converted to \ud835\udefd's when constructing PRS Here, we will use CAD as an example. You will find the summary statistic under Base_Data ( cad.add.txt ) and the phenotype file ( TAR.cad ) under Target_Data . You will also need to specify --binary-target T in the PRSice command to indicate that the phenotype is binary. \u2139\ufe0f GWAS summary statistics for binary traits tend to report the OR instead of the \ud835\udefd coefficient, in which case the --or should be used. However, CARDIoGRAM plus C 4 D consortium provided the \ud835\udefd coefficient, therefore we will include --beta in our code and specify --binary-target T to indicate that the phenotype is binary.","title":"Case Control Studies"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#rscript-prsiceprsicer-prsice-prsiceprsice_linux-base-base_datacadaddtxt-target-target_datatar-snp-markername-a1-effect_allele-a2-noneffect_allele-chr-chr-bp-bp_hg19-stat-beta-beta-pvalue-p_dgc-pheno-target_datacadpheno-binary-target-t-out-resultscadhighres","text":"\u2139\ufe0f --chr and --bp inform PRSice the columns containing the chromosomal coordinates. This enables PRSice to check whether the SNPs in the Base and Target data have the same chromosomal coordinate. Figure 1.5: BARPLOT generated from PRSice \u2753What is the R 2 and P-value of the best-fit PRS? Answer 0.39 and 0.001, respectively \u2753Does this suggest that there is a significant association between the CAD PRS and CAD status in the target sample? Answer The p-value does not suggest a significant association between the CAD PRS and CAD status.","title":"Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/cad.add.txt --target Target_Data/TAR --snp markername --A1 effect_allele --A2 noneffect_allele --chr chr --bp bp_hg19 --stat beta --beta --pvalue p_dgc --pheno Target_Data/CAD.pheno --binary-target T --out Results/CAD.highres\n"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#cross-trait-analysis","text":"A popular application of PRS is in performing cross-trait analyses. This allows some interesting analyses such as those performed by ( Ruderfer, D et al., 2014 ) which used the bipolar PRS to predict into different clinical dimensions of schizophrenia. In this practical, we will perform cross-trait analyses between CAD and Height, using height as the base and CAD as the target. \u2139\ufe0f We will only focus on the simplest form of cross-trait analysis in this practical. To perform the multi-phenotype cross-trait analysis similar to that of ( Ruderfer, D et al., 2014 ), you can use the --pheno-col to include multiple target phenotype into the analysis.","title":"Cross-Trait Analysis"},{"location":"tmp2/prs_2023-main/modules/Day2.docx/#rscript-prsiceprsicer-prsice-prsiceprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datacadpheno-binary-target-t-out-resultscrosshighres","text":"Figure 1.6: BARPLOT generated from PRSice \u2753What is the R 2 for the most predictive threshold when using height as the base phenotype and CAD as the target phenotype? Answer 0.032 \u2753Now try using CAD as the base to predict height as the target trait? What is the PRS R 2 for that? Answer Back to top","title":"Rscript ~/PRSice/PRSice.R --prsice ~/PRSice/PRSice_linux --base Base_Data/GIANT_Height.txt --target Target_Data/TAR --snp MarkerName --A1 Allele1 --A2 Allele2 --stat b --beta --pvalue p --pheno Target_Data/CAD.pheno --binary-target T --out Results/Cross.highres\n"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/","text":"Advanced Polygenic Risk Score Analyses Day 3 - Polygenic Risk Score Analyses Workshop 2023 Table of Contents Key Learning Outcomes Resources you will be using Datasets Exercise 1 Estimating R 2 in case and control studies Exercise 2 Overfitting caused by model optimisation Out of Sample Validation Exercise 3 Distribution of PRS Gene Set Analysis Molecular Signatures Database MSigDB General Transfer Format file Browser Extensible Data BED Gene Set Enrichment Analysis Exercise 4 Gene Set Based PRS Analysis Key Learning Outcomes After completing this practical, you should be able to: 1. know how to adjust for ascertainment bias in case-control analysis 2. Know how over-fitting a\ufb00ects PRS results and how to handle it 3. understand distribution of PRS 4. understand di\ufb00erent file formats involved in gene-set analysis 5. understand di\ufb00erence between self-contained and competitive gene-set analyses 6. Calculate pathway based PRS Resources you will be using To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link Additional Resources In this practical, we will explore how to perform gene-set based PRS analyses. To perform this analysis, gene-set information and coordinates for the genic regions are required. These information can be obtained from the following database: Data Set Description Download Link Ensembl Human Genome GTF file A file containing the coordinates for genes in the human genome. Used by PRSice to map the SNPs onto genic regions Link MSigDB Gene Sets File containing the gene-set information. Free registration required. Download here after registration Data Sets You will need to download the required files for this tutorial. Download Backup WeTransfer The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following commands. cd data mv ~/Downloads/Day_3.zip . unzip Day_3.zip cd Day_3 You will find all practical materials in the data/Day_3 directory. Relevant materials that you should see there at the start of the practical are as follows: \ud83d\udcc2: Base_Data - GIANT_Height.txt, - cad.add.txt, - cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udcc1: Reference files - Homo_sapiens.GRCh38.86.gt - Sets.gmt \ud83d\udee0\ufe0f: Software - PRSice.R - PRSice_linux - nagelkerke.R - Quantile.R \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Top Exercise 1 Estimating R 2 in case and control studies Bias in R 2 estimation caused by ascertained case/control samples can be adjusted using the equation proposed by Lee et al (2011) , which requires the sample prevalence (case/control ratio) and population prevalence as parameters. This function is implemented in PRSice and the adjustment can be performed by providing the population prevalence to the command --prevalence . Residuals of logistic regression is not well defined, and in PRS analyses, Nagelkerke R 2 is usually used to represent the model R 2 (this is the default of PRSice). However, this R 2 does not account for the di\ufb00erence between sample prevalence (i.e. case-control ratio) and population prevalence, which can lead to bias in the reported R 2 (Figure 1.1a). Figure 1.1: Performance of di\ufb00erent R 2 when the study contains equal portion of cases and controls (a) Nagelkerke R 2 Bias in R 2 estimation caused by ascertained case/control samples can be adjusted using the equation proposed by Lee et al. 2011 (Figure 1.1b) , which requires the sample prevalence (case/control ratio) and population prevalence as parameters. This function is implemented in PRSice and the adjustment can be performed by providing the population prevalence to the command --prevalence . Figure 1.1: Performance of di\ufb00erent R 2 when the study contains equal portion of cases and controls (b) Lee adjusted R 2 Now, account for the ascertainment of the case/control sample by including the population prevalence (let\u2019s assume e.g. 5% here) in the PRSice command to obtain the adjusted (Lee) R 2 : Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/cad.add.txt \\ --target Target_Data/TAR \\ --snp markername \\ --A1 effect_allele \\ --A2 noneffect_allele \\ --chr chr \\ --bp bp_hg19 \\ --stat beta \\ --beta \\ --pvalue p_dgc \\ --pheno Target_Data/TAR.cad \\ --prevalence 0.05 \\ --binary-target T \\ --out Results/CAD.highres.LEER2 The results are written to the \"Results\" directory. Examine the results folder and each file that was generated. For more information about each file type, see here . \u2b50 Check the *.summary file in the Results folder where you will find the usual (Nagelkerke) R 2 and the adjusted (Lee) R 2 . Figure 1.2: Barplot of CAD Lee R 2 \ud83d\udccc To speed up the practical, we have generated a smaller gene-set file. If you want the full gene-set file, you can download it from the link above. \ud83d\udccc All target phenotype data in this workshop are simulated. While they reflect the corresponding trait data, they have no specific biological meaning and are for demonstration purposes only. \u2753Has accounting for the population prevalence a\ufb00ected the R 2 ? Solution Yes, the adjusted R 2 = 0.0521524 and default R 2 = 0.0442664 \u2753Would you expect a di\ufb00erence between the Nagelkerke R 2 and the Lee adjusted R 2 if the case/control ratio in the target sample reflects the disease prevalence in the population? Solution No, the R 2 will be the same because the prevalence of the target is a true representation of the population prevalence. Back to Top Exercise 2 Overfitting caused by model optimisation In PRS analyses, the shrinkage or tuning parameter is usually optimized across a wide range of parametric space (e.g. P -value threshold, proportion of causal SNPs). When both optimisation and association testing are performed on the target data, over-fitted results will be obtained. The accuracy and predictive power of over-fitted results are likely to diminish when replicated in an independent data set. A simple solution is to perform permutation to obtain an empirical P -value for the association model, which is implemented in PRSice. Briefly, permutation is performed as follows: 1) Compute the P -value in your original data, denoted as obs.p, at the \"best\" threshold. 2) Then shu\ufb04e the phenotype and obtain the P -value of the \"best\" threshold for this null phenotype, denoted as null.p 3) Repeat 2) N times 4) Calculate the empirical P-value as: \\( Pemp = (\\sum(obs.p > null.pi + 1) / (N + 1) \\) You will have to specify the number of permutation (N ) to perform by providing --perm N as a parameter to PRSice. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --snp MarkerName \\ --A1 Allele1 \\ --A2 Allele2 \\ --stat b \\ --beta \\ --pvalue p \\ --pheno Target_Data/TAR.height \\ --binary-target F \\ --cov Target_Data/TAR.covariate \\ --cov-col Sex \\ --perm 1000 \\ --out Results/Height.perm Figure 1.3: Barplot of Height using 1000 permutations \ud83d\udcdd 10000 permutations typically provide empirical P-values with high accuracy to the second decimal place (eg. 0.05), but smaller empirical P-values should be considered approximate. \u2753 What is the smallest possible empirical P-value when 10000 permutation are performed? Solution 1.5 X 10 -34 . \u2753 Is the height PRS significantly associated with height after accounting for the over-fitting implicit in identifying the best-fit PRS? How about CAD? Solution Yes, the height PRS is significantly associated with height. After accounting for the over-fitting implicit in identifying the best-fit PRS, the emprical p-value is 0.000999001. Out of Sample Validation The best way to avoid having results that are over-fit is to perform validation on an independent validation data set. We can perform validation of the previous height + covariate analysis with PRSice, using the independent VAL target sample as validation data and the \"best\" P-value threshold predicted in the VAL samples: Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/GIANT_Height.txt \\ --target Target_Data/VAL \\ --snp MarkerName \\ --A1 Allele1 \\ --A2 Allele2 \\ --stat b \\ --beta \\ --pvalue p \\ --pheno Target_Data/VAL.height \\ --binary-target F \\ --no-full \\ --bar-levels 0.0680001 \\ --fastscore \\ --cov Target_Data/VAL.covariate \\ --cov-col Sex \\ --out Results/Height.val Figure 1.4: Barplot of Height validation dataset \u2753 Why do we use --bar-levels 0.0680001 --no-full and --fastscore in this script? \u2753 How does the PRS R2 and P -value for the validation data set compare to the analysis on the TAR target data? Is this what you would expect? Why? Back to Top Exercise 3 Distribution of PRS Many PRS study publications include quantile plots that show an exponential increase in phenotypic value or / Odd Ratios (OR) among the top quantiles (e.g. an S-shaped quantile plot, e.g. Figure 1.6). Figure 1.5: An example of density plot for PRS Figure 1.6: An example of a S-shaped quantile plot This might lead us to believe that individuals with PRS values in the top quantiles have a distinctly di\ufb00erent genetic aetiology compared to the rest of the sample, or that there is epistasis/interactions causing there substantially higher risk. However, when we plot a normally distributed variable (e.g. a PRS) as quantiles on the X-axis then we expect to observe this exponential pattern even when the X variable only has a linear e\ufb00ect on the Y variable. This is because the top (and bottom) quantiles are further away from each other on the absolute scale of the variable and so the di\ufb00erences in their e\ufb00ects are larger than between quantiles in the middle of the distribution. To understand this more, we will perform a simple simulation using R: R # First, we define some simulation parameters n.sample <- 10000 PRS.r2 <- 0.01 # Then, we simulate PRS that follow a random normal distribution prs <- rnorm(n.sample) # We can then simulate the phenotype using the following script pheno <- prs + rnorm(n.sample,mean=0, sd=sqrt(var(prs)*(1-PRS.r2)/(PRS.r2))) # We can examine the relationship between the phenotype and prs # using linear regression summary(lm(pheno~prs)) # Which shows that we have the expected PRS R2 # Group the phenotype and PRS into a data.frame info <- data.frame(SampleID=1:n.sample, PRS=prs, Phenotype=pheno) # Then we can generate the quantile plot. # To save time, we will load in the quantile plot script from Software source(\"./Software/Quantile.R\") # Then we can plot the quantile plot using quantile_plot function quantile_plot(info, \"Results/Height\", 100) Figure 1.7: The resulting quantile plot \u2753 What is the shape of the resulting quantile plot? \u2753 Try plotting the densities of the height or CAD PRS in R * - do they look normally distributed? Why? (*Hint: You can generate a density plot for the PRS in R using plot(density(x)) where x is a vector of the PRS values in the sample). Back to Top Gene Set Analysis Currently, most PRS analyses have been performed on a genome-wide scale, disregarding the underlying biological pathways. Udler et al. 2018 suggest that grouping Single Nucleotide Polymorphisms (SNPs) into biological functional groups can lead to PRS that are more relevant to clinical risk. In this practical, we will go through some common file formats for gene-set analysis and will then calculate some gene-set (or pathway) based PRS. Molecular Signatures Database MSigDB The Molecular Signatures Database (MSigDB) o\ufb00ers an excellent source of gene-sets, including the hallmark genes, gene-sets of di\ufb00erent biological processes, gene-sets of di\ufb00erent oncogenic signatures etc. All gene-sets from MSigDB follows the Gene Matrix Transposed file format (GMT), which consists of one line per gene-set, each containing at least 3 column of data: Set A Description Gene 1 Gene 2 ... Set A Description Gene 1 Gene 2 ... ** Have a look at the Reference/Sets.gmt file. ** \u2753 How many gene-sets are there in the Reference/Sets.gmt file? \u2753 How many genes does the largest gene-set contain? \ud83d\udcac While you can read the GMT file using Excel. You should be aware that Excel has a tendency to convert gene names into dates (e.g. SEPT9 to Sep-9) As GMT format does not contain the chromosomal location for each individual gene, an additional file is required to provide the chromosoaml location such that SNPs can be map to genes. General Transfer Format file The General Transfer Format (GTF) file contains the chromosomal coordinates for each gene. It is a tab separated file and all but the final field in each feature line must contain a value. \"Empty\" columns should be denoted with a \u2018.\u2019. You can read the full format specification here. One column that might be of particular interest is column 3: feature , which indicates what feature that line of GTF represents. This allows us to select or ignore features that are of interest. You can find the description of each feature here . Browser Extensible Data BED Browser Extensible Data (BED) file (di\ufb00erent to the binary ped file from PLINK) is a file format to define genetic regions. It contains 3 required fields per line (chromosome, start coordinate and end coordinate) together with 9 additional optional field. A special property of BED is that it is a 0-based format, i.e. chromosome starts at 0, as opposed to the usual 1-based format such as the PLINK format. For example, a SNP on chr1:10000 will be represented as: 1 9999 10000 \u2753 How should we represent the coordinate of rs2980300 (chr1:785989) in BED format? Back to Top Gene Set Enrichment Analysis Now we have gone through all the files involved in gene-set analysis, we should consider one of the most important aspects of gene-set (or pathway) enrichment analyses, which is the di\ufb00erent types of testing that we can perform when doing them: Self-Contained vs Competitive Testing The null-hypothesis of self-contained and competitive test statistics is di\ufb00erent: \u2013 Self-Contained - None of the genes within the gene-set are associated with the phenotype \u2013 Competitive - Genes within the gene-set are no more associated with the phenotype than genes outside the gene-set Therefore, a bigger gene-set will have a higher likelihood of having a significant P -value from self-contained test, which is not desirable. Exercise 4 Gene Set Based PRS Analysis Having learnt about the basics of gene-set analyses, we are now ready to perform gene-set association analyses using PRSet. To perform the PRSet analysis and obtain the set based PRS and competitive P-value, simply provide the GTF file and the GMT file to PRSice and specify the number of permutation for competitive P-value calculation using the --set-perm option. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --A1 Allele1 \\ --A2 Allele2 \\ --snp MarkerName \\ --pvalue p \\ --stat b \\ --beta \\ --binary-target F \\ --pheno Target_Data/TAR.height \\ --cov Target_Data/TAR.covariate \\ --out Results/Height.set \\ --gtf Reference/Homo_sapiens.GRCh38.86.gtf \\ --wind-5 5kb \\ --wind-3 1kb \\ --msigdb Reference/Sets.gmt \\ --multi-plot 10 \\ --set-perm 1000 Figure 1.8: An example of the multi-set plot. Sets are sorted based on their self-contained R2 . Base is the genome wide PRS \ud83d\udccc If the --wind-5 and --wind-3 flag is not specified, PRSet will use the exact coordinates of each gene as the boundary. By specifying eg. --wind-5 5kb and --wind-3 1kb then the boundary of each gene will be extended 5 kb towards the 5\u2019 end and 1 kb towards the 3\u2019 end so that regulatory elements of the gene can be included. \ud83d\udccd By default, when calculating set based PRS, PRSet will not perform P -value thresholding. This is because the aim in gene-set analyses is to assess the overall signal in each gene-set, and compare which is most enriched for signal, rather than optimise predictive power as typically desirable for genome-wide PRS. Providing any of the following commands will activate P -value thresholding for set based PRS calculation: --lower, --upper, --inter, --bar-levels, --fastscore \u2753 Can you plot the relationship between the gene-set R2 and the number of SNPs in each gene-set? What general trend can be seen? \u2753 Considering the plot, what gene-sets do you think are most interesting and why? \u2753 Why is it useful to have polygenic scores measured across gene-sets (or pathways) for individuals? Isn\u2019t it su\ufb03cient to just obtain a ranking of gene-sets according to GWAS-signal enrichment?","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#advanced-polygenic-risk-score-analyses","text":"","title":"Advanced Polygenic Risk Score Analyses"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#day-3-polygenic-risk-score-analyses-workshop-2023","text":"","title":"Day 3 - Polygenic Risk Score Analyses Workshop 2023"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#table-of-contents","text":"Key Learning Outcomes Resources you will be using Datasets Exercise 1 Estimating R 2 in case and control studies Exercise 2 Overfitting caused by model optimisation Out of Sample Validation Exercise 3 Distribution of PRS Gene Set Analysis Molecular Signatures Database MSigDB General Transfer Format file Browser Extensible Data BED Gene Set Enrichment Analysis Exercise 4 Gene Set Based PRS Analysis","title":"Table of Contents"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#key-learning-outcomes","text":"After completing this practical, you should be able to: 1. know how to adjust for ascertainment bias in case-control analysis 2. Know how over-fitting a\ufb00ects PRS results and how to handle it 3. understand distribution of PRS 4. understand di\ufb00erent file formats involved in gene-set analysis 5. understand di\ufb00erence between self-contained and competitive gene-set analyses 6. Calculate pathway based PRS","title":"Key Learning Outcomes"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#resources-you-will-be-using","text":"To perform PRS analyses, summary statistics from Genome-Wide Association Studies (GWAS) are required. In this workshop, the following summary statistics are used: Phenotype Provider Description Download Link Height GIANT Consortium GWAS of height on 253,288 individuals Link Coronary artery disease (CAD) CARDIoGRAMplusC4D Consortium GWAS on 60,801 CAD cases and 123,504 controls Link","title":"Resources you will be using"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#additional-resources","text":"In this practical, we will explore how to perform gene-set based PRS analyses. To perform this analysis, gene-set information and coordinates for the genic regions are required. These information can be obtained from the following database: Data Set Description Download Link Ensembl Human Genome GTF file A file containing the coordinates for genes in the human genome. Used by PRSice to map the SNPs onto genic regions Link MSigDB Gene Sets File containing the gene-set information. Free registration required. Download here after registration","title":"Additional Resources"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#data-sets","text":"You will need to download the required files for this tutorial. Download Backup WeTransfer The data will be downloaded into your \"Downloads\" folder. You will need to move it to right directory, using the following commands. cd data mv ~/Downloads/Day_3.zip . unzip Day_3.zip cd Day_3 You will find all practical materials in the data/Day_3 directory. Relevant materials that you should see there at the start of the practical are as follows: \ud83d\udcc2: Base_Data - GIANT_Height.txt, - cad.add.txt, - cad.add.readme. \ud83d\udcc2: Target_Data - TAR.fam - TAR.bim - TAR.bed - TAR.height - TAR.cad - TAR.covariate \ud83d\udcc1: Reference files - Homo_sapiens.GRCh38.86.gt - Sets.gmt \ud83d\udee0\ufe0f: Software - PRSice.R - PRSice_linux - nagelkerke.R - Quantile.R \u203c\ufe0f All target phenotype data in this worshop are simulated . They have no specific biological meaning and are for demonstration purposes only. Back to Top","title":"Data Sets"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#exercise-1-estimating-r2-in-case-and-control-studies","text":"Bias in R 2 estimation caused by ascertained case/control samples can be adjusted using the equation proposed by Lee et al (2011) , which requires the sample prevalence (case/control ratio) and population prevalence as parameters. This function is implemented in PRSice and the adjustment can be performed by providing the population prevalence to the command --prevalence . Residuals of logistic regression is not well defined, and in PRS analyses, Nagelkerke R 2 is usually used to represent the model R 2 (this is the default of PRSice). However, this R 2 does not account for the di\ufb00erence between sample prevalence (i.e. case-control ratio) and population prevalence, which can lead to bias in the reported R 2 (Figure 1.1a). Figure 1.1: Performance of di\ufb00erent R 2 when the study contains equal portion of cases and controls (a) Nagelkerke R 2 Bias in R 2 estimation caused by ascertained case/control samples can be adjusted using the equation proposed by Lee et al. 2011 (Figure 1.1b) , which requires the sample prevalence (case/control ratio) and population prevalence as parameters. This function is implemented in PRSice and the adjustment can be performed by providing the population prevalence to the command --prevalence . Figure 1.1: Performance of di\ufb00erent R 2 when the study contains equal portion of cases and controls (b) Lee adjusted R 2 Now, account for the ascertainment of the case/control sample by including the population prevalence (let\u2019s assume e.g. 5% here) in the PRSice command to obtain the adjusted (Lee) R 2 : Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/cad.add.txt \\ --target Target_Data/TAR \\ --snp markername \\ --A1 effect_allele \\ --A2 noneffect_allele \\ --chr chr \\ --bp bp_hg19 \\ --stat beta \\ --beta \\ --pvalue p_dgc \\ --pheno Target_Data/TAR.cad \\ --prevalence 0.05 \\ --binary-target T \\ --out Results/CAD.highres.LEER2 The results are written to the \"Results\" directory. Examine the results folder and each file that was generated. For more information about each file type, see here . \u2b50 Check the *.summary file in the Results folder where you will find the usual (Nagelkerke) R 2 and the adjusted (Lee) R 2 . Figure 1.2: Barplot of CAD Lee R 2 \ud83d\udccc To speed up the practical, we have generated a smaller gene-set file. If you want the full gene-set file, you can download it from the link above. \ud83d\udccc All target phenotype data in this workshop are simulated. While they reflect the corresponding trait data, they have no specific biological meaning and are for demonstration purposes only. \u2753Has accounting for the population prevalence a\ufb00ected the R 2 ? Solution Yes, the adjusted R 2 = 0.0521524 and default R 2 = 0.0442664 \u2753Would you expect a di\ufb00erence between the Nagelkerke R 2 and the Lee adjusted R 2 if the case/control ratio in the target sample reflects the disease prevalence in the population? Solution No, the R 2 will be the same because the prevalence of the target is a true representation of the population prevalence. Back to Top","title":"Exercise 1 Estimating R2 in case and control studies"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#exercise-2-overfitting-caused-by-model-optimisation","text":"In PRS analyses, the shrinkage or tuning parameter is usually optimized across a wide range of parametric space (e.g. P -value threshold, proportion of causal SNPs). When both optimisation and association testing are performed on the target data, over-fitted results will be obtained. The accuracy and predictive power of over-fitted results are likely to diminish when replicated in an independent data set. A simple solution is to perform permutation to obtain an empirical P -value for the association model, which is implemented in PRSice. Briefly, permutation is performed as follows: 1) Compute the P -value in your original data, denoted as obs.p, at the \"best\" threshold. 2) Then shu\ufb04e the phenotype and obtain the P -value of the \"best\" threshold for this null phenotype, denoted as null.p 3) Repeat 2) N times 4) Calculate the empirical P-value as:","title":"Exercise 2 Overfitting caused by model optimisation"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#pemp-sumobsp-nullpi-1-n-1","text":"You will have to specify the number of permutation (N ) to perform by providing --perm N as a parameter to PRSice.","title":"\\(Pemp = (\\sum(obs.p &gt; null.pi + 1) / (N + 1)\\)"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#rscript-softwareprsicer-prsice-softwareprsice_linux-base-base_datagiant_heighttxt-target-target_datatar-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datatarheight-binary-target-f-cov-target_datatarcovariate-cov-col-sex-perm-1000-out-resultsheightperm","text":"Figure 1.3: Barplot of Height using 1000 permutations \ud83d\udcdd 10000 permutations typically provide empirical P-values with high accuracy to the second decimal place (eg. 0.05), but smaller empirical P-values should be considered approximate. \u2753 What is the smallest possible empirical P-value when 10000 permutation are performed? Solution 1.5 X 10 -34 . \u2753 Is the height PRS significantly associated with height after accounting for the over-fitting implicit in identifying the best-fit PRS? How about CAD? Solution Yes, the height PRS is significantly associated with height. After accounting for the over-fitting implicit in identifying the best-fit PRS, the emprical p-value is 0.000999001.","title":"Rscript ./Software/PRSice.R \\\n    --prsice Software/PRSice_linux \\\n    --base  Base_Data/GIANT_Height.txt \\\n    --target Target_Data/TAR \\\n    --snp MarkerName \\\n    --A1 Allele1 \\\n    --A2 Allele2 \\\n    --stat b \\\n    --beta \\\n    --pvalue p \\\n    --pheno Target_Data/TAR.height \\\n    --binary-target F \\\n    --cov Target_Data/TAR.covariate \\\n    --cov-col Sex \\\n    --perm 1000 \\\n    --out Results/Height.perm\n"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#out-of-sample-validation","text":"The best way to avoid having results that are over-fit is to perform validation on an independent validation data set. We can perform validation of the previous height + covariate analysis with PRSice, using the independent VAL target sample as validation data and the \"best\" P-value threshold predicted in the VAL samples:","title":"Out of Sample Validation"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#rscript-softwareprsicer-prsice-softwareprsice_linux-base-base_datagiant_heighttxt-target-target_dataval-snp-markername-a1-allele1-a2-allele2-stat-b-beta-pvalue-p-pheno-target_datavalheight-binary-target-f-no-full-bar-levels-00680001-fastscore-cov-target_datavalcovariate-cov-col-sex-out-resultsheightval","text":"Figure 1.4: Barplot of Height validation dataset \u2753 Why do we use --bar-levels 0.0680001 --no-full and --fastscore in this script? \u2753 How does the PRS R2 and P -value for the validation data set compare to the analysis on the TAR target data? Is this what you would expect? Why? Back to Top","title":"Rscript ./Software/PRSice.R \\\n    --prsice Software/PRSice_linux \\\n    --base  Base_Data/GIANT_Height.txt \\\n    --target Target_Data/VAL \\\n    --snp MarkerName \\\n    --A1 Allele1 \\\n    --A2 Allele2 \\\n    --stat b \\\n    --beta \\\n    --pvalue p \\\n    --pheno Target_Data/VAL.height \\\n    --binary-target F \\\n    --no-full \\\n    --bar-levels 0.0680001 \\\n    --fastscore \\\n    --cov Target_Data/VAL.covariate \\\n    --cov-col Sex \\\n    --out Results/Height.val\n"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#exercise-3-distribution-of-prs","text":"Many PRS study publications include quantile plots that show an exponential increase in phenotypic value or / Odd Ratios (OR) among the top quantiles (e.g. an S-shaped quantile plot, e.g. Figure 1.6). Figure 1.5: An example of density plot for PRS Figure 1.6: An example of a S-shaped quantile plot This might lead us to believe that individuals with PRS values in the top quantiles have a distinctly di\ufb00erent genetic aetiology compared to the rest of the sample, or that there is epistasis/interactions causing there substantially higher risk. However, when we plot a normally distributed variable (e.g. a PRS) as quantiles on the X-axis then we expect to observe this exponential pattern even when the X variable only has a linear e\ufb00ect on the Y variable. This is because the top (and bottom) quantiles are further away from each other on the absolute scale of the variable and so the di\ufb00erences in their e\ufb00ects are larger than between quantiles in the middle of the distribution. To understand this more, we will perform a simple simulation using R: R # First, we define some simulation parameters n.sample <- 10000 PRS.r2 <- 0.01 # Then, we simulate PRS that follow a random normal distribution prs <- rnorm(n.sample) # We can then simulate the phenotype using the following script pheno <- prs + rnorm(n.sample,mean=0, sd=sqrt(var(prs)*(1-PRS.r2)/(PRS.r2))) # We can examine the relationship between the phenotype and prs # using linear regression summary(lm(pheno~prs)) # Which shows that we have the expected PRS R2 # Group the phenotype and PRS into a data.frame info <- data.frame(SampleID=1:n.sample, PRS=prs, Phenotype=pheno) # Then we can generate the quantile plot. # To save time, we will load in the quantile plot script from Software source(\"./Software/Quantile.R\") # Then we can plot the quantile plot using quantile_plot function quantile_plot(info, \"Results/Height\", 100) Figure 1.7: The resulting quantile plot \u2753 What is the shape of the resulting quantile plot? \u2753 Try plotting the densities of the height or CAD PRS in R * - do they look normally distributed? Why? (*Hint: You can generate a density plot for the PRS in R using plot(density(x)) where x is a vector of the PRS values in the sample). Back to Top","title":"Exercise 3 Distribution of PRS"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#gene-set-analysis","text":"Currently, most PRS analyses have been performed on a genome-wide scale, disregarding the underlying biological pathways. Udler et al. 2018 suggest that grouping Single Nucleotide Polymorphisms (SNPs) into biological functional groups can lead to PRS that are more relevant to clinical risk. In this practical, we will go through some common file formats for gene-set analysis and will then calculate some gene-set (or pathway) based PRS.","title":"Gene Set Analysis"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#molecular-signatures-database-msigdb","text":"The Molecular Signatures Database (MSigDB) o\ufb00ers an excellent source of gene-sets, including the hallmark genes, gene-sets of di\ufb00erent biological processes, gene-sets of di\ufb00erent oncogenic signatures etc. All gene-sets from MSigDB follows the Gene Matrix Transposed file format (GMT), which consists of one line per gene-set, each containing at least 3 column of data: Set A Description Gene 1 Gene 2 ... Set A Description Gene 1 Gene 2 ... ** Have a look at the Reference/Sets.gmt file. ** \u2753 How many gene-sets are there in the Reference/Sets.gmt file? \u2753 How many genes does the largest gene-set contain? \ud83d\udcac While you can read the GMT file using Excel. You should be aware that Excel has a tendency to convert gene names into dates (e.g. SEPT9 to Sep-9) As GMT format does not contain the chromosomal location for each individual gene, an additional file is required to provide the chromosoaml location such that SNPs can be map to genes.","title":"Molecular Signatures Database MSigDB"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#general-transfer-format-file","text":"The General Transfer Format (GTF) file contains the chromosomal coordinates for each gene. It is a tab separated file and all but the final field in each feature line must contain a value. \"Empty\" columns should be denoted with a \u2018.\u2019. You can read the full format specification here. One column that might be of particular interest is column 3: feature , which indicates what feature that line of GTF represents. This allows us to select or ignore features that are of interest. You can find the description of each feature here .","title":"General Transfer Format file"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#browser-extensible-data-bed","text":"Browser Extensible Data (BED) file (di\ufb00erent to the binary ped file from PLINK) is a file format to define genetic regions. It contains 3 required fields per line (chromosome, start coordinate and end coordinate) together with 9 additional optional field. A special property of BED is that it is a 0-based format, i.e. chromosome starts at 0, as opposed to the usual 1-based format such as the PLINK format. For example, a SNP on chr1:10000 will be represented as: 1 9999 10000 \u2753 How should we represent the coordinate of rs2980300 (chr1:785989) in BED format? Back to Top","title":"Browser Extensible Data BED"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#gene-set-enrichment-analysis","text":"Now we have gone through all the files involved in gene-set analysis, we should consider one of the most important aspects of gene-set (or pathway) enrichment analyses, which is the di\ufb00erent types of testing that we can perform when doing them:","title":"Gene Set Enrichment Analysis"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#self-contained-vs-competitive-testing","text":"The null-hypothesis of self-contained and competitive test statistics is di\ufb00erent: \u2013 Self-Contained - None of the genes within the gene-set are associated with the phenotype \u2013 Competitive - Genes within the gene-set are no more associated with the phenotype than genes outside the gene-set Therefore, a bigger gene-set will have a higher likelihood of having a significant P -value from self-contained test, which is not desirable.","title":"Self-Contained vs Competitive Testing"},{"location":"tmp2/prs_2023-main/modules/Day3.docx/#exercise-4-gene-set-based-prs-analysis","text":"Having learnt about the basics of gene-set analyses, we are now ready to perform gene-set association analyses using PRSet. To perform the PRSet analysis and obtain the set based PRS and competitive P-value, simply provide the GTF file and the GMT file to PRSice and specify the number of permutation for competitive P-value calculation using the --set-perm option. Rscript ./Software/PRSice.R \\ --prsice Software/PRSice_linux \\ --base Base_Data/GIANT_Height.txt \\ --target Target_Data/TAR \\ --A1 Allele1 \\ --A2 Allele2 \\ --snp MarkerName \\ --pvalue p \\ --stat b \\ --beta \\ --binary-target F \\ --pheno Target_Data/TAR.height \\ --cov Target_Data/TAR.covariate \\ --out Results/Height.set \\ --gtf Reference/Homo_sapiens.GRCh38.86.gtf \\ --wind-5 5kb \\ --wind-3 1kb \\ --msigdb Reference/Sets.gmt \\ --multi-plot 10 \\ --set-perm 1000 Figure 1.8: An example of the multi-set plot. Sets are sorted based on their self-contained R2 . Base is the genome wide PRS \ud83d\udccc If the --wind-5 and --wind-3 flag is not specified, PRSet will use the exact coordinates of each gene as the boundary. By specifying eg. --wind-5 5kb and --wind-3 1kb then the boundary of each gene will be extended 5 kb towards the 5\u2019 end and 1 kb towards the 3\u2019 end so that regulatory elements of the gene can be included. \ud83d\udccd By default, when calculating set based PRS, PRSet will not perform P -value thresholding. This is because the aim in gene-set analyses is to assess the overall signal in each gene-set, and compare which is most enriched for signal, rather than optimise predictive power as typically desirable for genome-wide PRS. Providing any of the following commands will activate P -value thresholding for set based PRS calculation: --lower, --upper, --inter, --bar-levels, --fastscore \u2753 Can you plot the relationship between the gene-set R2 and the number of SNPs in each gene-set? What general trend can be seen? \u2753 Considering the plot, what gene-sets do you think are most interesting and why? \u2753 Why is it useful to have polygenic scores measured across gene-sets (or pathways) for individuals? Isn\u2019t it su\ufb03cient to just obtain a ranking of gene-sets according to GWAS-signal enrichment?","title":"Exercise 4 Gene Set Based PRS Analysis"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/","text":"Introduction to Cross-Ancestry PRS analysis Before starting the practical the following commands will need to be run from within your virtual machine: (1) conda create -n \"PRScsx\" python=3.7 (2) conda activate PRScsx (3) pip install scipy (4) pip install h5py The goal of this practical is to provide you with basic understanding and experience of running the PRS-CSx software. After completing this practical, you should: * Be able to perform cross-population descriptives. * Be familiar with running cross-ancestry PRS analyses using PRS-CSx. * Understand how to evaluate linear models using Akaike\u2019s Information Criterion 1. The 1000 Genomes dataset The data we will be working with are coming from the 1000 Genomes Project reference panel. The data relates to individuals from 26 different source populations around the world. For simplicity, the populations have been collapsed into 5 broader continental super-populations: East Asian, European, South Asian, Amerindian, African ((EAS, EUR, SAS, EUR and AFR)). The scripts used to download and process the 1000Genomes data for the purposes of this course will be provided in the course appendix at the end of this week. 2. Cross-population allele frequency Genetic variation is conveyed using allelic frequencies. Allele frequency is shaped by evolutionary forces and drift. Here we compare profiles of allele frequency across the five ancestral populations. Global differences in allelic frequency has important implications for the portability of PRS across populations. Using plink it is possible to generate allele frequency statistics for each SNP, across populations, using the annotations provided in the file pop_info.pheno. In /home/manager/data/Data_Day4 : ./software/plink_linux --bfile ./data/chr1-22 --freq --within ./data/pop_info.pheno Population-stratified allele frequencies are reported in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: grep -F 'AFR' plink.frq.strat | wc -l From there we can print the number of SNPs with minor allele frequencies greater than 0 (and are hence potentially available for genomic analyes). grep -F 'EAS' plink.frq.strat | awk '$6 >0' | wc -l Recycle the code above to find the number of available SNPs in each of the 4 other global populations (EUR, AFR, SAS, AMR). Questions (i) Which population contains the most SNPs? (ii) What is the significance of the observed population order? 3. Distribution of allele frequencies R library ( dplyr ) library ( ggplot2 ) freq <-read.table ( \"plink.frq.strat\" , header = T ) plotDat <- freq %>% mutate ( AlleleFrequency = cut ( MAF, seq (0 , 1 , 0 .25 ))) %>% group_by ( AlleleFrequency, CLST ) %>% summarise ( FractionOfSNPs = n () /nrow ( freq ) * 100) ggplot ( na.omit ( plotDat ) , aes ( AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST )) + geom_line () + scale_y_continuous ( limits = c (0 , 12)) + ggtitle ( \"Distribution of allele frequency across genome\" ) Questions (i) Which population has the most SNPs? (ii) What is the significance of the observed population ordering? (iii) What is the reason behind these two features? 4. Calculation of Fst Fst is a formal metric which is used to convey the level of genetic divergence between populations (on a scale between 0 and 1), using information derived from a set of genome-wide and mutually independent SNPs. Fst between parwise populations is estimated efficiently in Plink-2. So first we need to download Plink-2 using the command below: sudo apt install plink2 A higher Fst corresponds to greater divergence between populations. Use the following command to calculate Fst: plink2 --bfile ./data/chr1-22 --fst POP --pheno ./data/pop_info.pheno Check the output file plink2.fst.summary Questions (i) Which population pairs have the highest Fst ? (ii) For which populations is Fst smallest?? Introduction to PRS-CSx 5. Background to PRS-CSX PRS-CSx is a Python based command line tool that integrates GWAS summary statistics and external LD reference panels from multiple populations to improve cross-population polygenic prediction. We will be using simulated trait data pertaininng to systolic blood pressure (SBP) to explore PRS performance using 2 target populations that consist of 650 individuals of African ancestry and 500 individuals of European ancestry. Please note when running PRSice that the object of the flag \"--prsice\" will change according to whether plink is being called within the linux-like environment of the virtual machine (PRSice_linux) or a mac (PRSice_mac). Both executables can be found in the /home/manager/data/Data_Day4 directory. 6. Extraction of SNPs PRS-CSx uses only HAPMAP3 SNPs therefore we produce a set of plink files containing this SNP subset. ./software/plink_linux --bfile ./data/1kg.eur.dbSNP153.hg38 --extract ./data/csxsnp --make-bed --out ./data/EUR_1kg.hm3.only.csx ./software/plink_linux --bfile ./data/1kg.afr.dbSNP153.hg38 --extract ./data/csxsnp --make-bed --out ./data/AFR_1kg.hm3.only.csx 7. Running PRS-CSx To model the coupling of effect sizes at individual SNPs across ancestries PRS-CSx uses an MCMC (Bayesian) sampling algorithm to determine values of the global shrinkage parameter (\"phi\") by Maximum likelihood. For samples of mixed or admixed genetic ancestry (which ours are not) the optimal value of the shrinkage parameter is estimated autonomously from the data. Here we use the value of phi (1e-4), which is suggested by the software authors, given that our trait is simulated to have a relatively small number (N=110) causal variants, distributed genome-wide. To save time, we will be running the analyses across chromosome 15, rather than the entire genome. The commands needed to run PRS-CSx are contained in two script files, located in /home/manager/data/Data_Day4/scripts. The file run_prscsx_afr-target.sh is used to estimate optimal SNP weights for predicting into the African target population. NB - move the snp file to the reference folder cp /home/manager/PRScsx/snpinfo_mult_1kg_hm3 /home/manager/data/Data_Day4/reference/csx NB - the ld block files must be moved to /home/manager/data/Data_Day4/reference/csx to /home/manager/PRScsx/ mv /home/manager/PRScsx/*.tar.gz /home/manager/PRScsx/ then extracted with tar tar -xvfz ld...tar.gz be careful of space, your vm has 100GB cap. remove the .gz files once extracted Script contents : python /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir = /home/manager/data/Data_Day4/reference/csx \\ --bim_prefix = /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --sst_file = /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx,/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --n_gwas =25732 ,4855 \\ --pop = EUR,AFR \\ --chrom =15 \\ --phi = 1e-4 \\ --out_dir = /home/manager/data/Data_Day4/out/csx \\ --out_name = afr.target.csx The file run_prscsx_eur-target.sh is used to estimate optimal SNP weights for predicting into the European target population: Script contents : python /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir = /home/manager/data/Data_Day4/reference/csx \\ --bim_prefix = /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --sst_file = /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx,/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --n_gwas =25732 ,4855 \\ --pop = EUR,AFR \\ --chrom =15 \\ --phi = 1e-4 \\ --out_dir = /home/manager/data/Data_Day4/out/csx \\ --out_name = eur.target.csx Prior to running each script you will need to update the first line with a reference (i.e the pathname) to your home directory. From /home/manager/data/Data_Day4 the scripts can then be run as follows: ./scripts/run_prscsx_afr-target.sh ./scripts/run_prscsx_eur-target.sh Questions (i) How many results files do you see in the output directory? (ii) What does each file correspond to? (ii) In which column are the adjusted SNP weights contained? 8. Processing The next step would be to collate adjusted SNP weight information from multiple chromosomes and relabel the consolidated files for clarity. The following code works regardless of whether the preceding PRS-CSx analysis was performed for single or multiple chromosomes. In /home/manager/data/Data_Day4/out/csx for file in afr.target.csx_AFR_*; do cat $file >> posteriors.afr.by.afr done for file in afr.target.csx_EUR_*; do cat $file >> posteriors.afr.by.eur done for file in eur.target.csx_AFR_*; do cat $file >> posteriors.eur.by.afr done for file in eur.target.csx_EUR_*; do cat $file >> posteriors.eur.by.eur done 9. Data processing in R The next stage of data processing, done in R will create a new set of summary statistics files, containing the adjusting SNP weights from PRS-CSx. Staying in /home/manager/data/Data_Day4/out/csx : R # Load posteriors effect sizes from PRS-CSx output afr.afr<-read.table ( \"posteriors.afr.by.afr\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.afr.afr\" )) afr.by.eur<-read.table ( \"posteriors.afr.by.eur\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.afr.by.eur\" )) eur.eur<-read.table ( \"posteriors.eur.by.eur\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.eur.eur\" )) eur.by.afr<-read.table ( \"posteriors.eur.by.afr\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.eur.by.afr\" )) # Load original summary statistics afr.SBP<-read.table ( \"/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx\" , header = T ) eur.SBP<-read.table ( \"/home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx\" , header = T ) # Combine the posterior derived weights and summary statistics eur.SBP.merge1<-merge ( x = eur.SBP, y = eur.eur [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) eur.SBP.merge<-merge ( x = eur.SBP.merge1, y = afr.by.eur [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) afr.SBP.merge1<-merge ( x = afr.SBP, y = afr.afr [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) afr.SBP.merge<-merge ( x = afr.SBP.merge1, y = eur.by.afr [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) # Save files write.table ( afr.SBP.merge, \"/home/manager/data/Data_Day4/afr.SBP.posterior.sumstats\" , quote = F, row.names = F ) write.table ( eur.SBP.merge, \"/home/manager/data/Data_Day4/eur.SBP.posterior.sumstats\" , quote = F, row.names = F ) q () 10. Use PRSice to apply the adjusted SNP effects to target phenotypes We first need to create a list of SNPs to be used as input, based on the previous PRS-CSx analysis. This is done in location /home/manager/data/Data_Day4 . awk 'NR>1 {print $1}' afr.SBP.posterior.sumstats > snps.afr.posterior awk 'NR>1 {print $1}' eur.SBP.posterior.sumstats > snps.eur.posterior The next series of commands implement in-ancestry and cross-ancestry prediction of the systolic blood pressure phenotype using the PRS-CSx optimised SNP weights. Do not forget to exchange PRSice_linux for PRSice_mac if running the commands in a Mac environment. The phenotypic files sbp_afr_1kg.sim_pheno and sbp_eur_1kg.sim_pheno contain data on systolic blood pressure with simulated heritabilities that vary from 10%, 20%, 33%, 50% and 100%. To compensate for the fact that the adjusted weights generated are based on chromosome 15, rather than the entire genome, we will be using the 100% trait version (pheno100) for this analysis. 11. Predicting from African training to African target data Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/afr.sbp.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.afr.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.afr.afr \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.afr 12. Predicting from European training to African target data Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/eur.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.eur.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.afr.by.eur \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.by.eur 13. Predicting from European training to European target data Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/eur.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.eur.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.eur.eur \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.eur 14. Predicting from African training to European target data Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/afr.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.afr.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.eur.by.afr \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.by.afr 15. Create summary files From location /home/manager/data/Data_Day4/out/prscsx_prsice awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.afr.afr.summary > quicksum.afr-afr awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.afr.by.eur.summary > quicksum.afr-by-eur awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.eur.by.afr.summary > quicksum.eur-by-afr awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.eur.eur.summary > quicksum.eur-eur Questions (i) What information is being summarized in the output files?? (ii) For each prediction model what is the R2 and value??? 16. Complete the remaining PRS analysis in R Step 1: Load and prepare data R # Load libraries sudo apt install cmake install.packages ( \"AICcmodavg\" ) install.packages ( \"fmsb\" ) library ( AICcmodavg ) library ( fmsb ) afr.afr<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.afr.best\" , header = T ) afr.eur<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.by.eur.best\" , header = T ) eur.eur<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.eur.best\" , header = T ) eur.afr<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.by.afr.best\" , header = T ) colnames ( afr.afr )[4] <- \"afr.afr\" # african prediction using african PRS colnames ( afr.eur )[4] <- \"afr.eur\" # african prediction using european PRS colnames ( eur.eur )[4] <- \"eur.eur\" # european prediction using european PRS colnames ( eur.afr )[4] <- \"eur.afr\" # european prediction using african PRS # Merge PRSs according to target ancestry and source population combined.afr<-merge ( x = afr.afr, y = afr.eur [ c (2 ,4 )] , by = \"IID\" , all.x = T ) combined.eur<-merge ( x = eur.eur, y = eur.afr [ c (2 ,4 )] , by = \"IID\" , all.x = T ) # Rescale scores to have mean = \u20180\u2019 and standard deviation = \u20181\u2019 combined.afr [4 :5 ] <- as.data.frame ( scale ( combined.afr [4 :5 ])) combined.eur [4 :5 ] <- as.data.frame ( scale ( combined.eur [4 :5 ])) # Load phenotype data sbp.eur<-read.table ( \"/home/manager/data/Data_Day4/data/SBP_eur_1kg.sim_pheno\" , header = T ) sbp.afr<-read.table ( \"/home/manager/data/Data_Day4/data/SBP_afr_1kg.sim_pheno\" , header = T ) # Merge phenotypes and PRS combined.eur.pheno<-merge ( x = combined.eur [ -c (2 ,3 )] , y = sbp.eur [ ,c (2 ,3 )] , by = \"IID\" , all.x = T ) combined.afr.pheno<-merge ( x = combined.afr [ -c (2 ,3 )] , y = sbp.afr [ ,c (2 ,3 )] , by = \"IID\" , all.x = T ) Step 2: Model selection using Akaike\u2019s Information Criterion In the final step we want to determine whether the use of the multi-ancestry PRS formulation generated by PRS-CSx performs better at predicting systolic blood pressure, compared to the single-ancestry PRS formulation. To do this we use (AIC Akaike\u2019s Information Criterion). AIC is used to assess the performance of a competing set of regression models. We use it to compare the performance of models that contain different numbers of predictors, given that R2 is inflated by the inclusion of redundant terms in a model. 16b. Model evaluation # EUROPEAN model1.eur <- glm ( pheno100 ~ eur.eur, data = combined.eur.pheno, family = gaussian ) model2.eur <- glm ( pheno100 ~ eur.afr, data = combined.eur.pheno, family = gaussian ) model3.eur <- glm ( pheno100 ~ eur.eur + eur.afr, data = combined.eur.pheno, family = gaussian ) models.eur <- list ( model1.eur, model2.eur, model3.eur ) # define model set mod.names.eur <- c ( 'eur.eur' , 'eur.afr' , 'eur.combined' ) # add model names aictab ( cand.set = models.eur, modnames = mod.names.eur ) # calculate model AICs model # AFRICAN model1.afr <- glm ( pheno100 ~ afr.afr, data = combined.afr.pheno, family = gaussian ) model2.afr <- glm ( pheno100 ~ afr.eur, data = combined.afr.pheno, family = gaussian ) model3.afr <- glm ( pheno100 ~ afr.afr + afr.eur, data = combined.afr.pheno, family = gaussian ) models.afr <- list ( model1.afr, model2.afr, model3.afr ) # define model set mod.names.afr <- c ( 'afr.afr' , 'afr.eur' , 'afr.combined' ) # add model names aictab ( cand.set = models.afr, modnames = mod.names.afr ) # calculate model AICs # NagelkerkeR2 calculations in R # African target NagelkerkeR2 ( model1.afr ) NagelkerkeR2 ( model2.afr ) NagelkerkeR2 ( model3.afr ) # European target NagelkerkeR2 ( model1.eur ) NagelkerkeR2 ( model2.eur ) NagelkerkeR2 ( model3.eur ) For each ancestry which predictive model performs best and worst? Does combining the two sets of adjusted scores perform consistently better than modelling each one separately? Questions (i) For each ancestry which model performs best and which performs worst? (ii) Does linearly combining adjusted scores (European plus African) always result in better performance compared to single-ancestry prediction?","title":"Day4.docx"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#introduction-to-cross-ancestry-prs-analysis","text":"Before starting the practical the following commands will need to be run from within your virtual machine: (1) conda create -n \"PRScsx\" python=3.7 (2) conda activate PRScsx (3) pip install scipy (4) pip install h5py The goal of this practical is to provide you with basic understanding and experience of running the PRS-CSx software. After completing this practical, you should: * Be able to perform cross-population descriptives. * Be familiar with running cross-ancestry PRS analyses using PRS-CSx. * Understand how to evaluate linear models using Akaike\u2019s Information Criterion","title":"Introduction to Cross-Ancestry PRS analysis"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#1-the-1000-genomes-dataset","text":"The data we will be working with are coming from the 1000 Genomes Project reference panel. The data relates to individuals from 26 different source populations around the world. For simplicity, the populations have been collapsed into 5 broader continental super-populations: East Asian, European, South Asian, Amerindian, African ((EAS, EUR, SAS, EUR and AFR)). The scripts used to download and process the 1000Genomes data for the purposes of this course will be provided in the course appendix at the end of this week.","title":"1. The 1000 Genomes dataset"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#2-cross-population-allele-frequency","text":"Genetic variation is conveyed using allelic frequencies. Allele frequency is shaped by evolutionary forces and drift. Here we compare profiles of allele frequency across the five ancestral populations. Global differences in allelic frequency has important implications for the portability of PRS across populations. Using plink it is possible to generate allele frequency statistics for each SNP, across populations, using the annotations provided in the file pop_info.pheno. In /home/manager/data/Data_Day4 : ./software/plink_linux --bfile ./data/chr1-22 --freq --within ./data/pop_info.pheno Population-stratified allele frequencies are reported in the output file plink.frq.strat. For each population, print the numbers of total SNPs to screen, as follows: grep -F 'AFR' plink.frq.strat | wc -l From there we can print the number of SNPs with minor allele frequencies greater than 0 (and are hence potentially available for genomic analyes). grep -F 'EAS' plink.frq.strat | awk '$6 >0' | wc -l Recycle the code above to find the number of available SNPs in each of the 4 other global populations (EUR, AFR, SAS, AMR).","title":"2. Cross-population allele frequency"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#questions","text":"","title":"Questions"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#i-which-population-contains-the-most-snps","text":"","title":"(i) Which population contains the most SNPs?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#ii-what-is-the-significance-of-the-observed-population-order","text":"","title":"(ii) What  is the significance of the observed population order?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#3-distribution-of-allele-frequencies","text":"R library ( dplyr ) library ( ggplot2 ) freq <-read.table ( \"plink.frq.strat\" , header = T ) plotDat <- freq %>% mutate ( AlleleFrequency = cut ( MAF, seq (0 , 1 , 0 .25 ))) %>% group_by ( AlleleFrequency, CLST ) %>% summarise ( FractionOfSNPs = n () /nrow ( freq ) * 100) ggplot ( na.omit ( plotDat ) , aes ( AlleleFrequency, FractionOfSNPs, group = CLST, col = CLST )) + geom_line () + scale_y_continuous ( limits = c (0 , 12)) + ggtitle ( \"Distribution of allele frequency across genome\" )","title":"3. Distribution of allele frequencies"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#questions_1","text":"","title":"Questions"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#i-which-population-has-the-most-snps","text":"","title":"(i) Which population has the most SNPs?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#ii-what-is-the-significance-of-the-observed-population-ordering","text":"","title":"(ii) What  is the significance of the observed population ordering?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#iii-what-is-the-reason-behind-these-two-features","text":"","title":"(iii) What is the reason behind these two features?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#4-calculation-of-fst","text":"Fst is a formal metric which is used to convey the level of genetic divergence between populations (on a scale between 0 and 1), using information derived from a set of genome-wide and mutually independent SNPs. Fst between parwise populations is estimated efficiently in Plink-2. So first we need to download Plink-2 using the command below: sudo apt install plink2 A higher Fst corresponds to greater divergence between populations. Use the following command to calculate Fst: plink2 --bfile ./data/chr1-22 --fst POP --pheno ./data/pop_info.pheno Check the output file plink2.fst.summary","title":"4. Calculation of Fst"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#questions_2","text":"","title":"Questions"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#i-which-population-pairs-have-the-highest-fst","text":"","title":"(i) Which population pairs have the highest Fst ?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#ii-for-which-populations-is-fst-smallest","text":"","title":"(ii) For which populations is Fst smallest??"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#introduction-to-prs-csx","text":"","title":"Introduction to PRS-CSx"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#5-background-to-prs-csx","text":"PRS-CSx is a Python based command line tool that integrates GWAS summary statistics and external LD reference panels from multiple populations to improve cross-population polygenic prediction. We will be using simulated trait data pertaininng to systolic blood pressure (SBP) to explore PRS performance using 2 target populations that consist of 650 individuals of African ancestry and 500 individuals of European ancestry. Please note when running PRSice that the object of the flag \"--prsice\" will change according to whether plink is being called within the linux-like environment of the virtual machine (PRSice_linux) or a mac (PRSice_mac). Both executables can be found in the /home/manager/data/Data_Day4 directory.","title":"5. Background to PRS-CSX"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#6-extraction-of-snps","text":"PRS-CSx uses only HAPMAP3 SNPs therefore we produce a set of plink files containing this SNP subset. ./software/plink_linux --bfile ./data/1kg.eur.dbSNP153.hg38 --extract ./data/csxsnp --make-bed --out ./data/EUR_1kg.hm3.only.csx ./software/plink_linux --bfile ./data/1kg.afr.dbSNP153.hg38 --extract ./data/csxsnp --make-bed --out ./data/AFR_1kg.hm3.only.csx","title":"6. Extraction of SNPs"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#7-running-prs-csx","text":"To model the coupling of effect sizes at individual SNPs across ancestries PRS-CSx uses an MCMC (Bayesian) sampling algorithm to determine values of the global shrinkage parameter (\"phi\") by Maximum likelihood. For samples of mixed or admixed genetic ancestry (which ours are not) the optimal value of the shrinkage parameter is estimated autonomously from the data. Here we use the value of phi (1e-4), which is suggested by the software authors, given that our trait is simulated to have a relatively small number (N=110) causal variants, distributed genome-wide. To save time, we will be running the analyses across chromosome 15, rather than the entire genome. The commands needed to run PRS-CSx are contained in two script files, located in /home/manager/data/Data_Day4/scripts. The file run_prscsx_afr-target.sh is used to estimate optimal SNP weights for predicting into the African target population. NB - move the snp file to the reference folder cp /home/manager/PRScsx/snpinfo_mult_1kg_hm3 /home/manager/data/Data_Day4/reference/csx NB - the ld block files must be moved to /home/manager/data/Data_Day4/reference/csx to /home/manager/PRScsx/ mv /home/manager/PRScsx/*.tar.gz /home/manager/PRScsx/ then extracted with tar tar -xvfz ld...tar.gz be careful of space, your vm has 100GB cap. remove the .gz files once extracted Script contents : python /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir = /home/manager/data/Data_Day4/reference/csx \\ --bim_prefix = /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --sst_file = /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx,/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --n_gwas =25732 ,4855 \\ --pop = EUR,AFR \\ --chrom =15 \\ --phi = 1e-4 \\ --out_dir = /home/manager/data/Data_Day4/out/csx \\ --out_name = afr.target.csx The file run_prscsx_eur-target.sh is used to estimate optimal SNP weights for predicting into the European target population: Script contents : python /home/manager/data/Data_Day4/software/PRScsx.py \\ --ref_dir = /home/manager/data/Data_Day4/reference/csx \\ --bim_prefix = /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --sst_file = /home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx,/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx \\ --n_gwas =25732 ,4855 \\ --pop = EUR,AFR \\ --chrom =15 \\ --phi = 1e-4 \\ --out_dir = /home/manager/data/Data_Day4/out/csx \\ --out_name = eur.target.csx Prior to running each script you will need to update the first line with a reference (i.e the pathname) to your home directory. From /home/manager/data/Data_Day4 the scripts can then be run as follows: ./scripts/run_prscsx_afr-target.sh ./scripts/run_prscsx_eur-target.sh","title":"7. Running PRS-CSx"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#questions_3","text":"","title":"Questions"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#i-how-many-results-files-do-you-see-in-the-output-directory","text":"","title":"(i) How many results files do you see in the output directory?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#ii-what-does-each-file-correspond-to","text":"","title":"(ii) What does each file correspond to?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#ii-in-which-column-are-the-adjusted-snp-weights-contained","text":"","title":"(ii) In which column are the adjusted SNP weights contained?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#8-processing","text":"The next step would be to collate adjusted SNP weight information from multiple chromosomes and relabel the consolidated files for clarity. The following code works regardless of whether the preceding PRS-CSx analysis was performed for single or multiple chromosomes. In /home/manager/data/Data_Day4/out/csx for file in afr.target.csx_AFR_*; do cat $file >> posteriors.afr.by.afr done for file in afr.target.csx_EUR_*; do cat $file >> posteriors.afr.by.eur done for file in eur.target.csx_AFR_*; do cat $file >> posteriors.eur.by.afr done for file in eur.target.csx_EUR_*; do cat $file >> posteriors.eur.by.eur done","title":"8. Processing"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#9-data-processing-in-r","text":"The next stage of data processing, done in R will create a new set of summary statistics files, containing the adjusting SNP weights from PRS-CSx. Staying in /home/manager/data/Data_Day4/out/csx : R # Load posteriors effect sizes from PRS-CSx output afr.afr<-read.table ( \"posteriors.afr.by.afr\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.afr.afr\" )) afr.by.eur<-read.table ( \"posteriors.afr.by.eur\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.afr.by.eur\" )) eur.eur<-read.table ( \"posteriors.eur.by.eur\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.eur.eur\" )) eur.by.afr<-read.table ( \"posteriors.eur.by.afr\" , col.names = c ( \"chr\" , \"SNP\" , \"bp\" , \"a1\" , \"a2\" , \"post.eur.by.afr\" )) # Load original summary statistics afr.SBP<-read.table ( \"/home/manager/data/Data_Day4/data/AFR-SBP-simulated.sumstats.prscsx\" , header = T ) eur.SBP<-read.table ( \"/home/manager/data/Data_Day4/data/EUR-SBP-simulated.sumstats.prscsx\" , header = T ) # Combine the posterior derived weights and summary statistics eur.SBP.merge1<-merge ( x = eur.SBP, y = eur.eur [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) eur.SBP.merge<-merge ( x = eur.SBP.merge1, y = afr.by.eur [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) afr.SBP.merge1<-merge ( x = afr.SBP, y = afr.afr [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) afr.SBP.merge<-merge ( x = afr.SBP.merge1, y = eur.by.afr [ c (2 ,6 )] , by = \"SNP\" , all.y = T ) # Save files write.table ( afr.SBP.merge, \"/home/manager/data/Data_Day4/afr.SBP.posterior.sumstats\" , quote = F, row.names = F ) write.table ( eur.SBP.merge, \"/home/manager/data/Data_Day4/eur.SBP.posterior.sumstats\" , quote = F, row.names = F ) q ()","title":"9. Data processing in R"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#10-use-prsice-to-apply-the-adjusted-snp-effects-to-target-phenotypes","text":"We first need to create a list of SNPs to be used as input, based on the previous PRS-CSx analysis. This is done in location /home/manager/data/Data_Day4 . awk 'NR>1 {print $1}' afr.SBP.posterior.sumstats > snps.afr.posterior awk 'NR>1 {print $1}' eur.SBP.posterior.sumstats > snps.eur.posterior The next series of commands implement in-ancestry and cross-ancestry prediction of the systolic blood pressure phenotype using the PRS-CSx optimised SNP weights. Do not forget to exchange PRSice_linux for PRSice_mac if running the commands in a Mac environment. The phenotypic files sbp_afr_1kg.sim_pheno and sbp_eur_1kg.sim_pheno contain data on systolic blood pressure with simulated heritabilities that vary from 10%, 20%, 33%, 50% and 100%. To compensate for the fact that the adjusted weights generated are based on chromosome 15, rather than the entire genome, we will be using the 100% trait version (pheno100) for this analysis.","title":"10. Use PRSice to apply the adjusted SNP effects to target phenotypes"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#11-predicting-from-african-training-to-african-target-data","text":"Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/afr.sbp.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.afr.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.afr.afr \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.afr","title":"11. Predicting from African training to African target data"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#12-predicting-from-european-training-to-african-target-data","text":"Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/eur.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.eur.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.afr.by.eur \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/AFR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_afr_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.by.eur","title":"12. Predicting from European training to African target data"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#13-predicting-from-european-training-to-european-target-data","text":"Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/eur.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.eur.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.eur.eur \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.eur","title":"13. Predicting from European training to European target data"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#14-predicting-from-african-training-to-european-target-data","text":"Rscript /home/manager/data/Data_Day4/software/PRSice.R \\ --prsice /home/manager/data/Data_Day4/software/PRSice_linux \\ --base /home/manager/data/Data_Day4/afr.SBP.posterior.sumstats \\ --extract /home/manager/data/Data_Day4/snps.afr.posterior \\ --A1 A1 \\ --pvalue P \\ --no-clump \\ --stat post.eur.by.afr \\ --beta \\ --snp SNP \\ --score sum \\ --target /home/manager/data/Data_Day4/data/EUR_1kg.hm3.only.csx \\ --binary-target F \\ --pheno /home/manager/data/Data_Day4/data/sbp_eur_1kg.sim_pheno \\ --pheno-col pheno100 \\ --thread 8 \\ --out /home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.by.afr","title":"14. Predicting from African training to European target data"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#15-create-summary-files","text":"From location /home/manager/data/Data_Day4/out/prscsx_prsice awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.afr.afr.summary > quicksum.afr-afr awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.afr.by.eur.summary > quicksum.afr-by-eur awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.eur.by.afr.summary > quicksum.eur-by-afr awk '{print $1,\"\\t\",$4,\"\\t\",$8,\"\\t\",$10}' SBP.eur.eur.summary > quicksum.eur-eur","title":"15. Create summary files"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#questions_4","text":"","title":"Questions"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#i-what-information-is-being-summarized-in-the-output-files","text":"","title":"(i) What information is being summarized in the output files??"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#ii-for-each-prediction-model-what-is-the-r2-and-value","text":"","title":"(ii) For each prediction model what is the R2 and  value???"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#16-complete-the-remaining-prs-analysis-in-r","text":"","title":"16. Complete the remaining PRS analysis in R"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#step-1-load-and-prepare-data","text":"R # Load libraries sudo apt install cmake install.packages ( \"AICcmodavg\" ) install.packages ( \"fmsb\" ) library ( AICcmodavg ) library ( fmsb ) afr.afr<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.afr.best\" , header = T ) afr.eur<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.afr.by.eur.best\" , header = T ) eur.eur<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.eur.best\" , header = T ) eur.afr<-read.table ( \"/home/manager/data/Data_Day4/out/prscsx_prsice/SBP.eur.by.afr.best\" , header = T ) colnames ( afr.afr )[4] <- \"afr.afr\" # african prediction using african PRS colnames ( afr.eur )[4] <- \"afr.eur\" # african prediction using european PRS colnames ( eur.eur )[4] <- \"eur.eur\" # european prediction using european PRS colnames ( eur.afr )[4] <- \"eur.afr\" # european prediction using african PRS # Merge PRSs according to target ancestry and source population combined.afr<-merge ( x = afr.afr, y = afr.eur [ c (2 ,4 )] , by = \"IID\" , all.x = T ) combined.eur<-merge ( x = eur.eur, y = eur.afr [ c (2 ,4 )] , by = \"IID\" , all.x = T ) # Rescale scores to have mean = \u20180\u2019 and standard deviation = \u20181\u2019 combined.afr [4 :5 ] <- as.data.frame ( scale ( combined.afr [4 :5 ])) combined.eur [4 :5 ] <- as.data.frame ( scale ( combined.eur [4 :5 ])) # Load phenotype data sbp.eur<-read.table ( \"/home/manager/data/Data_Day4/data/SBP_eur_1kg.sim_pheno\" , header = T ) sbp.afr<-read.table ( \"/home/manager/data/Data_Day4/data/SBP_afr_1kg.sim_pheno\" , header = T ) # Merge phenotypes and PRS combined.eur.pheno<-merge ( x = combined.eur [ -c (2 ,3 )] , y = sbp.eur [ ,c (2 ,3 )] , by = \"IID\" , all.x = T ) combined.afr.pheno<-merge ( x = combined.afr [ -c (2 ,3 )] , y = sbp.afr [ ,c (2 ,3 )] , by = \"IID\" , all.x = T )","title":"Step 1: Load and prepare data"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#step-2-model-selection-using-akaikes-information-criterion","text":"In the final step we want to determine whether the use of the multi-ancestry PRS formulation generated by PRS-CSx performs better at predicting systolic blood pressure, compared to the single-ancestry PRS formulation. To do this we use (AIC Akaike\u2019s Information Criterion). AIC is used to assess the performance of a competing set of regression models. We use it to compare the performance of models that contain different numbers of predictors, given that R2 is inflated by the inclusion of redundant terms in a model.","title":"Step 2: Model selection using Akaike\u2019s Information Criterion"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#16b-model-evaluation","text":"# EUROPEAN model1.eur <- glm ( pheno100 ~ eur.eur, data = combined.eur.pheno, family = gaussian ) model2.eur <- glm ( pheno100 ~ eur.afr, data = combined.eur.pheno, family = gaussian ) model3.eur <- glm ( pheno100 ~ eur.eur + eur.afr, data = combined.eur.pheno, family = gaussian ) models.eur <- list ( model1.eur, model2.eur, model3.eur ) # define model set mod.names.eur <- c ( 'eur.eur' , 'eur.afr' , 'eur.combined' ) # add model names aictab ( cand.set = models.eur, modnames = mod.names.eur ) # calculate model AICs model # AFRICAN model1.afr <- glm ( pheno100 ~ afr.afr, data = combined.afr.pheno, family = gaussian ) model2.afr <- glm ( pheno100 ~ afr.eur, data = combined.afr.pheno, family = gaussian ) model3.afr <- glm ( pheno100 ~ afr.afr + afr.eur, data = combined.afr.pheno, family = gaussian ) models.afr <- list ( model1.afr, model2.afr, model3.afr ) # define model set mod.names.afr <- c ( 'afr.afr' , 'afr.eur' , 'afr.combined' ) # add model names aictab ( cand.set = models.afr, modnames = mod.names.afr ) # calculate model AICs # NagelkerkeR2 calculations in R # African target NagelkerkeR2 ( model1.afr ) NagelkerkeR2 ( model2.afr ) NagelkerkeR2 ( model3.afr ) # European target NagelkerkeR2 ( model1.eur ) NagelkerkeR2 ( model2.eur ) NagelkerkeR2 ( model3.eur ) For each ancestry which predictive model performs best and worst? Does combining the two sets of adjusted scores perform consistently better than modelling each one separately?","title":"16b. Model evaluation"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#questions_5","text":"","title":"Questions"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#i-for-each-ancestry-which-model-performs-best-and-which-performs-worst","text":"","title":"(i) For each ancestry which model performs best and which performs worst?"},{"location":"tmp2/prs_2023-main/modules/Day4.docx/#ii-does-linearly-combining-adjusted-scores-european-plus-african-always-result-in-better-performance-compared-to-single-ancestry-prediction","text":"","title":"(ii) Does linearly combining adjusted scores (European plus African) always result in better performance compared to single-ancestry prediction?"},{"location":"tmp2/prs_2023-main/modules/Day5_Projects/","text":"Multi-Ancestry Trait Prediction - an extension of the work on Thursday Task \u2013 PRS calculation in multiple populations [3.5 hrs] Thursday\u2019s practical will focus on getting you up and running with some of the leading software tools for performing PRS calculation across ancestries. * Then we will allow you to adapt the scripts that we will provide you with, in order to complete the practical that we will set for you. * You\u2019ll be doing the practical in the groups that you were assigned to at the beginning of the week and at the end of the practical (on Friday) each group will give a presentation about your work and your findings * For the project there will be a total of 5 populations to choose from, namely East Asian, European, South Asian, Amerindian, African (EAS, EUR, SAS, AMR and AFR). Each group will choose a combination of two populations, which have been simulated to have the same genetic architecture but with a different LD structure and allele frequencies. * Using the methods you will learn during the day 4 practical (and potentially other skills learned throughout this week) you will evaluate the performance of at least one of the multi-ancestry methods you will learn about tomorrow and compare this against the performance of PRSice, (a tool which hasn\u2019t been designed for multi-ancestry purposes).","title":"Multi-Ancestry Trait Prediction -  an extension of the work on Thursday"},{"location":"tmp2/prs_2023-main/modules/Day5_Projects/#multi-ancestry-trait-prediction-an-extension-of-the-work-on-thursday","text":"","title":"Multi-Ancestry Trait Prediction -  an extension of the work on Thursday"},{"location":"tmp2/prs_2023-main/modules/Day5_Projects/#task-prs-calculation-in-multiple-populations-35-hrs","text":"Thursday\u2019s practical will focus on getting you up and running with some of the leading software tools for performing PRS calculation across ancestries. * Then we will allow you to adapt the scripts that we will provide you with, in order to complete the practical that we will set for you. * You\u2019ll be doing the practical in the groups that you were assigned to at the beginning of the week and at the end of the practical (on Friday) each group will give a presentation about your work and your findings * For the project there will be a total of 5 populations to choose from, namely East Asian, European, South Asian, Amerindian, African (EAS, EUR, SAS, AMR and AFR). Each group will choose a combination of two populations, which have been simulated to have the same genetic architecture but with a different LD structure and allele frequencies. * Using the methods you will learn during the day 4 practical (and potentially other skills learned throughout this week) you will evaluate the performance of at least one of the multi-ancestry methods you will learn about tomorrow and compare this against the performance of PRSice, (a tool which hasn\u2019t been designed for multi-ancestry purposes).","title":"Task \u2013 PRS calculation in multiple populations [3.5 hrs]"},{"location":"tmp2/prs_2023-main/modules/READme/","text":"Module directory Directory for placing the course module files - these should be markdown or PDF documents They include the presentations and practical manuals for the module. Converting between markdown to PDF can be performed using pandoc. Here is a tutorial and system for that: Converting with Pandoc There is an example markdown file - module_base.md","title":"Module directory"},{"location":"tmp2/prs_2023-main/modules/READme/#module-directory","text":"Directory for placing the course module files - these should be markdown or PDF documents They include the presentations and practical manuals for the module. Converting between markdown to PDF can be performed using pandoc. Here is a tutorial and system for that: Converting with Pandoc There is an example markdown file - module_base.md","title":"Module directory"},{"location":"tmp2/prs_2023-main/modules/module_base/","text":"This is a base file to modify with your module content Please rename this md file to suit your module Markdown guide is available https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax Example git https://github.com/WCSCourses/WWPG_2022/blob/main/manuals/module_linux_scripting/module_linux_scripting.md","title":"This is a base file to modify with your module content"},{"location":"tmp2/prs_2023-main/modules/module_base/#this-is-a-base-file-to-modify-with-your-module-content","text":"","title":"This is a base file to modify with your module content"},{"location":"tmp2/prs_2023-main/modules/module_base/#please-rename-this-md-file-to-suit-your-module","text":"","title":"Please rename this md file to suit your module"},{"location":"tmp2/prs_2023-main/modules/module_base/#markdown-guide-is-available","text":"https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax","title":"Markdown guide is available"},{"location":"tmp2/prs_2023-main/modules/module_base/#example-git","text":"https://github.com/WCSCourses/WWPG_2022/blob/main/manuals/module_linux_scripting/module_linux_scripting.md","title":"Example git"},{"location":"tmp2/prs_2023-main/scripts/base/","text":"scripts base","title":"Base"}]}